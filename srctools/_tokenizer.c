/* Generated by Cython 0.29.24 */

#ifndef PY_SSIZE_T_CLEAN
#define PY_SSIZE_T_CLEAN
#endif /* PY_SSIZE_T_CLEAN */
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_29_24"
#define CYTHON_HEX_VERSION 0x001D18F0
#define CYTHON_FUTURE_DIVISION 1
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
  #ifndef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS (PY_VERSION_HEX >= 0x030600B1)
  #endif
  #ifndef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #elif defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif

#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
#if PY_VERSION_HEX >= 0x030800A4 && PY_VERSION_HEX < 0x030800B2
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, 0, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#if PY_VERSION_HEX <= 0x030700A3 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030400A1
  #define PyMem_RawMalloc(n)           PyMem_Malloc(n)
  #define PyMem_RawRealloc(p, n)       PyMem_Realloc(p, n)
  #define PyMem_RawFree(p)             PyMem_Free(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if PY_VERSION_HEX < 0x030700A2 && !defined(PyThread_tss_create) && !defined(Py_tss_NEEDS_INIT)
#include "pythread.h"
#define Py_tss_NEEDS_INIT 0
typedef int Py_tss_t;
static CYTHON_INLINE int PyThread_tss_create(Py_tss_t *key) {
  *key = PyThread_create_key();
  return 0;
}
static CYTHON_INLINE Py_tss_t * PyThread_tss_alloc(void) {
  Py_tss_t *key = (Py_tss_t *)PyObject_Malloc(sizeof(Py_tss_t));
  *key = Py_tss_NEEDS_INIT;
  return key;
}
static CYTHON_INLINE void PyThread_tss_free(Py_tss_t *key) {
  PyObject_Free(key);
}
static CYTHON_INLINE int PyThread_tss_is_created(Py_tss_t *key) {
  return *key != Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE void PyThread_tss_delete(Py_tss_t *key) {
  PyThread_delete_key(*key);
  *key = Py_tss_NEEDS_INIT;
}
static CYTHON_INLINE int PyThread_tss_set(Py_tss_t *key, void *value) {
  return PyThread_set_key_value(*key, value);
}
static CYTHON_INLINE void * PyThread_tss_get(Py_tss_t *key) {
  return PyThread_get_key_value(*key);
}
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
#else
#define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #if defined(PyUnicode_IS_READY)
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #else
  #define __Pyx_PyUnicode_READY(op)       (0)
  #endif
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #if defined(PyUnicode_IS_READY) && defined(PyUnicode_GET_SIZE)
  #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
  #else
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
  #endif
  #else
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #endif
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None || (PyString_Check(b) && !PyString_CheckExact(b)))) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#ifndef PyObject_Unicode
  #define PyObject_Unicode             PyObject_Str
#endif
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
#else
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? ((void)(klass), PyMethod_New(func, self)) : __Pyx_NewRef(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#define __PYX_MARK_ERR_POS(f_index, lineno) \
    { __pyx_filename = __pyx_f[f_index]; (void)__pyx_filename; __pyx_lineno = lineno; (void)__pyx_lineno; __pyx_clineno = __LINE__; (void)__pyx_clineno; }
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__srctools___tokenizer
#define __PYX_HAVE_API__srctools___tokenizer
/* Early includes */
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT (PY_MAJOR_VERSION >= 3 && __PYX_DEFAULT_STRING_ENCODING_IS_UTF8)
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c) + 1);
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime = NULL;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "srctools\\_tokenizer.pyx",
  "type.pxd",
};

/*--- Type declarations ---*/
struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer;
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer;
struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer;
struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter;
struct __pyx_obj_8srctools_10_tokenizer_BlockIter;
struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr;

/* "srctools/_tokenizer.pyx":74
 * 
 * # noinspection PyMissingTypeHints
 * cdef class BaseTokenizer:             # <<<<<<<<<<<<<<
 *     """Provides an interface for processing text into tokens.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer {
  PyObject_HEAD
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *__pyx_vtab;
  PyObject *error_type;
  PyObject *filename;
  PyObject *pushback_tok;
  PyObject *pushback_val;
  int line_num;
  uint_fast8_t flags;
};


/* "srctools/_tokenizer.pyx":311
 * 
 * 
 * cdef class Tokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_Tokenizer {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  PyObject *cur_chunk;
  PyObject *chunk_iter;
  Py_ssize_t char_index;
  Py_ssize_t buf_size;
  Py_ssize_t buf_pos;
  unsigned char *val_buffer;
  unsigned char const *chunk_buf;
  Py_ssize_t chunk_size;
};


/* "srctools/_tokenizer.pyx":816
 * 
 * 
 * cdef class IterTokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Wraps a token iterator to provide the tokenizer interface.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  PyObject *source;
};


/* "srctools/_tokenizer.pyx":849
 * @cython.embedsignature(False)
 * @cython.internal
 * cdef class _NewlinesIter:             # <<<<<<<<<<<<<<
 *     """Iterate over the tokens, skipping newlines."""
 *     cdef BaseTokenizer tok
 */
struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter {
  PyObject_HEAD
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *tok;
};


/* "srctools/_tokenizer.pyx":885
 * @cython.embedsignature(False)
 * @cython.internal
 * cdef class BlockIter:             # <<<<<<<<<<<<<<
 *     """Helper iterator for parsing keyvalue style blocks."""
 *     cdef BaseTokenizer tok
 */
struct __pyx_obj_8srctools_10_tokenizer_BlockIter {
  PyObject_HEAD
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *tok;
  PyObject *name;
  int expect_brace;
};


/* "srctools/_tokenizer.pyx":990
 * # This is a replacement for a method in VPK, which is very slow normally
 * # since it has to accumulate character by character.
 * cdef class _VPK_IterNullstr:             # <<<<<<<<<<<<<<
 *     """Read a null-terminated ASCII string from the file.
 * 
 */
struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr {
  PyObject_HEAD
  PyObject *file;
  unsigned char *chars;
  Py_ssize_t size;
  Py_ssize_t used;
};



/* "srctools/_tokenizer.pyx":74
 * 
 * # noinspection PyMissingTypeHints
 * cdef class BaseTokenizer:             # <<<<<<<<<<<<<<
 *     """Provides an interface for processing text into tokens.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer {
  PyObject *(*_error)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *);
  PyObject *(*next_token)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *);
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *);


/* "srctools/_tokenizer.pyx":311
 * 
 * 
 * cdef class Tokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Processes text data into groups of tokens.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer {
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
  void (*buf_reset)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  int (*buf_add_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, char);
  PyObject *(*buf_get_text)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
  unsigned char (*_next_char)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *__pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *);
static CYTHON_INLINE int __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, char);


/* "srctools/_tokenizer.pyx":816
 * 
 * 
 * cdef class IterTokenizer(BaseTokenizer):             # <<<<<<<<<<<<<<
 *     """Wraps a token iterator to provide the tokenizer interface.
 * 
 */

struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer {
  struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_base;
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer *__pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyUnicode_Substring.proto */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_Substring(
            PyObject* text, Py_ssize_t start, Py_ssize_t stop);

/* PyObjectFormatSimple.proto */
#if CYTHON_COMPILING_IN_PYPY
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#elif PY_MAJOR_VERSION < 3
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyString_CheckExact(s)) ? PyUnicode_FromEncodedObject(s, NULL, "strict") :\
        PyObject_Format(s, f))
#elif CYTHON_USE_TYPE_SLOTS
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        likely(PyLong_CheckExact(s)) ? PyLong_Type.tp_str(s) :\
        likely(PyFloat_CheckExact(s)) ? PyFloat_Type.tp_str(s) :\
        PyObject_Format(s, f))
#else
    #define __Pyx_PyObject_FormatSimple(s, f) (\
        likely(PyUnicode_CheckExact(s)) ? (Py_INCREF(s), s) :\
        PyObject_Format(s, f))
#endif

/* IncludeStringH.proto */
#include <string.h>

/* JoinPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      Py_UCS4 max_char);

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* PyUnicode_Unicode.proto */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_Unicode(PyObject *obj);

/* KeywordStringCheck.proto */
static int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* PyObjectFormatAndDecref.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f);
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* PyObjectCall2Args.proto */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2);

/* IterNext.proto */
#define __Pyx_PyIter_Next(obj) __Pyx_PyIter_Next2(obj, NULL)
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject *, PyObject *);

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* GCCDiagnostics.proto */
#if defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define __Pyx_HAS_GCC_DIAGNOSTIC
#endif

/* BuildPyUnicode.proto */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char);

/* CIntToPyUnicode.proto */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char);

/* decode_c_string_utf16.proto */
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 0;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16LE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = -1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16BE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* PyObjectFormat.proto */
#if CYTHON_USE_UNICODE_WRITER
static PyObject* __Pyx_PyObject_Format(PyObject* s, PyObject* f);
#else
#define __Pyx_PyObject_Format(s, f) PyObject_Format(s, f)
#endif

/* PyObject_GenericGetAttrNoDict.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttrNoDict PyObject_GenericGetAttr
#endif

/* PyObject_GenericGetAttr.proto */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GenericGetAttr PyObject_GenericGetAttr
#endif

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto
#define __PYX_HAVE_RT_ImportType_proto
enum __Pyx_ImportType_CheckSize {
   __Pyx_ImportType_CheckSize_Error = 0,
   __Pyx_ImportType_CheckSize_Warn = 1,
   __Pyx_ImportType_CheckSize_Ignore = 2
};
static PyTypeObject *__Pyx_ImportType(PyObject* module, const char *module_name, const char *class_name, size_t size, enum __Pyx_ImportType_CheckSize check_size);
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* CythonFunctionShared.proto */
#define __Pyx_CyFunction_USED 1
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#define __Pyx_CyFunction_GetClassObj(f)\
    (((__pyx_CyFunctionObject *) (f))->func_classobj)
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
    PyCFunctionObject func;
#if PY_VERSION_HEX < 0x030500A0
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
    PyObject *func_classobj;
    void *defaults;
    int defaults_pyobjects;
    size_t defaults_size;  // used by FusedFunction for copying defaults
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
} __pyx_CyFunctionObject;
static PyTypeObject *__pyx_CyFunctionType = 0;
#define __Pyx_CyFunction_Check(obj)  (__Pyx_TypeCheck(obj, __pyx_CyFunctionType))
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject* op, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *self,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *m,
                                                         size_t size,
                                                         int pyobjects);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(void);

/* CythonFunction.proto */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
#define __Pyx_GetModuleGlobalNameUncached(var, name)  {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
}
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o, n, NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value);
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_char(unsigned char value);

/* BytesContains.proto */
static CYTHON_INLINE int __Pyx_BytesContains(PyObject* bytes, char character);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto*/
static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static CYTHON_INLINE int __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, char __pyx_v_new_char); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static unsigned char __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto*/
static PyObject *__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto*/

/* Module declarations from 'cython' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'libc.stdint' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'srctools._tokenizer' */
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_Tokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_IterTokenizer = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer__NewlinesIter = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer_BlockIter = 0;
static PyTypeObject *__pyx_ptype_8srctools_10_tokenizer__VPK_IterNullstr = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_os_fspath = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_Token = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_TokenSyntaxError = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_STRING = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PAREN_ARGS = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PROP_FLAG = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_DIRECTIVE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_OPEN = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EOF_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_COLON_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_EQUALS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_PLUS_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_COMMA_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = 0;
static PyObject *__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = 0;
static unsigned char *__pyx_v_8srctools_10_tokenizer_EMPTY_BUF;
#define __Pyx_MODULE_NAME "srctools._tokenizer"
extern int __pyx_module_is_main_srctools___tokenizer;
int __pyx_module_is_main_srctools___tokenizer = 0;

/* Implementation of 'srctools._tokenizer' */
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_NotImplementedError;
static PyObject *__pyx_builtin_StopIteration;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_MemoryError;
static PyObject *__pyx_builtin_AttributeError;
static PyObject *__pyx_builtin_UnicodeDecodeError;
static PyObject *__pyx_builtin_id;
static PyObject *__pyx_builtin_range;
static const char __pyx_k_[] = "\"!";
static const char __pyx_k_X[] = "X";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_j[] = "j";
static const char __pyx_k__3[] = "!.";
static const char __pyx_k__4[] = "(";
static const char __pyx_k__5[] = ")!";
static const char __pyx_k__6[] = "!";
static const char __pyx_k__8[] = "";
static const char __pyx_k__9[] = "\n";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_os[] = "os";
static const char __pyx_k_EOF[] = "EOF";
static const char __pyx_k__10[] = "{";
static const char __pyx_k__11[] = "}";
static const char __pyx_k__12[] = "[";
static const char __pyx_k__13[] = "]";
static const char __pyx_k__14[] = ":";
static const char __pyx_k__15[] = "=";
static const char __pyx_k__16[] = "+";
static const char __pyx_k__17[] = ",";
static const char __pyx_k__21[] = ", ";
static const char __pyx_k__22[] = ")";
static const char __pyx_k__23[] = ">";
static const char __pyx_k_all[] = "__all__";
static const char __pyx_k_tok[] = "tok";
static const char __pyx_k_None[] = "None";
static const char __pyx_k_PLUS[] = "PLUS";
static const char __pyx_k_args[] = "args";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_file[] = "file";
static const char __pyx_k_init[] = "__init__";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "__name__";
static const char __pyx_k_peek[] = "peek";
static const char __pyx_k_read[] = "read";
static const char __pyx_k_self[] = "self";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_text[] = "text";
static const char __pyx_k_COLON[] = "COLON";
static const char __pyx_k_COMMA[] = "COMMA";
static const char __pyx_k_Token[] = "Token ";
static const char __pyx_k_block[] = " block!";
static const char __pyx_k_error[] = "error";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_token[] = "token";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_EQUALS[] = "EQUALS";
static const char __pyx_k_STRING[] = "STRING";
static const char __pyx_k_expect[] = "expect";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_fspath[] = "fspath";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_in_buf[] = "in_buf";
static const char __pyx_k_letter[] = "letter";
static const char __pyx_k_module[] = "__module__";
static const char __pyx_k_name_2[] = "name";
static const char __pyx_k_reduce[] = "__reduce__";
static const char __pyx_k_return[] = "return";
static const char __pyx_k_source[] = "source";
static const char __pyx_k_NEWLINE[] = "NEWLINE";
static const char __pyx_k_Token_2[] = "Token";
static const char __pyx_k_block_2[] = "block";
static const char __pyx_k_but_got[] = ", but got ";
static const char __pyx_k_message[] = "message";
static const char __pyx_k_str_msg[] = "str_msg";
static const char __pyx_k_tok_val[] = "tok_val";
static const char __pyx_k_unicode[] = "unicode";
static const char __pyx_k_value_2[] = "_value_";
static const char __pyx_k_Expected[] = "Expected ";
static const char __pyx_k_Unclosed[] = "Unclosed ";
static const char __pyx_k_casefold[] = "casefold";
static const char __pyx_k_filename[] = "filename";
static const char __pyx_k_out_buff[] = "out_buff";
static const char __pyx_k_DIRECTIVE[] = "DIRECTIVE";
static const char __pyx_k_PROP_FLAG[] = "PROP_FLAG";
static const char __pyx_k_Tokenizer[] = "Tokenizer";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_get_token[] = "_get_token";
static const char __pyx_k_push_back[] = "push_back";
static const char __pyx_k_BRACE_OPEN[] = "BRACE_OPEN";
static const char __pyx_k_BRACK_OPEN[] = "BRACK_OPEN";
static const char __pyx_k_PAREN_ARGS[] = "PAREN_ARGS";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_final_size[] = "final_size";
static const char __pyx_k_next_token[] = "next_token";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_BRACE_CLOSE[] = "BRACE_CLOSE";
static const char __pyx_k_BRACK_CLOSE[] = "BRACK_CLOSE";
static const char __pyx_k_MemoryError[] = "MemoryError";
static const char __pyx_k_escape_text[] = "escape_text";
static const char __pyx_k_tok_and_val[] = "tok_and_val";
static const char __pyx_k_expect_brace[] = "expect_brace";
static const char __pyx_k_skip_newline[] = "skip_newline";
static const char __pyx_k_BaseTokenizer[] = "BaseTokenizer";
static const char __pyx_k_IterTokenizer[] = "IterTokenizer(";
static const char __pyx_k_StopIteration[] = "StopIteration";
static const char __pyx_k_Unknown_token[] = "Unknown token ";
static const char __pyx_k_allow_escapes[] = "allow_escapes";
static const char __pyx_k_consume_brace[] = "consume_brace";
static const char __pyx_k_AttributeError[] = "AttributeError";
static const char __pyx_k_colon_operator[] = "colon_operator";
static const char __pyx_k_is_not_a_Token[] = " is not a Token!";
static const char __pyx_k_string_bracket[] = "string_bracket";
static const char __pyx_k_IterTokenizer_2[] = "IterTokenizer";
static const char __pyx_k_VPK_IterNullstr[] = "_VPK_IterNullstr";
static const char __pyx_k_TokenSyntaxError[] = "TokenSyntaxError";
static const char __pyx_k_Unexpected_token[] = "Unexpected token ";
static const char __pyx_k_skipping_newlines[] = "skipping_newlines";
static const char __pyx_k_BaseTokenizer_peek[] = "BaseTokenizer.peek";
static const char __pyx_k_BlockIter___reduce[] = "BlockIter.__reduce__";
static const char __pyx_k_UnicodeDecodeError[] = "UnicodeDecodeError";
static const char __pyx_k_Value_required_for[] = "Value required for ";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_srctools_tokenizer[] = "srctools.tokenizer";
static const char __pyx_k_BaseTokenizer_block[] = "BaseTokenizer.block";
static const char __pyx_k_BaseTokenizer_error[] = "BaseTokenizer.error";
static const char __pyx_k_Expected_string_got[] = "Expected string, got ";
static const char __pyx_k_NotImplementedError[] = "NotImplementedError";
static const char __pyx_k_Unterminated_string[] = "Unterminated string!";
static const char __pyx_k_allow_star_comments[] = "allow_star_comments";
static const char __pyx_k_srctools__tokenizer[] = "srctools._tokenizer";
static const char __pyx_k_BaseTokenizer_expect[] = "BaseTokenizer.expect";
static const char __pyx_k_Cannot_nest_brackets[] = "Cannot nest [] brackets!";
static const char __pyx_k_Unexpected_character[] = "Unexpected character \"";
static const char __pyx_k_Could_not_decode_file[] = "Could not decode file!";
static const char __pyx_k_Data_was_not_a_string[] = "Data was not a string!";
static const char __pyx_k_NewlinesIter___reduce[] = "_NewlinesIter.__reduce__";
static const char __pyx_k_No_open_to_close_with[] = "No open [] to close with \"]\"!";
static const char __pyx_k_BaseTokenizer___reduce[] = "BaseTokenizer.__reduce__";
static const char __pyx_k_Cannot_nest_brackets_2[] = "Cannot nest () brackets!";
static const char __pyx_k_Invalid_error_instance[] = "Invalid error instance \"";
static const char __pyx_k_BaseTokenizer_push_back[] = "BaseTokenizer.push_back";
static const char __pyx_k_Cannot_pickle_BlockIter[] = "Cannot pickle BlockIter!";
static const char __pyx_k_No_open_to_close_with_2[] = "No open () to close with \")\"!";
static const char __pyx_k_srctools__tokenizer_pyx[] = "srctools\\_tokenizer.pyx";
static const char __pyx_k_BaseTokenizer__get_token[] = "BaseTokenizer._get_token";
static const char __pyx_k_Cannot_parse_binary_data[] = "Cannot parse binary data!";
static const char __pyx_k_Cannot_pickle_Tokenizers[] = "Cannot pickle Tokenizers!";
static const char __pyx_k_Unterminated_parentheses[] = "Unterminated parentheses!";
static const char __pyx_k_Token_already_pushed_back[] = "Token already pushed back!";
static const char __pyx_k_Cannot_pickle__NewlinesIter[] = "Cannot pickle _NewlinesIter!";
static const char __pyx_k_Expected_BRACE_OPEN_but_got[] = "Expected BRACE_OPEN, but got ";
static const char __pyx_k_passed_with_multiple_values[] = " passed with multiple values: ";
static const char __pyx_k_style_comments_are_not_allowed[] = "/**/-style comments are not allowed!";
static const char __pyx_k_BaseTokenizer_skipping_newlines[] = "BaseTokenizer.skipping_newlines";
static const char __pyx_k_Cannot_parse_binary_data_Decode[] = "Cannot parse binary data! Decode to the desired encoding, or wrap in io.TextIOWrapper() to decode gradually.";
static const char __pyx_k_Cython_version_of_the_Tokenizer[] = "Cython version of the Tokenizer class.";
static const char __pyx_k_srctools_tokenizer_BaseTokenize[] = "<srctools.tokenizer.BaseTokenizer.skipping_newlines() at ";
static const char __pyx_k_Asked_to_read_1_byte_got_multipl[] = "Asked to read 1 byte, got multiple?";
static const char __pyx_k_Cannot_create_BlockIter_instance[] = "Cannot create 'BlockIter' instances";
static const char __pyx_k_Cannot_create__NewlinesIter_inst[] = "Cannot create '_NewlinesIter' instances";
static const char __pyx_k_Reached_EOF_without_null_termina[] = "Reached EOF without null-terminator in ";
static const char __pyx_k_Reached_end_of_line_without_clos[] = "Reached end of line without closing \"]\"!";
static const char __pyx_k_Single_slash_found_instead_of_tw[] = "Single slash found, instead of two for a comment (// or /* */)!";
static const char __pyx_k_The_error_type_must_be_a_TokenSy[] = "The error type must be a TokenSyntaxError subclass, not ";
static const char __pyx_k_Unclosed_comment_starting_on_lin[] = "Unclosed /* comment (starting on line ";
static const char __pyx_k_srctools_tokenizer_BaseTokenize_2[] = "<srctools.tokenizer.BaseTokenizer.block() at ";
static const char __pyx_k_Single_slash_found_instead_of_tw_2[] = "Single slash found, instead of two for a comment (//)!";
static PyObject *__pyx_kp_u_;
static PyObject *__pyx_kp_u_Asked_to_read_1_byte_got_multipl;
static PyObject *__pyx_n_s_AttributeError;
static PyObject *__pyx_n_s_BRACE_CLOSE;
static PyObject *__pyx_n_s_BRACE_OPEN;
static PyObject *__pyx_n_s_BRACK_CLOSE;
static PyObject *__pyx_n_s_BRACK_OPEN;
static PyObject *__pyx_n_s_BaseTokenizer;
static PyObject *__pyx_n_u_BaseTokenizer;
static PyObject *__pyx_n_s_BaseTokenizer___reduce;
static PyObject *__pyx_n_s_BaseTokenizer__get_token;
static PyObject *__pyx_n_s_BaseTokenizer_block;
static PyObject *__pyx_n_s_BaseTokenizer_error;
static PyObject *__pyx_n_s_BaseTokenizer_expect;
static PyObject *__pyx_n_s_BaseTokenizer_peek;
static PyObject *__pyx_n_s_BaseTokenizer_push_back;
static PyObject *__pyx_n_s_BaseTokenizer_skipping_newlines;
static PyObject *__pyx_n_s_BlockIter___reduce;
static PyObject *__pyx_n_s_COLON;
static PyObject *__pyx_n_s_COMMA;
static PyObject *__pyx_kp_u_Cannot_create_BlockIter_instance;
static PyObject *__pyx_kp_u_Cannot_create__NewlinesIter_inst;
static PyObject *__pyx_kp_u_Cannot_nest_brackets;
static PyObject *__pyx_kp_u_Cannot_nest_brackets_2;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data;
static PyObject *__pyx_kp_u_Cannot_parse_binary_data_Decode;
static PyObject *__pyx_kp_u_Cannot_pickle_BlockIter;
static PyObject *__pyx_kp_u_Cannot_pickle_Tokenizers;
static PyObject *__pyx_kp_u_Cannot_pickle__NewlinesIter;
static PyObject *__pyx_kp_u_Could_not_decode_file;
static PyObject *__pyx_n_s_DIRECTIVE;
static PyObject *__pyx_kp_u_Data_was_not_a_string;
static PyObject *__pyx_n_s_EOF;
static PyObject *__pyx_n_s_EQUALS;
static PyObject *__pyx_kp_u_Expected;
static PyObject *__pyx_kp_u_Expected_BRACE_OPEN_but_got;
static PyObject *__pyx_kp_u_Expected_string_got;
static PyObject *__pyx_kp_u_Invalid_error_instance;
static PyObject *__pyx_kp_u_IterTokenizer;
static PyObject *__pyx_n_s_IterTokenizer_2;
static PyObject *__pyx_n_u_IterTokenizer_2;
static PyObject *__pyx_n_s_MemoryError;
static PyObject *__pyx_n_s_NEWLINE;
static PyObject *__pyx_n_s_NewlinesIter___reduce;
static PyObject *__pyx_kp_u_No_open_to_close_with;
static PyObject *__pyx_kp_u_No_open_to_close_with_2;
static PyObject *__pyx_kp_u_None;
static PyObject *__pyx_n_s_NotImplementedError;
static PyObject *__pyx_n_s_PAREN_ARGS;
static PyObject *__pyx_n_s_PLUS;
static PyObject *__pyx_n_s_PROP_FLAG;
static PyObject *__pyx_kp_u_Reached_EOF_without_null_termina;
static PyObject *__pyx_kp_u_Reached_end_of_line_without_clos;
static PyObject *__pyx_n_s_STRING;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw;
static PyObject *__pyx_kp_u_Single_slash_found_instead_of_tw_2;
static PyObject *__pyx_n_s_StopIteration;
static PyObject *__pyx_kp_u_The_error_type_must_be_a_TokenSy;
static PyObject *__pyx_kp_u_Token;
static PyObject *__pyx_n_s_TokenSyntaxError;
static PyObject *__pyx_n_s_Token_2;
static PyObject *__pyx_kp_u_Token_already_pushed_back;
static PyObject *__pyx_n_s_Tokenizer;
static PyObject *__pyx_n_u_Tokenizer;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_kp_u_Unclosed;
static PyObject *__pyx_kp_u_Unclosed_comment_starting_on_lin;
static PyObject *__pyx_kp_u_Unexpected_character;
static PyObject *__pyx_kp_u_Unexpected_token;
static PyObject *__pyx_n_s_UnicodeDecodeError;
static PyObject *__pyx_kp_u_Unknown_token;
static PyObject *__pyx_kp_u_Unterminated_parentheses;
static PyObject *__pyx_kp_u_Unterminated_string;
static PyObject *__pyx_n_s_VPK_IterNullstr;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_u_Value_required_for;
static PyObject *__pyx_n_u_X;
static PyObject *__pyx_kp_u__10;
static PyObject *__pyx_kp_u__11;
static PyObject *__pyx_kp_u__12;
static PyObject *__pyx_kp_u__13;
static PyObject *__pyx_kp_u__14;
static PyObject *__pyx_kp_u__15;
static PyObject *__pyx_kp_u__16;
static PyObject *__pyx_kp_u__17;
static PyObject *__pyx_kp_u__21;
static PyObject *__pyx_kp_u__22;
static PyObject *__pyx_kp_u__23;
static PyObject *__pyx_kp_u__3;
static PyObject *__pyx_kp_u__4;
static PyObject *__pyx_kp_u__5;
static PyObject *__pyx_kp_u__6;
static PyObject *__pyx_kp_u__8;
static PyObject *__pyx_kp_u__9;
static PyObject *__pyx_n_s_all;
static PyObject *__pyx_n_s_allow_escapes;
static PyObject *__pyx_n_s_allow_star_comments;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_kp_u_block;
static PyObject *__pyx_n_s_block_2;
static PyObject *__pyx_kp_u_but_got;
static PyObject *__pyx_n_s_casefold;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_colon_operator;
static PyObject *__pyx_n_s_consume_brace;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_n_s_error;
static PyObject *__pyx_n_s_escape_text;
static PyObject *__pyx_n_u_escape_text;
static PyObject *__pyx_n_s_expect;
static PyObject *__pyx_n_s_expect_brace;
static PyObject *__pyx_n_s_file;
static PyObject *__pyx_n_s_filename;
static PyObject *__pyx_n_s_final_size;
static PyObject *__pyx_n_s_format;
static PyObject *__pyx_n_s_fspath;
static PyObject *__pyx_n_s_get_token;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_in_buf;
static PyObject *__pyx_n_s_init;
static PyObject *__pyx_kp_u_is_not_a_Token;
static PyObject *__pyx_n_s_j;
static PyObject *__pyx_n_s_letter;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_message;
static PyObject *__pyx_n_s_module;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_name_2;
static PyObject *__pyx_n_s_next_token;
static PyObject *__pyx_n_s_os;
static PyObject *__pyx_n_s_out_buff;
static PyObject *__pyx_kp_u_passed_with_multiple_values;
static PyObject *__pyx_n_s_peek;
static PyObject *__pyx_n_s_push_back;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_read;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_return;
static PyObject *__pyx_n_s_self;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_skip_newline;
static PyObject *__pyx_n_s_skipping_newlines;
static PyObject *__pyx_n_s_source;
static PyObject *__pyx_n_s_srctools__tokenizer;
static PyObject *__pyx_kp_s_srctools__tokenizer_pyx;
static PyObject *__pyx_n_s_srctools_tokenizer;
static PyObject *__pyx_kp_u_srctools_tokenizer;
static PyObject *__pyx_kp_u_srctools_tokenizer_BaseTokenize;
static PyObject *__pyx_kp_u_srctools_tokenizer_BaseTokenize_2;
static PyObject *__pyx_n_s_str_msg;
static PyObject *__pyx_n_s_string_bracket;
static PyObject *__pyx_kp_u_style_comments_are_not_allowed;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_text;
static PyObject *__pyx_n_s_tok;
static PyObject *__pyx_n_s_tok_and_val;
static PyObject *__pyx_n_s_tok_val;
static PyObject *__pyx_n_s_token;
static PyObject *__pyx_n_u_unicode;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_value_2;
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_filename, PyObject *__pyx_v_error); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_fname); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8_get_token(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10__iter__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12__next__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14push_back(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16peek(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_20block(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_name, PyObject *__pyx_v_consume_brace); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_22expect(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments, int __pyx_v_colon_operator); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_filename, PyObject *__pyx_v_error); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_value); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9BlockIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok, PyObject *__pyx_v_name, int __pyx_v_expect_brace); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_9BlockIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr___cinit__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self); /* proto */
static void __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self); /* proto */
static int __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_4__init__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self, PyObject *__pyx_v_file); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_8__next__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self); /* proto */
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_IterTokenizer(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BlockIter(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_8srctools_10_tokenizer__VPK_IterNullstr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_1024;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__7;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__25;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__49;
static PyObject *__pyx_codeobj__30;
static PyObject *__pyx_codeobj__32;
static PyObject *__pyx_codeobj__34;
static PyObject *__pyx_codeobj__36;
static PyObject *__pyx_codeobj__38;
static PyObject *__pyx_codeobj__40;
static PyObject *__pyx_codeobj__42;
static PyObject *__pyx_codeobj__44;
static PyObject *__pyx_codeobj__46;
static PyObject *__pyx_codeobj__48;
static PyObject *__pyx_codeobj__50;
/* Late includes */

/* "srctools/_tokenizer.pyx":92
 *     cdef uint_fast8_t flags
 * 
 *     def __init__(self, filename, error):             # <<<<<<<<<<<<<<
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_filename,&__pyx_n_s_error,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, 1); __PYX_ERR(0, 92, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 92, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_filename = values[0];
    __pyx_v_error = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 92, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_filename, __pyx_v_error);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_filename, PyObject *__pyx_v_error) {
  PyObject *__pyx_v_fname = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  Py_UCS4 __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":95
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 *         if filename is not None:             # <<<<<<<<<<<<<<
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(filename)
 */
  __pyx_t_1 = (__pyx_v_filename != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":97
 *         if filename is not None:
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(filename)             # <<<<<<<<<<<<<<
 *             if isinstance(fname, bytes):
 *                 # We only use this for display, so if bytes convert.
 */
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_v_8srctools_10_tokenizer_os_fspath, __pyx_v_filename); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 97, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_v_fname = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":98
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(filename)
 *             if isinstance(fname, bytes):             # <<<<<<<<<<<<<<
 *                 # We only use this for display, so if bytes convert.
 *                 # Call repr() then strip the b'', so we get the
 */
    __pyx_t_2 = PyBytes_Check(__pyx_v_fname); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "srctools/_tokenizer.pyx":102
 *                 # Call repr() then strip the b'', so we get the
 *                 # automatic escaping of unprintable characters.
 *                 fname = (<str>repr(fname))[2:-1]             # <<<<<<<<<<<<<<
 *             self.filename = str(fname)
 *         else:
 */
      __pyx_t_3 = PyObject_Repr(__pyx_v_fname); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 102, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (unlikely(__pyx_t_3 == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 102, __pyx_L1_error)
      }
      __pyx_t_4 = __Pyx_PyUnicode_Substring(((PyObject*)__pyx_t_3), 2, -1L); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 102, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_fname, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":98
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(filename)
 *             if isinstance(fname, bytes):             # <<<<<<<<<<<<<<
 *                 # We only use this for display, so if bytes convert.
 *                 # Call repr() then strip the b'', so we get the
 */
    }

    /* "srctools/_tokenizer.pyx":103
 *                 # automatic escaping of unprintable characters.
 *                 fname = (<str>repr(fname))[2:-1]
 *             self.filename = str(fname)             # <<<<<<<<<<<<<<
 *         else:
 *             self.filename = None
 */
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_fname); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 103, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->filename);
    __Pyx_DECREF(__pyx_v_self->filename);
    __pyx_v_self->filename = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "srctools/_tokenizer.pyx":95
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 *         if filename is not None:             # <<<<<<<<<<<<<<
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(filename)
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":105
 *             self.filename = str(fname)
 *         else:
 *             self.filename = None             # <<<<<<<<<<<<<<
 * 
 *         if error is None:
 */
  /*else*/ {
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->filename);
    __Pyx_DECREF(__pyx_v_self->filename);
    __pyx_v_self->filename = ((PyObject*)Py_None);
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":107
 *             self.filename = None
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
  __pyx_t_1 = (__pyx_v_error == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":108
 * 
 *         if error is None:
 *             self.error_type = TokenSyntaxError             # <<<<<<<<<<<<<<
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 */
    __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;

    /* "srctools/_tokenizer.pyx":107
 *             self.filename = None
 * 
 *         if error is None:             # <<<<<<<<<<<<<<
 *             self.error_type = TokenSyntaxError
 *         else:
 */
    goto __pyx_L5;
  }

  /* "srctools/_tokenizer.pyx":110
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error
 */
  /*else*/ {
    __pyx_t_4 = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;
    __Pyx_INCREF(__pyx_t_4);
    __pyx_t_2 = PyObject_IsSubclass(__pyx_v_error, __pyx_t_4); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 110, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
    if (unlikely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":111
 *         else:
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')             # <<<<<<<<<<<<<<
 *             self.error_type = error
 * 
 */
      __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = 0;
      __pyx_t_6 = 127;
      __Pyx_INCREF(__pyx_kp_u_Invalid_error_instance);
      __pyx_t_5 += 24;
      __Pyx_GIVEREF(__pyx_kp_u_Invalid_error_instance);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_kp_u_Invalid_error_instance);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)Py_TYPE(__pyx_v_error)), __pyx_n_s_name); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_3, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_6) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_6;
      __pyx_t_5 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_7);
      __pyx_t_7 = 0;
      __Pyx_INCREF(__pyx_kp_u_);
      __pyx_t_5 += 2;
      __Pyx_GIVEREF(__pyx_kp_u_);
      PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_kp_u_);
      __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_4, 3, __pyx_t_5, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 111, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __PYX_ERR(0, 111, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":110
 *             self.error_type = TokenSyntaxError
 *         else:
 *             if not issubclass(error, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error
 */
    }

    /* "srctools/_tokenizer.pyx":112
 *             if not issubclass(error, TokenSyntaxError):
 *                 raise TypeError(f'Invalid error instance "{type(error).__name__}"' '!')
 *             self.error_type = error             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = self.pushback_val = None
 */
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    __Pyx_GOTREF(__pyx_v_self->error_type);
    __Pyx_DECREF(__pyx_v_self->error_type);
    __pyx_v_self->error_type = __pyx_v_error;
  }
  __pyx_L5:;

  /* "srctools/_tokenizer.pyx":114
 *             self.error_type = error
 * 
 *         self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *         self.line_num = 1
 *         self.flags = 0
 */
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = Py_None;
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = Py_None;

  /* "srctools/_tokenizer.pyx":115
 * 
 *         self.pushback_tok = self.pushback_val = None
 *         self.line_num = 1             # <<<<<<<<<<<<<<
 *         self.flags = 0
 * 
 */
  __pyx_v_self->line_num = 1;

  /* "srctools/_tokenizer.pyx":116
 *         self.pushback_tok = self.pushback_val = None
 *         self.line_num = 1
 *         self.flags = 0             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  __pyx_v_self->flags = 0;

  /* "srctools/_tokenizer.pyx":92
 *     cdef uint_fast8_t flags
 * 
 *     def __init__(self, filename, error):             # <<<<<<<<<<<<<<
 *         # Use os method to convert to string.
 *         # We know this isn't a method, so skip Cython's optimisation.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_fname);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":118
 *         self.flags = 0
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__[] = "BaseTokenizer.__reduce__(self)\nDisallow pickling Tokenizers.\n\n        The files themselves usually are not pickleable, or are very\n        large strings.\n        There is also the issue with recreating the C/Python versions.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":125
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise TypeError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 125, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":118
 *         self.flags = 0
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":128
 * 
 *     @property
 *     def filename(self):             # <<<<<<<<<<<<<<
 *         """Retrieve the filename used in error messages."""
 *         return self.filename
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":130
 *     def filename(self):
 *         """Retrieve the filename used in error messages."""
 *         return self.filename             # <<<<<<<<<<<<<<
 * 
 *     @filename.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->filename);
  __pyx_r = __pyx_v_self->filename;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":128
 * 
 *     @property
 *     def filename(self):             # <<<<<<<<<<<<<<
 *         """Retrieve the filename used in error messages."""
 *         return self.filename
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":133
 * 
 *     @filename.setter
 *     def filename(self, fname):             # <<<<<<<<<<<<<<
 *         """Change the filename used in error messages."""
 *         if fname is None:
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_fname); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_fname) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_fname));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8filename_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_fname) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_fname);

  /* "srctools/_tokenizer.pyx":135
 *     def filename(self, fname):
 *         """Change the filename used in error messages."""
 *         if fname is None:             # <<<<<<<<<<<<<<
 *             self.filename = None
 *         else:
 */
  __pyx_t_1 = (__pyx_v_fname == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":136
 *         """Change the filename used in error messages."""
 *         if fname is None:
 *             self.filename = None             # <<<<<<<<<<<<<<
 *         else:
 *             with cython.optimize.unpack_method_calls(False):
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->filename);
    __Pyx_DECREF(__pyx_v_self->filename);
    __pyx_v_self->filename = ((PyObject*)Py_None);

    /* "srctools/_tokenizer.pyx":135
 *     def filename(self, fname):
 *         """Change the filename used in error messages."""
 *         if fname is None:             # <<<<<<<<<<<<<<
 *             self.filename = None
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":138
 *             self.filename = None
 *         else:
 *             with cython.optimize.unpack_method_calls(False):             # <<<<<<<<<<<<<<
 *                 fname = os_fspath(fname)
 *             if isinstance(fname, bytes):
 */
  /*else*/ {

    /* "srctools/_tokenizer.pyx":139
 *         else:
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(fname)             # <<<<<<<<<<<<<<
 *             if isinstance(fname, bytes):
 *                 # We only use this for display, so if bytes convert.
 */
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_v_8srctools_10_tokenizer_os_fspath, __pyx_v_fname); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 139, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF_SET(__pyx_v_fname, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":140
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(fname)
 *             if isinstance(fname, bytes):             # <<<<<<<<<<<<<<
 *                 # We only use this for display, so if bytes convert.
 *                 # Call repr() then strip the b'', so we get the
 */
    __pyx_t_2 = PyBytes_Check(__pyx_v_fname); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "srctools/_tokenizer.pyx":144
 *                 # Call repr() then strip the b'', so we get the
 *                 # automatic escaping of unprintable characters.
 *                 fname = (<str> repr(fname))[2:-1]             # <<<<<<<<<<<<<<
 *             self.filename = str(fname)
 * 
 */
      __pyx_t_3 = PyObject_Repr(__pyx_v_fname); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 144, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      if (unlikely(__pyx_t_3 == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 144, __pyx_L1_error)
      }
      __pyx_t_4 = __Pyx_PyUnicode_Substring(((PyObject*)__pyx_t_3), 2, -1L); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 144, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_fname, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":140
 *             with cython.optimize.unpack_method_calls(False):
 *                 fname = os_fspath(fname)
 *             if isinstance(fname, bytes):             # <<<<<<<<<<<<<<
 *                 # We only use this for display, so if bytes convert.
 *                 # Call repr() then strip the b'', so we get the
 */
    }

    /* "srctools/_tokenizer.pyx":145
 *                 # automatic escaping of unprintable characters.
 *                 fname = (<str> repr(fname))[2:-1]
 *             self.filename = str(fname)             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
    __pyx_t_4 = __Pyx_PyObject_CallOneArg(((PyObject *)(&PyUnicode_Type)), __pyx_v_fname); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 145, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __Pyx_GOTREF(__pyx_v_self->filename);
    __Pyx_DECREF(__pyx_v_self->filename);
    __pyx_v_self->filename = ((PyObject*)__pyx_t_4);
    __pyx_t_4 = 0;
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":133
 * 
 *     @filename.setter
 *     def filename(self, fname):             # <<<<<<<<<<<<<<
 *         """Change the filename used in error messages."""
 *         if fname is None:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.filename.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_fname);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":148
 * 
 *     @property
 *     def error_type(self):             # <<<<<<<<<<<<<<
 *         """Return the TokenSyntaxError subclass raised when errors occur."""
 *         return self.error_type
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type___get__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":150
 *     def error_type(self):
 *         """Return the TokenSyntaxError subclass raised when errors occur."""
 *         return self.error_type             # <<<<<<<<<<<<<<
 * 
 *     @error_type.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->error_type);
  __pyx_r = __pyx_v_self->error_type;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":148
 * 
 *     @property
 *     def error_type(self):             # <<<<<<<<<<<<<<
 *         """Return the TokenSyntaxError subclass raised when errors occur."""
 *         return self.error_type
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":153
 * 
 *     @error_type.setter
 *     def error_type(self, value):             # <<<<<<<<<<<<<<
 *         """Alter the TokenSyntaxError subclass raised when errors occur."""
 *         if not issubclass(value, TokenSyntaxError):
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10error_type_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "srctools/_tokenizer.pyx":155
 *     def error_type(self, value):
 *         """Alter the TokenSyntaxError subclass raised when errors occur."""
 *         if not issubclass(value, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *             raise TypeError(f'The error type must be a TokenSyntaxError subclass, not {type(value).__name__}!.')
 *         self.error_type = value
 */
  __pyx_t_1 = __pyx_v_8srctools_10_tokenizer_TokenSyntaxError;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyObject_IsSubclass(__pyx_v_value, __pyx_t_1); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 155, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = ((!(__pyx_t_2 != 0)) != 0);
  if (unlikely(__pyx_t_3)) {

    /* "srctools/_tokenizer.pyx":156
 *         """Alter the TokenSyntaxError subclass raised when errors occur."""
 *         if not issubclass(value, TokenSyntaxError):
 *             raise TypeError(f'The error type must be a TokenSyntaxError subclass, not {type(value).__name__}!.')             # <<<<<<<<<<<<<<
 *         self.error_type = value
 * 
 */
    __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_The_error_type_must_be_a_TokenSy);
    __pyx_t_4 += 56;
    __Pyx_GIVEREF(__pyx_kp_u_The_error_type_must_be_a_TokenSy);
    PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_The_error_type_must_be_a_TokenSy);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)Py_TYPE(__pyx_v_value)), __pyx_n_s_name); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_6, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
    __Pyx_GIVEREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_7);
    __pyx_t_7 = 0;
    __Pyx_INCREF(__pyx_kp_u__3);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__3);
    PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__3);
    __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 156, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 156, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":155
 *     def error_type(self, value):
 *         """Alter the TokenSyntaxError subclass raised when errors occur."""
 *         if not issubclass(value, TokenSyntaxError):             # <<<<<<<<<<<<<<
 *             raise TypeError(f'The error type must be a TokenSyntaxError subclass, not {type(value).__name__}!.')
 *         self.error_type = value
 */
  }

  /* "srctools/_tokenizer.pyx":157
 *         if not issubclass(value, TokenSyntaxError):
 *             raise TypeError(f'The error type must be a TokenSyntaxError subclass, not {type(value).__name__}!.')
 *         self.error_type = value             # <<<<<<<<<<<<<<
 * 
 *     def error(self, message, *args):
 */
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->error_type);
  __Pyx_DECREF(__pyx_v_self->error_type);
  __pyx_v_self->error_type = __pyx_v_value;

  /* "srctools/_tokenizer.pyx":153
 * 
 *     @error_type.setter
 *     def error_type(self, value):             # <<<<<<<<<<<<<<
 *         """Alter the TokenSyntaxError subclass raised when errors occur."""
 *         if not issubclass(value, TokenSyntaxError):
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.error_type.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":159
 *         self.error_type = value
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error[] = "BaseTokenizer.error(self, message, *args)\nRaise a syntax error exception.\n\n        This returns the TokenSyntaxError instance, with\n        line number and filename attributes filled in.\n        Either pass a token and optionally the value to give a generic message,\n        or a string which will be {}-formatted with the positional args\n        if they are present.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_5error = {"error", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_message = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("error (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 1) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 1, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return NULL;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_message,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_message)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t used_pos_args = (pos_args < 1) ? pos_args : 1;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, used_pos_args, "error") < 0)) __PYX_ERR(0, 159, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_message = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("error", 0, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 159, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_message, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_4error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_tok_val = 0;
  PyObject *__pyx_v_str_msg = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  Py_ssize_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("error", 0);

  /* "srctools/_tokenizer.pyx":169
 *         """
 *         cdef str tok_val, str_msg
 *         if type(message) is Token:  # We know no subclasses exist..             # <<<<<<<<<<<<<<
 *             if len(args) > 1:
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 */
  __pyx_t_1 = (((PyObject *)Py_TYPE(__pyx_v_message)) == __pyx_v_8srctools_10_tokenizer_Token);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":170
 *         cdef str tok_val, str_msg
 *         if type(message) is Token:  # We know no subclasses exist..
 *             if len(args) > 1:             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 170, __pyx_L1_error)
    __pyx_t_2 = ((__pyx_t_3 > 1) != 0);
    if (unlikely(__pyx_t_2)) {

      /* "srctools/_tokenizer.pyx":171
 *         if type(message) is Token:  # We know no subclasses exist..
 *             if len(args) > 1:
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')             # <<<<<<<<<<<<<<
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):
 *                 tok_val = <str?>args[0]
 */
      __pyx_t_4 = PyTuple_New(4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = 0;
      __pyx_t_5 = 127;
      __Pyx_INCREF(__pyx_kp_u_Token);
      __pyx_t_3 += 6;
      __Pyx_GIVEREF(__pyx_kp_u_Token);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_kp_u_Token);
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_name_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_t_6, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
      __pyx_t_3 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_7);
      __pyx_t_7 = 0;
      __Pyx_INCREF(__pyx_kp_u_passed_with_multiple_values);
      __pyx_t_3 += 30;
      __Pyx_GIVEREF(__pyx_kp_u_passed_with_multiple_values);
      PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_kp_u_passed_with_multiple_values);
      __pyx_t_7 = __Pyx_PyObject_FormatSimple(__pyx_v_args, __pyx_empty_unicode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_5;
      __pyx_t_3 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_4, 3, __pyx_t_7);
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_4, 4, __pyx_t_3, __pyx_t_5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 171, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __PYX_ERR(0, 171, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":170
 *         cdef str tok_val, str_msg
 *         if type(message) is Token:  # We know no subclasses exist..
 *             if len(args) > 1:             # <<<<<<<<<<<<<<
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):
 */
    }

    /* "srctools/_tokenizer.pyx":172
 *             if len(args) > 1:
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):             # <<<<<<<<<<<<<<
 *                 tok_val = <str?>args[0]
 *                 str_msg = f'Unexpected token {message.name}({tok_val})!'
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 172, __pyx_L1_error)
    __pyx_t_1 = ((__pyx_t_3 == 1) != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_v_message == __pyx_v_8srctools_10_tokenizer_STRING);
    __pyx_t_8 = (__pyx_t_1 != 0);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_2 = __pyx_t_8;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_message == __pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
    __pyx_t_1 = (__pyx_t_8 != 0);
    if (!__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_v_message == __pyx_v_8srctools_10_tokenizer_PROP_FLAG);
    __pyx_t_8 = (__pyx_t_1 != 0);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_2 = __pyx_t_8;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_message == __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
    __pyx_t_1 = (__pyx_t_8 != 0);
    __pyx_t_2 = __pyx_t_1;
    __pyx_L6_bool_binop_done:;
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":173
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):
 *                 tok_val = <str?>args[0]             # <<<<<<<<<<<<<<
 *                 str_msg = f'Unexpected token {message.name}({tok_val})!'
 *             else:
 */
      __pyx_t_4 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 173, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      if (!(likely(PyUnicode_CheckExact(__pyx_t_4))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(0, 173, __pyx_L1_error)
      __pyx_t_7 = __pyx_t_4;
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_v_tok_val = ((PyObject*)__pyx_t_7);
      __pyx_t_7 = 0;

      /* "srctools/_tokenizer.pyx":174
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):
 *                 tok_val = <str?>args[0]
 *                 str_msg = f'Unexpected token {message.name}({tok_val})!'             # <<<<<<<<<<<<<<
 *             else:
 *                 str_msg = f'Unexpected token {message.name}' '!'
 */
      __pyx_t_7 = PyTuple_New(5); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_3 = 0;
      __pyx_t_5 = 127;
      __Pyx_INCREF(__pyx_kp_u_Unexpected_token);
      __pyx_t_3 += 17;
      __Pyx_GIVEREF(__pyx_kp_u_Unexpected_token);
      PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_kp_u_Unexpected_token);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_name_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_6 = __Pyx_PyObject_FormatSimple(__pyx_t_4, __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
      __pyx_t_3 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_t_6);
      __pyx_t_6 = 0;
      __Pyx_INCREF(__pyx_kp_u__4);
      __pyx_t_3 += 1;
      __Pyx_GIVEREF(__pyx_kp_u__4);
      PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_kp_u__4);
      __pyx_t_6 = __Pyx_PyUnicode_Unicode(__pyx_v_tok_val); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
      __pyx_t_3 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_7, 3, __pyx_t_6);
      __pyx_t_6 = 0;
      __Pyx_INCREF(__pyx_kp_u__5);
      __pyx_t_3 += 2;
      __Pyx_GIVEREF(__pyx_kp_u__5);
      PyTuple_SET_ITEM(__pyx_t_7, 4, __pyx_kp_u__5);
      __pyx_t_6 = __Pyx_PyUnicode_Join(__pyx_t_7, 5, __pyx_t_3, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 174, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_v_str_msg = ((PyObject*)__pyx_t_6);
      __pyx_t_6 = 0;

      /* "srctools/_tokenizer.pyx":172
 *             if len(args) > 1:
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 *             if len(args) == 1 and (message is STRING or message is PAREN_ARGS or message is PROP_FLAG or message is DIRECTIVE):             # <<<<<<<<<<<<<<
 *                 tok_val = <str?>args[0]
 *                 str_msg = f'Unexpected token {message.name}({tok_val})!'
 */
      goto __pyx_L5;
    }

    /* "srctools/_tokenizer.pyx":176
 *                 str_msg = f'Unexpected token {message.name}({tok_val})!'
 *             else:
 *                 str_msg = f'Unexpected token {message.name}' '!'             # <<<<<<<<<<<<<<
 *         elif args:
 *             str_msg = message.format(*args)
 */
    /*else*/ {
      __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 176, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_3 = 0;
      __pyx_t_5 = 127;
      __Pyx_INCREF(__pyx_kp_u_Unexpected_token);
      __pyx_t_3 += 17;
      __Pyx_GIVEREF(__pyx_kp_u_Unexpected_token);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_kp_u_Unexpected_token);
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_name_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 176, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_4 = __Pyx_PyObject_FormatSimple(__pyx_t_7, __pyx_empty_unicode); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 176, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) : __pyx_t_5;
      __pyx_t_3 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_4);
      __pyx_t_4 = 0;
      __Pyx_INCREF(__pyx_kp_u__6);
      __pyx_t_3 += 1;
      __Pyx_GIVEREF(__pyx_kp_u__6);
      PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_kp_u__6);
      __pyx_t_4 = __Pyx_PyUnicode_Join(__pyx_t_6, 3, __pyx_t_3, __pyx_t_5); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 176, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_v_str_msg = ((PyObject*)__pyx_t_4);
      __pyx_t_4 = 0;
    }
    __pyx_L5:;

    /* "srctools/_tokenizer.pyx":169
 *         """
 *         cdef str tok_val, str_msg
 *         if type(message) is Token:  # We know no subclasses exist..             # <<<<<<<<<<<<<<
 *             if len(args) > 1:
 *                 raise TypeError(f'Token {message.name} passed with multiple values: {args}')
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":177
 *             else:
 *                 str_msg = f'Unexpected token {message.name}' '!'
 *         elif args:             # <<<<<<<<<<<<<<
 *             str_msg = message.format(*args)
 *         else:
 */
  __pyx_t_2 = (PyTuple_GET_SIZE(__pyx_v_args) != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":178
 *                 str_msg = f'Unexpected token {message.name}' '!'
 *         elif args:
 *             str_msg = message.format(*args)             # <<<<<<<<<<<<<<
 *         else:
 *             str_msg = message
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_message, __pyx_n_s_format); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 178, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_v_args, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 178, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (!(likely(PyUnicode_CheckExact(__pyx_t_6))||((__pyx_t_6) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_t_6)->tp_name), 0))) __PYX_ERR(0, 178, __pyx_L1_error)
    __pyx_v_str_msg = ((PyObject*)__pyx_t_6);
    __pyx_t_6 = 0;

    /* "srctools/_tokenizer.pyx":177
 *             else:
 *                 str_msg = f'Unexpected token {message.name}' '!'
 *         elif args:             # <<<<<<<<<<<<<<
 *             str_msg = message.format(*args)
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":180
 *             str_msg = message.format(*args)
 *         else:
 *             str_msg = message             # <<<<<<<<<<<<<<
 *         return self._error(str_msg)
 * 
 */
  /*else*/ {
    if (!(likely(PyUnicode_CheckExact(__pyx_v_message))||((__pyx_v_message) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_message)->tp_name), 0))) __PYX_ERR(0, 180, __pyx_L1_error)
    __pyx_t_6 = __pyx_v_message;
    __Pyx_INCREF(__pyx_t_6);
    __pyx_v_str_msg = ((PyObject*)__pyx_t_6);
    __pyx_t_6 = 0;
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":181
 *         else:
 *             str_msg = message
 *         return self._error(str_msg)             # <<<<<<<<<<<<<<
 * 
 *     # Don't unpack, error_type should be a class.
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self, __pyx_v_str_msg); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_r = __pyx_t_6;
  __pyx_t_6 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":159
 *         self.error_type = value
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_val);
  __Pyx_XDECREF(__pyx_v_str_msg);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":185
 *     # Don't unpack, error_type should be a class.
 *     @cython.optimize.unpack_method_calls(False)
 *     cdef inline _error(self, message: str):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

static CYTHON_INLINE PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_message) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_error", 0);

  /* "srctools/_tokenizer.pyx":187
 *     cdef inline _error(self, message: str):
 *         """C-private self.error()."""
 *         return self.error_type(             # <<<<<<<<<<<<<<
 *             message,
 *             self.filename,
 */
  __Pyx_XDECREF(__pyx_r);

  /* "srctools/_tokenizer.pyx":190
 *             message,
 *             self.filename,
 *             self.line_num,             # <<<<<<<<<<<<<<
 *         )
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);

  /* "srctools/_tokenizer.pyx":187
 *     cdef inline _error(self, message: str):
 *         """C-private self.error()."""
 *         return self.error_type(             # <<<<<<<<<<<<<<
 *             message,
 *             self.filename,
 */
  __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_message);
  __Pyx_GIVEREF(__pyx_v_message);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_message);
  __Pyx_INCREF(__pyx_v_self->filename);
  __Pyx_GIVEREF(__pyx_v_self->filename);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_v_self->filename);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_v_self->error_type, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":185
 *     # Don't unpack, error_type should be a class.
 *     @cython.optimize.unpack_method_calls(False)
 *     cdef inline _error(self, message: str):             # <<<<<<<<<<<<<<
 *         """C-private self.error()."""
 *         return self.error_type(
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer._error", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":193
 *         )
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_6__call__[] = "Return the next token, value pair.";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
#endif
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__call__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__call__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__call__", 0))) return NULL;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_6__call__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__call__", 0);

  /* "srctools/_tokenizer.pyx":195
 *     def __call__(self):
 *         """Return the next token, value pair."""
 *         return self.next_token()             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":193
 *         )
 * 
 *     def __call__(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair."""
 *         return self.next_token()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":197
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Call the Python-overridable method.
 * 
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_v_output = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":202
 *         This also implements pushback.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  __pyx_t_1 = (__pyx_v_self->pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":203
 *         """
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val             # <<<<<<<<<<<<<<
 *             self.pushback_tok = self.pushback_val = None
 *             return output
 */
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 203, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_self->pushback_tok);
    __Pyx_GIVEREF(__pyx_v_self->pushback_tok);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_self->pushback_tok);
    __Pyx_INCREF(__pyx_v_self->pushback_val);
    __Pyx_GIVEREF(__pyx_v_self->pushback_val);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_self->pushback_val);
    __pyx_v_output = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":204
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *             return output
 * 
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->pushback_tok);
    __Pyx_DECREF(__pyx_v_self->pushback_tok);
    __pyx_v_self->pushback_tok = Py_None;
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->pushback_val);
    __Pyx_DECREF(__pyx_v_self->pushback_val);
    __pyx_v_self->pushback_val = Py_None;

    /* "srctools/_tokenizer.pyx":205
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 *             return output             # <<<<<<<<<<<<<<
 * 
 *         return self._get_token()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_output);
    __pyx_r = __pyx_v_output;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":202
 *         This also implements pushback.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  }

  /* "srctools/_tokenizer.pyx":207
 *             return output
 * 
 *         return self._get_token()             # <<<<<<<<<<<<<<
 * 
 *     def _get_token(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get_token); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_4, function);
    }
  }
  __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5) : __Pyx_PyObject_CallNoArg(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":197
 *         return self.next_token()
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Call the Python-overridable method.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_output);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":209
 *         return self._get_token()
 * 
 *     def _get_token(self):             # <<<<<<<<<<<<<<
 *         """Compute the next token, must be implemented by subclasses."""
 *         raise NotImplementedError
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9_get_token(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_8_get_token[] = "BaseTokenizer._get_token(self)\nCompute the next token, must be implemented by subclasses.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_9_get_token = {"_get_token", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9_get_token, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_8_get_token};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9_get_token(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_get_token (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8_get_token(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8_get_token(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_get_token", 0);

  /* "srctools/_tokenizer.pyx":211
 *     def _get_token(self):
 *         """Compute the next token, must be implemented by subclasses."""
 *         raise NotImplementedError             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __Pyx_Raise(__pyx_builtin_NotImplementedError, 0, 0, 0);
  __PYX_ERR(0, 211, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":209
 *         return self._get_token()
 * 
 *     def _get_token(self):             # <<<<<<<<<<<<<<
 *         """Compute the next token, must be implemented by subclasses."""
 *         raise NotImplementedError
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer._get_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":213
 *         raise NotImplementedError
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         """Tokenizers are their own iterator."""
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11__iter__(PyObject *__pyx_v_self); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_10__iter__[] = "Tokenizers are their own iterator.";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_10__iter__;
#endif
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10__iter__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_10__iter__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":215
 *     def __iter__(self):
 *         """Tokenizers are their own iterator."""
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":213
 *         raise NotImplementedError
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         """Tokenizers are their own iterator."""
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":217
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         """Iterate to produce a token, stopping at EOF."""
 *         tok_and_val = self.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__(PyObject *__pyx_v_self); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12__next__[] = "Iterate to produce a token, stopping at EOF.";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_12__next__;
#endif
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12__next__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_12__next__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":219
 *     def __next__(self):
 *         """Iterate to produce a token, stopping at EOF."""
 *         tok_and_val = self.next_token()             # <<<<<<<<<<<<<<
 *         if (<tuple?> tok_and_val)[0] is EOF:
 *             raise StopIteration
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_tok_and_val = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":220
 *         """Iterate to produce a token, stopping at EOF."""
 *         tok_and_val = self.next_token()
 *         if (<tuple?> tok_and_val)[0] is EOF:             # <<<<<<<<<<<<<<
 *             raise StopIteration
 *         return tok_and_val
 */
  if (!(likely(PyTuple_CheckExact(__pyx_v_tok_and_val))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v_tok_and_val)->tp_name), 0))) __PYX_ERR(0, 220, __pyx_L1_error)
  if (unlikely(__pyx_v_tok_and_val == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 220, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(((PyObject*)__pyx_v_tok_and_val), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 220, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__pyx_t_1 == __pyx_v_8srctools_10_tokenizer_EOF);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (unlikely(__pyx_t_3)) {

    /* "srctools/_tokenizer.pyx":221
 *         tok_and_val = self.next_token()
 *         if (<tuple?> tok_and_val)[0] is EOF:
 *             raise StopIteration             # <<<<<<<<<<<<<<
 *         return tok_and_val
 * 
 */
    __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
    __PYX_ERR(0, 221, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":220
 *         """Iterate to produce a token, stopping at EOF."""
 *         tok_and_val = self.next_token()
 *         if (<tuple?> tok_and_val)[0] is EOF:             # <<<<<<<<<<<<<<
 *             raise StopIteration
 *         return tok_and_val
 */
  }

  /* "srctools/_tokenizer.pyx":222
 *         if (<tuple?> tok_and_val)[0] is EOF:
 *             raise StopIteration
 *         return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def push_back(self, object tok not None, str value=None):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tok_and_val);
  __pyx_r = __pyx_v_tok_and_val;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":217
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         """Iterate to produce a token, stopping at EOF."""
 *         tok_and_val = self.next_token()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":224
 *         return tok_and_val
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14push_back[] = "BaseTokenizer.push_back(self, tok, unicode value=None)\nReturn a token, so it will be reproduced when called again.\n\n        Only one token can be pushed back at once.\n        The value is required for STRING, PAREN_ARGS and PROP_FLAGS, but ignored\n        for other token types.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_15push_back = {"push_back", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15push_back, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14push_back};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15push_back(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_tok = 0;
  PyObject *__pyx_v_value = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("push_back (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject*)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_value);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "push_back") < 0)) __PYX_ERR(0, 224, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_tok = values[0];
    __pyx_v_value = ((PyObject*)values[1]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("push_back", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 224, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_tok) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "tok"); __PYX_ERR(0, 224, __pyx_L1_error)
  }
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_value), (&PyUnicode_Type), 1, "value", 1))) __PYX_ERR(0, 224, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14push_back(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_tok, __pyx_v_value);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_14push_back(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_tok, PyObject *__pyx_v_value) {
  int __pyx_v_tok_val;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  Py_UCS4 __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("push_back", 0);
  __Pyx_INCREF(__pyx_v_value);

  /* "srctools/_tokenizer.pyx":231
 *         for other token types.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  __pyx_t_1 = (__pyx_v_self->pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (unlikely(__pyx_t_2)) {

    /* "srctools/_tokenizer.pyx":232
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(f'{tok!r} is not a Token!')
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 232, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 232, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":231
 *         for other token types.
 *         """
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 */
  }

  /* "srctools/_tokenizer.pyx":233
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(f'{tok!r} is not a Token!')
 * 
 */
  __pyx_t_3 = __pyx_v_8srctools_10_tokenizer_Token;
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_2 = PyObject_IsInstance(__pyx_v_tok, __pyx_t_3); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 233, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = ((!(__pyx_t_2 != 0)) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":234
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):
 *             raise ValueError(f'{tok!r} is not a Token!')             # <<<<<<<<<<<<<<
 * 
 *         # Read this directly to skip the 'value' descriptor.
 */
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_tok), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 234, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyUnicode_Concat(__pyx_t_3, __pyx_kp_u_is_not_a_Token); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 234, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 234, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 234, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":233
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')
 *         if not isinstance(tok, Token):             # <<<<<<<<<<<<<<
 *             raise ValueError(f'{tok!r} is not a Token!')
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":237
 * 
 *         # Read this directly to skip the 'value' descriptor.
 *         cdef int tok_val = tok._value_             # <<<<<<<<<<<<<<
 * 
 *         if tok_val == 0: # EOF
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_tok, __pyx_n_s_value_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 237, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 237, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_tok_val = __pyx_t_5;

  /* "srctools/_tokenizer.pyx":239
 *         cdef int tok_val = tok._value_
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             value = ''
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG
 */
  switch (__pyx_v_tok_val) {
    case 0:

    /* "srctools/_tokenizer.pyx":240
 * 
 *         if tok_val == 0: # EOF
 *             value = ''             # <<<<<<<<<<<<<<
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG
 *             # Value parameter is required.
 */
    __Pyx_INCREF(__pyx_kp_u__8);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__8);

    /* "srctools/_tokenizer.pyx":239
 *         cdef int tok_val = tok._value_
 * 
 *         if tok_val == 0: # EOF             # <<<<<<<<<<<<<<
 *             value = ''
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG
 */
    break;
    case 1:

    /* "srctools/_tokenizer.pyx":241
 *         if tok_val == 0: # EOF
 *             value = ''
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG             # <<<<<<<<<<<<<<
 *             # Value parameter is required.
 *             if value is None:
 */
    case 3:
    case 4:
    case 10:

    /* "srctools/_tokenizer.pyx":243
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG
 *             # Value parameter is required.
 *             if value is None:             # <<<<<<<<<<<<<<
 *                 raise ValueError(f'Value required for {tok!r}' '!')
 *         elif tok_val == 2:  # NEWLINE
 */
    __pyx_t_1 = (__pyx_v_value == ((PyObject*)Py_None));
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (unlikely(__pyx_t_2)) {

      /* "srctools/_tokenizer.pyx":244
 *             # Value parameter is required.
 *             if value is None:
 *                 raise ValueError(f'Value required for {tok!r}' '!')             # <<<<<<<<<<<<<<
 *         elif tok_val == 2:  # NEWLINE
 *             value = '\n'
 */
      __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = 0;
      __pyx_t_7 = 127;
      __Pyx_INCREF(__pyx_kp_u_Value_required_for);
      __pyx_t_6 += 19;
      __Pyx_GIVEREF(__pyx_kp_u_Value_required_for);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Value_required_for);
      __pyx_t_4 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_tok), __pyx_empty_unicode); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_7 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) > __pyx_t_7) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_4) : __pyx_t_7;
      __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_4);
      __pyx_t_4 = 0;
      __Pyx_INCREF(__pyx_kp_u__6);
      __pyx_t_6 += 1;
      __Pyx_GIVEREF(__pyx_kp_u__6);
      PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__6);
      __pyx_t_4 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 244, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 244, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":243
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG
 *             # Value parameter is required.
 *             if value is None:             # <<<<<<<<<<<<<<
 *                 raise ValueError(f'Value required for {tok!r}' '!')
 *         elif tok_val == 2:  # NEWLINE
 */
    }

    /* "srctools/_tokenizer.pyx":241
 *         if tok_val == 0: # EOF
 *             value = ''
 *         elif tok_val in (1, 3, 4, 10):  # STRING, PAREN_ARGS, DIRECTIVE, PROP_FLAG             # <<<<<<<<<<<<<<
 *             # Value parameter is required.
 *             if value is None:
 */
    break;
    case 2:

    /* "srctools/_tokenizer.pyx":246
 *                 raise ValueError(f'Value required for {tok!r}' '!')
 *         elif tok_val == 2:  # NEWLINE
 *             value = '\n'             # <<<<<<<<<<<<<<
 *         elif tok_val == 5:  # BRACE_OPEN
 *             value = '{'
 */
    __Pyx_INCREF(__pyx_kp_u__9);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__9);

    /* "srctools/_tokenizer.pyx":245
 *             if value is None:
 *                 raise ValueError(f'Value required for {tok!r}' '!')
 *         elif tok_val == 2:  # NEWLINE             # <<<<<<<<<<<<<<
 *             value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN
 */
    break;
    case 5:

    /* "srctools/_tokenizer.pyx":248
 *             value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN
 *             value = '{'             # <<<<<<<<<<<<<<
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             value = '}'
 */
    __Pyx_INCREF(__pyx_kp_u__10);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__10);

    /* "srctools/_tokenizer.pyx":247
 *         elif tok_val == 2:  # NEWLINE
 *             value = '\n'
 *         elif tok_val == 5:  # BRACE_OPEN             # <<<<<<<<<<<<<<
 *             value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE
 */
    break;
    case 6:

    /* "srctools/_tokenizer.pyx":250
 *             value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             value = '}'             # <<<<<<<<<<<<<<
 *         elif tok_val == 11:  # BRACK_OPEN
 *             value = '['
 */
    __Pyx_INCREF(__pyx_kp_u__11);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__11);

    /* "srctools/_tokenizer.pyx":249
 *         elif tok_val == 5:  # BRACE_OPEN
 *             value = '{'
 *         elif tok_val == 6:  # BRACE_CLOSE             # <<<<<<<<<<<<<<
 *             value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 */
    break;
    case 11:

    /* "srctools/_tokenizer.pyx":252
 *             value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN
 *             value = '['             # <<<<<<<<<<<<<<
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             value = ']'
 */
    __Pyx_INCREF(__pyx_kp_u__12);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__12);

    /* "srctools/_tokenizer.pyx":251
 *         elif tok_val == 6:  # BRACE_CLOSE
 *             value = '}'
 *         elif tok_val == 11:  # BRACK_OPEN             # <<<<<<<<<<<<<<
 *             value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 */
    break;
    case 12:

    /* "srctools/_tokenizer.pyx":254
 *             value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             value = ']'             # <<<<<<<<<<<<<<
 *         elif tok_val == 13:  # COLON
 *             value = ':'
 */
    __Pyx_INCREF(__pyx_kp_u__13);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__13);

    /* "srctools/_tokenizer.pyx":253
 *         elif tok_val == 11:  # BRACK_OPEN
 *             value = '['
 *         elif tok_val == 12:  # BRACK_CLOSE             # <<<<<<<<<<<<<<
 *             value = ']'
 *         elif tok_val == 13:  # COLON
 */
    break;
    case 13:

    /* "srctools/_tokenizer.pyx":256
 *             value = ']'
 *         elif tok_val == 13:  # COLON
 *             value = ':'             # <<<<<<<<<<<<<<
 *         elif tok_val == 14:  # EQUALS
 *             value = '='
 */
    __Pyx_INCREF(__pyx_kp_u__14);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__14);

    /* "srctools/_tokenizer.pyx":255
 *         elif tok_val == 12:  # BRACK_CLOSE
 *             value = ']'
 *         elif tok_val == 13:  # COLON             # <<<<<<<<<<<<<<
 *             value = ':'
 *         elif tok_val == 14:  # EQUALS
 */
    break;
    case 14:

    /* "srctools/_tokenizer.pyx":258
 *             value = ':'
 *         elif tok_val == 14:  # EQUALS
 *             value = '='             # <<<<<<<<<<<<<<
 *         elif tok_val == 15:  # PLUS
 *             value = '+'
 */
    __Pyx_INCREF(__pyx_kp_u__15);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__15);

    /* "srctools/_tokenizer.pyx":257
 *         elif tok_val == 13:  # COLON
 *             value = ':'
 *         elif tok_val == 14:  # EQUALS             # <<<<<<<<<<<<<<
 *             value = '='
 *         elif tok_val == 15:  # PLUS
 */
    break;
    case 15:

    /* "srctools/_tokenizer.pyx":260
 *             value = '='
 *         elif tok_val == 15:  # PLUS
 *             value = '+'             # <<<<<<<<<<<<<<
 *         elif tok_val == 16: # COMMA
 *             value = ','
 */
    __Pyx_INCREF(__pyx_kp_u__16);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__16);

    /* "srctools/_tokenizer.pyx":259
 *         elif tok_val == 14:  # EQUALS
 *             value = '='
 *         elif tok_val == 15:  # PLUS             # <<<<<<<<<<<<<<
 *             value = '+'
 *         elif tok_val == 16: # COMMA
 */
    break;
    case 16:

    /* "srctools/_tokenizer.pyx":262
 *             value = '+'
 *         elif tok_val == 16: # COMMA
 *             value = ','             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError(f'Unknown token {tok!r}')
 */
    __Pyx_INCREF(__pyx_kp_u__17);
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_kp_u__17);

    /* "srctools/_tokenizer.pyx":261
 *         elif tok_val == 15:  # PLUS
 *             value = '+'
 *         elif tok_val == 16: # COMMA             # <<<<<<<<<<<<<<
 *             value = ','
 *         else:
 */
    break;
    default:

    /* "srctools/_tokenizer.pyx":264
 *             value = ','
 *         else:
 *             raise ValueError(f'Unknown token {tok!r}')             # <<<<<<<<<<<<<<
 * 
 *         self.pushback_tok = tok
 */
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_tok), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 264, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyUnicode_Concat(__pyx_kp_u_Unknown_token, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 264, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 264, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 264, __pyx_L1_error)
    break;
  }

  /* "srctools/_tokenizer.pyx":266
 *             raise ValueError(f'Unknown token {tok!r}')
 * 
 *         self.pushback_tok = tok             # <<<<<<<<<<<<<<
 *         self.pushback_val = value
 * 
 */
  __Pyx_INCREF(__pyx_v_tok);
  __Pyx_GIVEREF(__pyx_v_tok);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":267
 * 
 *         self.pushback_tok = tok
 *         self.pushback_val = value             # <<<<<<<<<<<<<<
 * 
 *     def peek(self):
 */
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_v_value;

  /* "srctools/_tokenizer.pyx":224
 *         return tok_and_val
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.push_back", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":269
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16peek[] = "BaseTokenizer.peek(self)\nPeek at the next token, without removing it from the stream.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_17peek = {"peek", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17peek, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16peek};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17peek(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("peek (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16peek(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_16peek(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("peek", 0);

  /* "srctools/_tokenizer.pyx":273
 *         # We know this is a valid pushback value, and any existing value was
 *         # just removed. So unconditionally assign.
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         return tok_and_val
 */
  __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_t_1;
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (likely(__pyx_t_2 != Py_None)) {
    PyObject* sequence = __pyx_t_2;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 273, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_1 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_1 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 273, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 273, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 273, __pyx_L1_error)
  }
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->pushback_tok);
  __Pyx_DECREF(__pyx_v_self->pushback_tok);
  __pyx_v_self->pushback_tok = __pyx_t_1;
  __pyx_t_1 = 0;
  __Pyx_GIVEREF(__pyx_t_3);
  __Pyx_GOTREF(__pyx_v_self->pushback_val);
  __Pyx_DECREF(__pyx_v_self->pushback_val);
  __pyx_v_self->pushback_val = __pyx_t_3;
  __pyx_t_3 = 0;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_v_tok_and_val = ((PyObject*)__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":275
 *         self.pushback_tok, self.pushback_val = tok_and_val = <tuple>self.next_token()
 * 
 *         return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def skipping_newlines(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_tok_and_val);
  __pyx_r = __pyx_v_tok_and_val;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":269
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.peek", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":277
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines[] = "BaseTokenizer.skipping_newlines(self)\nIterate over the tokens, skipping newlines.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines = {"skipping_newlines", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("skipping_newlines (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("skipping_newlines", 0);

  /* "srctools/_tokenizer.pyx":279
 *     def skipping_newlines(self):
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)             # <<<<<<<<<<<<<<
 * 
 *     def block(self, str name, consume_brace=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_self));
  __pyx_t_2 = ((PyObject *)__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter), __pyx_t_1, NULL)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_GOTREF(((PyObject *)__pyx_t_2));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = ((PyObject *)__pyx_t_2);
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":277
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.skipping_newlines", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":281
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def block(self, str name, consume_brace=True):             # <<<<<<<<<<<<<<
 *         """Helper iterator for parsing keyvalue style blocks.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_21block(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_20block[] = "BaseTokenizer.block(self, unicode name, consume_brace=True)\nHelper iterator for parsing keyvalue style blocks.\n\n        This will first consume a {. Then it will skip newlines, and output\n        each string section found. When } is found it terminates, anything else\n        produces an appropriate error.\n        This is safely re-entrant, and tokens can be taken or put back as required.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_21block = {"block", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_21block, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_20block};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_21block(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_name = 0;
  PyObject *__pyx_v_consume_brace = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("block (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_name_2,&__pyx_n_s_consume_brace,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_name_2)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_consume_brace);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "block") < 0)) __PYX_ERR(0, 281, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_name = ((PyObject*)values[0]);
    __pyx_v_consume_brace = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("block", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 281, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.block", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_name), (&PyUnicode_Type), 1, "name", 1))) __PYX_ERR(0, 281, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_20block(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_name, __pyx_v_consume_brace);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_20block(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_name, PyObject *__pyx_v_consume_brace) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("block", 0);

  /* "srctools/_tokenizer.pyx":289
 *         This is safely re-entrant, and tokens can be taken or put back as required.
 *         """
 *         return BlockIter.__new__(BlockIter, self, name, consume_brace)             # <<<<<<<<<<<<<<
 * 
 *     def expect(self, object token, bint skip_newline=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_self));
  __Pyx_INCREF(__pyx_v_name);
  __Pyx_GIVEREF(__pyx_v_name);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_name);
  __Pyx_INCREF(__pyx_v_consume_brace);
  __Pyx_GIVEREF(__pyx_v_consume_brace);
  PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_v_consume_brace);
  __pyx_t_2 = ((PyObject *)__pyx_tp_new_8srctools_10_tokenizer_BlockIter(((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_BlockIter), __pyx_t_1, NULL)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 289, __pyx_L1_error)
  __Pyx_GOTREF(((PyObject *)__pyx_t_2));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = ((PyObject *)__pyx_t_2);
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":281
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def block(self, str name, consume_brace=True):             # <<<<<<<<<<<<<<
 *         """Helper iterator for parsing keyvalue style blocks.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.block", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":291
 *         return BlockIter.__new__(BlockIter, self, name, consume_brace)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_23expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_22expect[] = "BaseTokenizer.expect(self, token, bool skip_newline=True)\nConsume the next token, which should be the given type.\n\n        If it is not, this raises an error.\n        If skip_newline is true, newlines will be skipped over. This\n        does not apply if the desired token is newline.\n        ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_23expect = {"expect", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_23expect, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_22expect};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_23expect(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_token = 0;
  int __pyx_v_skip_newline;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("expect (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_token,&__pyx_n_s_skip_newline,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_token)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_skip_newline);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "expect") < 0)) __PYX_ERR(0, 291, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_token = values[0];
    if (values[1]) {
      __pyx_v_skip_newline = __Pyx_PyObject_IsTrue(values[1]); if (unlikely((__pyx_v_skip_newline == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 291, __pyx_L3_error)
    } else {
      __pyx_v_skip_newline = ((int)1);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("expect", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 291, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_22expect(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_v_token, __pyx_v_skip_newline);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_22expect(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_token, int __pyx_v_skip_newline) {
  PyObject *__pyx_v_next_token = NULL;
  PyObject *__pyx_v_value = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  Py_UCS4 __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("expect", 0);

  /* "srctools/_tokenizer.pyx":298
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  __pyx_t_1 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":299
 *         """
 *         if token is NEWLINE:
 *             skip_newline = False             # <<<<<<<<<<<<<<
 * 
 *         next_token, value = <tuple>self.next_token()
 */
    __pyx_v_skip_newline = 0;

    /* "srctools/_tokenizer.pyx":298
 *         does not apply if the desired token is newline.
 *         """
 *         if token is NEWLINE:             # <<<<<<<<<<<<<<
 *             skip_newline = False
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":301
 *             skip_newline = False
 * 
 *         next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         while skip_newline and next_token is NEWLINE:
 */
  __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __pyx_t_3;
  __Pyx_INCREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (likely(__pyx_t_4 != Py_None)) {
    PyObject* sequence = __pyx_t_4;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 301, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
    __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_5);
    #else
    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    #endif
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  } else {
    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 301, __pyx_L1_error)
  }
  __pyx_v_next_token = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_value = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "srctools/_tokenizer.pyx":303
 *         next_token, value = <tuple>self.next_token()
 * 
 *         while skip_newline and next_token is NEWLINE:             # <<<<<<<<<<<<<<
 *             next_token, value = <tuple>self.next_token()
 * 
 */
  while (1) {
    __pyx_t_1 = (__pyx_v_skip_newline != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L6_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_v_next_token == __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_6 = (__pyx_t_1 != 0);
    __pyx_t_2 = __pyx_t_6;
    __pyx_L6_bool_binop_done:;
    if (!__pyx_t_2) break;

    /* "srctools/_tokenizer.pyx":304
 * 
 *         while skip_newline and next_token is NEWLINE:
 *             next_token, value = <tuple>self.next_token()             # <<<<<<<<<<<<<<
 * 
 *         if next_token is not token:
 */
    __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->__pyx_vtab)->next_token(__pyx_v_self); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 304, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __pyx_t_4;
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (likely(__pyx_t_5 != Py_None)) {
      PyObject* sequence = __pyx_t_5;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 304, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_3);
      #else
      __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 304, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 304, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      #endif
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 304, __pyx_L1_error)
    }
    __Pyx_DECREF_SET(__pyx_v_next_token, __pyx_t_4);
    __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_value, __pyx_t_3);
    __pyx_t_3 = 0;
  }

  /* "srctools/_tokenizer.pyx":306
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value
 */
  __pyx_t_2 = (__pyx_v_next_token != __pyx_v_token);
  __pyx_t_6 = (__pyx_t_2 != 0);
  if (unlikely(__pyx_t_6)) {

    /* "srctools/_tokenizer.pyx":307
 * 
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')             # <<<<<<<<<<<<<<
 *         return value
 * 
 */
    __pyx_t_5 = PyTuple_New(5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_7 = 0;
    __pyx_t_8 = 127;
    __Pyx_INCREF(__pyx_kp_u_Expected);
    __pyx_t_7 += 9;
    __Pyx_GIVEREF(__pyx_kp_u_Expected);
    PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_kp_u_Expected);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u_but_got);
    __pyx_t_7 += 10;
    __Pyx_GIVEREF(__pyx_kp_u_but_got);
    PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_kp_u_but_got);
    __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_next_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_8) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_8;
    __pyx_t_7 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__6);
    __pyx_t_7 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__6);
    PyTuple_SET_ITEM(__pyx_t_5, 4, __pyx_kp_u__6);
    __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_5, 5, __pyx_t_7, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self, ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_5, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __PYX_ERR(0, 307, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":306
 *             next_token, value = <tuple>self.next_token()
 * 
 *         if next_token is not token:             # <<<<<<<<<<<<<<
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value
 */
  }

  /* "srctools/_tokenizer.pyx":308
 *         if next_token is not token:
 *             raise self._error(f'Expected {token}, but got {next_token}' '!')
 *         return value             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_value);
  __pyx_r = __pyx_v_value;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":291
 *         return BlockIter.__new__(BlockIter, self, name, consume_brace)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.expect", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_next_token);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":89
 *     cdef object pushback_val
 * 
 *     cdef public int line_num             # <<<<<<<<<<<<<<
 *     cdef uint_fast8_t flags
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num___get__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->line_num); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 89, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.line_num.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13BaseTokenizer_8line_num_2__set__(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__set__", 0);
  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_value); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 89, __pyx_L1_error)
  __pyx_v_self->line_num = __pyx_t_1;

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BaseTokenizer.line_num.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":336
 *     cdef Py_ssize_t chunk_size
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.buf_size = 128
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer___cinit__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":337
 * 
 *     def __cinit__(self):
 *         self.buf_size = 128             # <<<<<<<<<<<<<<
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 *         self.buf_pos = 0
 */
  __pyx_v_self->buf_size = 0x80;

  /* "srctools/_tokenizer.pyx":338
 *     def __cinit__(self):
 *         self.buf_size = 128
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))             # <<<<<<<<<<<<<<
 *         self.buf_pos = 0
 *         if self.val_buffer is NULL:
 */
  __pyx_v_self->val_buffer = ((unsigned char *)PyMem_Malloc((__pyx_v_self->buf_size * (sizeof(unsigned char)))));

  /* "srctools/_tokenizer.pyx":339
 *         self.buf_size = 128
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 *         if self.val_buffer is NULL:
 *             raise MemoryError
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":340
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 *         self.buf_pos = 0
 *         if self.val_buffer is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->val_buffer == NULL) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":341
 *         self.buf_pos = 0
 *         if self.val_buffer is NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
 */
    PyErr_NoMemory(); __PYX_ERR(0, 341, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":340
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 *         self.buf_pos = 0
 *         if self.val_buffer is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":336
 *     cdef Py_ssize_t chunk_size
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.buf_size = 128
 *         self.val_buffer = <uchar *>PyMem_Malloc(self.buf_size * sizeof(uchar))
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":343
 *             raise MemoryError
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

/* Python wrapper */
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_8srctools_10_tokenizer_9Tokenizer_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "srctools/_tokenizer.pyx":344
 * 
 *     def __dealloc__(self):
 *         PyMem_Free(self.val_buffer)             # <<<<<<<<<<<<<<
 * 
 *     def __init__(
 */
  PyMem_Free(__pyx_v_self->val_buffer);

  /* "srctools/_tokenizer.pyx":343
 *             raise MemoryError
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.val_buffer)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":346
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_data = 0;
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_v_string_bracket;
  int __pyx_v_allow_escapes;
  int __pyx_v_allow_star_comments;
  int __pyx_v_colon_operator;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_data,&__pyx_n_s_filename,&__pyx_n_s_error,&__pyx_n_s_string_bracket,&__pyx_n_s_allow_escapes,&__pyx_n_s_allow_star_comments,&__pyx_n_s_colon_operator,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};

    /* "srctools/_tokenizer.pyx":349
 *         self,
 *         data not None,
 *         object filename=None,             # <<<<<<<<<<<<<<
 *         error=None,
 *         bint string_bracket=False,
 */
    values[1] = ((PyObject *)Py_None);

    /* "srctools/_tokenizer.pyx":350
 *         data not None,
 *         object filename=None,
 *         error=None,             # <<<<<<<<<<<<<<
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 */
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_data)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_string_bracket);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_escapes);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allow_star_comments);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_colon_operator);
          if (value) { values[6] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 346, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_data = values[0];
    __pyx_v_filename = values[1];
    __pyx_v_error = values[2];
    if (values[3]) {
      __pyx_v_string_bracket = __Pyx_PyObject_IsTrue(values[3]); if (unlikely((__pyx_v_string_bracket == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 351, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":351
 *         object filename=None,
 *         error=None,
 *         bint string_bracket=False,             # <<<<<<<<<<<<<<
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,
 */
      __pyx_v_string_bracket = ((int)0);
    }
    if (values[4]) {
      __pyx_v_allow_escapes = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allow_escapes == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 352, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":352
 *         error=None,
 *         bint string_bracket=False,
 *         bint allow_escapes=True,             # <<<<<<<<<<<<<<
 *         bint allow_star_comments=False,
 *         bint colon_operator=False,
 */
      __pyx_v_allow_escapes = ((int)1);
    }
    if (values[5]) {
      __pyx_v_allow_star_comments = __Pyx_PyObject_IsTrue(values[5]); if (unlikely((__pyx_v_allow_star_comments == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 353, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":353
 *         bint string_bracket=False,
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,             # <<<<<<<<<<<<<<
 *         bint colon_operator=False,
 *     ):
 */
      __pyx_v_allow_star_comments = ((int)0);
    }
    if (values[6]) {
      __pyx_v_colon_operator = __Pyx_PyObject_IsTrue(values[6]); if (unlikely((__pyx_v_colon_operator == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 354, __pyx_L3_error)
    } else {

      /* "srctools/_tokenizer.pyx":354
 *         bint allow_escapes=True,
 *         bint allow_star_comments=False,
 *         bint colon_operator=False,             # <<<<<<<<<<<<<<
 *     ):
 *         # Early warning for this particular error.
 */
      __pyx_v_colon_operator = ((int)0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 346, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(((PyObject *)__pyx_v_data) == Py_None)) {
    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "data"); __PYX_ERR(0, 348, __pyx_L1_error)
  }
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), __pyx_v_data, __pyx_v_filename, __pyx_v_error, __pyx_v_string_bracket, __pyx_v_allow_escapes, __pyx_v_allow_star_comments, __pyx_v_colon_operator);

  /* "srctools/_tokenizer.pyx":346
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_4__init__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, PyObject *__pyx_v_data, PyObject *__pyx_v_filename, PyObject *__pyx_v_error, int __pyx_v_string_bracket, int __pyx_v_allow_escapes, int __pyx_v_allow_star_comments, int __pyx_v_colon_operator) {
  int __pyx_v_flags;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  unsigned char const *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  unsigned char __pyx_t_13;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);
  __Pyx_INCREF(__pyx_v_filename);

  /* "srctools/_tokenizer.pyx":357
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise TypeError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_data); 
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = PyByteArray_Check(__pyx_v_data); 
  __pyx_t_2 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":358
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise TypeError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__18, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 358, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 358, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":357
 *     ):
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):             # <<<<<<<<<<<<<<
 *             raise TypeError(
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 */
  }

  /* "srctools/_tokenizer.pyx":363
 *             )
 * 
 *         cdef int flags = 0             # <<<<<<<<<<<<<<
 *         if string_bracket:
 *             flags |= FL_STRING_BRACKETS
 */
  __pyx_v_flags = 0;

  /* "srctools/_tokenizer.pyx":364
 * 
 *         cdef int flags = 0
 *         if string_bracket:             # <<<<<<<<<<<<<<
 *             flags |= FL_STRING_BRACKETS
 *         if allow_escapes:
 */
  __pyx_t_1 = (__pyx_v_string_bracket != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":365
 *         cdef int flags = 0
 *         if string_bracket:
 *             flags |= FL_STRING_BRACKETS             # <<<<<<<<<<<<<<
 *         if allow_escapes:
 *             flags |= FL_ALLOW_ESCAPES
 */
    __pyx_v_flags = (__pyx_v_flags | 1);

    /* "srctools/_tokenizer.pyx":364
 * 
 *         cdef int flags = 0
 *         if string_bracket:             # <<<<<<<<<<<<<<
 *             flags |= FL_STRING_BRACKETS
 *         if allow_escapes:
 */
  }

  /* "srctools/_tokenizer.pyx":366
 *         if string_bracket:
 *             flags |= FL_STRING_BRACKETS
 *         if allow_escapes:             # <<<<<<<<<<<<<<
 *             flags |= FL_ALLOW_ESCAPES
 *         if allow_star_comments:
 */
  __pyx_t_1 = (__pyx_v_allow_escapes != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":367
 *             flags |= FL_STRING_BRACKETS
 *         if allow_escapes:
 *             flags |= FL_ALLOW_ESCAPES             # <<<<<<<<<<<<<<
 *         if allow_star_comments:
 *             flags |= FL_ALLOW_STAR_COMMENTS
 */
    __pyx_v_flags = (__pyx_v_flags | 2);

    /* "srctools/_tokenizer.pyx":366
 *         if string_bracket:
 *             flags |= FL_STRING_BRACKETS
 *         if allow_escapes:             # <<<<<<<<<<<<<<
 *             flags |= FL_ALLOW_ESCAPES
 *         if allow_star_comments:
 */
  }

  /* "srctools/_tokenizer.pyx":368
 *         if allow_escapes:
 *             flags |= FL_ALLOW_ESCAPES
 *         if allow_star_comments:             # <<<<<<<<<<<<<<
 *             flags |= FL_ALLOW_STAR_COMMENTS
 *         if colon_operator:
 */
  __pyx_t_1 = (__pyx_v_allow_star_comments != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":369
 *             flags |= FL_ALLOW_ESCAPES
 *         if allow_star_comments:
 *             flags |= FL_ALLOW_STAR_COMMENTS             # <<<<<<<<<<<<<<
 *         if colon_operator:
 *             flags |= FL_COLON_OPERATOR
 */
    __pyx_v_flags = (__pyx_v_flags | 4);

    /* "srctools/_tokenizer.pyx":368
 *         if allow_escapes:
 *             flags |= FL_ALLOW_ESCAPES
 *         if allow_star_comments:             # <<<<<<<<<<<<<<
 *             flags |= FL_ALLOW_STAR_COMMENTS
 *         if colon_operator:
 */
  }

  /* "srctools/_tokenizer.pyx":370
 *         if allow_star_comments:
 *             flags |= FL_ALLOW_STAR_COMMENTS
 *         if colon_operator:             # <<<<<<<<<<<<<<
 *             flags |= FL_COLON_OPERATOR
 * 
 */
  __pyx_t_1 = (__pyx_v_colon_operator != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":371
 *             flags |= FL_ALLOW_STAR_COMMENTS
 *         if colon_operator:
 *             flags |= FL_COLON_OPERATOR             # <<<<<<<<<<<<<<
 * 
 *         # For direct strings, we can immediately assign that as our chunk,
 */
    __pyx_v_flags = (__pyx_v_flags | 8);

    /* "srctools/_tokenizer.pyx":370
 *         if allow_star_comments:
 *             flags |= FL_ALLOW_STAR_COMMENTS
 *         if colon_operator:             # <<<<<<<<<<<<<<
 *             flags |= FL_COLON_OPERATOR
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":375
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to indicate EOF after that.
 *         if type(data) is str:             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_buf = PyUnicode_AsUTF8AndSize(data, &self.chunk_size)
 */
  __pyx_t_1 = (((PyObject *)Py_TYPE(__pyx_v_data)) == ((PyObject *)(&PyUnicode_Type)));
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":376
 *         # and then set the iterable to indicate EOF after that.
 *         if type(data) is str:
 *             self.cur_chunk = data             # <<<<<<<<<<<<<<
 *             self.chunk_buf = PyUnicode_AsUTF8AndSize(data, &self.chunk_size)
 *             self.chunk_iter = None
 */
    __Pyx_INCREF(__pyx_v_data);
    __Pyx_GIVEREF(__pyx_v_data);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = __pyx_v_data;

    /* "srctools/_tokenizer.pyx":377
 *         if type(data) is str:
 *             self.cur_chunk = data
 *             self.chunk_buf = PyUnicode_AsUTF8AndSize(data, &self.chunk_size)             # <<<<<<<<<<<<<<
 *             self.chunk_iter = None
 *         else:
 */
    if (!(likely(PyUnicode_CheckExact(__pyx_v_data))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_data)->tp_name), 0))) __PYX_ERR(0, 377, __pyx_L1_error)
    __pyx_t_5 = PyUnicode_AsUTF8AndSize(((PyObject*)__pyx_v_data), (&__pyx_v_self->chunk_size)); if (unlikely(__pyx_t_5 == ((unsigned char const *)NULL))) __PYX_ERR(0, 377, __pyx_L1_error)
    __pyx_v_self->chunk_buf = __pyx_t_5;

    /* "srctools/_tokenizer.pyx":378
 *             self.cur_chunk = data
 *             self.chunk_buf = PyUnicode_AsUTF8AndSize(data, &self.chunk_size)
 *             self.chunk_iter = None             # <<<<<<<<<<<<<<
 *         else:
 *             # The first next_char() call will pull out a chunk.
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->chunk_iter);
    __Pyx_DECREF(__pyx_v_self->chunk_iter);
    __pyx_v_self->chunk_iter = Py_None;

    /* "srctools/_tokenizer.pyx":375
 *         # For direct strings, we can immediately assign that as our chunk,
 *         # and then set the iterable to indicate EOF after that.
 *         if type(data) is str:             # <<<<<<<<<<<<<<
 *             self.cur_chunk = data
 *             self.chunk_buf = PyUnicode_AsUTF8AndSize(data, &self.chunk_size)
 */
    goto __pyx_L10;
  }

  /* "srctools/_tokenizer.pyx":381
 *         else:
 *             # The first next_char() call will pull out a chunk.
 *             self.cur_chunk = ''             # <<<<<<<<<<<<<<
 *             self.chunk_size = 0
 *             self.chunk_buf = EMPTY_BUF
 */
  /*else*/ {
    __Pyx_INCREF(__pyx_kp_u__8);
    __Pyx_GIVEREF(__pyx_kp_u__8);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = __pyx_kp_u__8;

    /* "srctools/_tokenizer.pyx":382
 *             # The first next_char() call will pull out a chunk.
 *             self.cur_chunk = ''
 *             self.chunk_size = 0             # <<<<<<<<<<<<<<
 *             self.chunk_buf = EMPTY_BUF
 * 
 */
    __pyx_v_self->chunk_size = 0;

    /* "srctools/_tokenizer.pyx":383
 *             self.cur_chunk = ''
 *             self.chunk_size = 0
 *             self.chunk_buf = EMPTY_BUF             # <<<<<<<<<<<<<<
 * 
 *             # If a file, use the read method to pull bulk data.
 */
    __pyx_v_self->chunk_buf = __pyx_v_8srctools_10_tokenizer_EMPTY_BUF;

    /* "srctools/_tokenizer.pyx":386
 * 
 *             # If a file, use the read method to pull bulk data.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.chunk_iter = data.read
 *             except AttributeError:
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_8);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":387
 *             # If a file, use the read method to pull bulk data.
 *             try:
 *                 self.chunk_iter = data.read             # <<<<<<<<<<<<<<
 *             except AttributeError:
 *                 # This checks that it is indeed iterable.
 */
        __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_data, __pyx_n_s_read); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 387, __pyx_L11_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_4);
        __Pyx_GOTREF(__pyx_v_self->chunk_iter);
        __Pyx_DECREF(__pyx_v_self->chunk_iter);
        __pyx_v_self->chunk_iter = __pyx_t_4;
        __pyx_t_4 = 0;

        /* "srctools/_tokenizer.pyx":386
 * 
 *             # If a file, use the read method to pull bulk data.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.chunk_iter = data.read
 *             except AttributeError:
 */
      }

      /* "srctools/_tokenizer.pyx":392
 *                 self.chunk_iter = iter(data)
 *             else:
 *                 flags |= FL_FILE_INPUT             # <<<<<<<<<<<<<<
 * 
 *         # We initially add one, so it'll be 0 next.
 */
      /*else:*/ {
        __pyx_v_flags = (__pyx_v_flags | 16);
      }
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      goto __pyx_L16_try_end;
      __pyx_L11_error:;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":388
 *             try:
 *                 self.chunk_iter = data.read
 *             except AttributeError:             # <<<<<<<<<<<<<<
 *                 # This checks that it is indeed iterable.
 *                 self.chunk_iter = iter(data)
 */
      __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_AttributeError);
      if (__pyx_t_9) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_10, &__pyx_t_11) < 0) __PYX_ERR(0, 388, __pyx_L13_except_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_GOTREF(__pyx_t_11);

        /* "srctools/_tokenizer.pyx":390
 *             except AttributeError:
 *                 # This checks that it is indeed iterable.
 *                 self.chunk_iter = iter(data)             # <<<<<<<<<<<<<<
 *             else:
 *                 flags |= FL_FILE_INPUT
 */
        __pyx_t_12 = PyObject_GetIter(__pyx_v_data); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 390, __pyx_L13_except_error)
        __Pyx_GOTREF(__pyx_t_12);
        __Pyx_GIVEREF(__pyx_t_12);
        __Pyx_GOTREF(__pyx_v_self->chunk_iter);
        __Pyx_DECREF(__pyx_v_self->chunk_iter);
        __pyx_v_self->chunk_iter = __pyx_t_12;
        __pyx_t_12 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
        goto __pyx_L12_exception_handled;
      }
      goto __pyx_L13_except_error;
      __pyx_L13_except_error:;

      /* "srctools/_tokenizer.pyx":386
 * 
 *             # If a file, use the read method to pull bulk data.
 *             try:             # <<<<<<<<<<<<<<
 *                 self.chunk_iter = data.read
 *             except AttributeError:
 */
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
      goto __pyx_L1_error;
      __pyx_L12_exception_handled:;
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_ExceptionReset(__pyx_t_6, __pyx_t_7, __pyx_t_8);
      __pyx_L16_try_end:;
    }
  }
  __pyx_L10:;

  /* "srctools/_tokenizer.pyx":395
 * 
 *         # We initially add one, so it'll be 0 next.
 *         self.char_index = -1             # <<<<<<<<<<<<<<
 *         self.buf_reset()
 * 
 */
  __pyx_v_self->char_index = -1L;

  /* "srctools/_tokenizer.pyx":396
 *         # We initially add one, so it'll be 0 next.
 *         self.char_index = -1
 *         self.buf_reset()             # <<<<<<<<<<<<<<
 * 
 *         if not filename:
 */
  __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

  /* "srctools/_tokenizer.pyx":398
 *         self.buf_reset()
 * 
 *         if not filename:             # <<<<<<<<<<<<<<
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_filename); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 398, __pyx_L1_error)
  __pyx_t_1 = ((!__pyx_t_2) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":400
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_8, &__pyx_t_7, &__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_6);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":401
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 *                 filename = data.name             # <<<<<<<<<<<<<<
 *             except AttributeError:
 *                 # If not, a Falsey filename means nothing is added to any
 */
        __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_data, __pyx_n_s_name_2); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 401, __pyx_L20_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_DECREF_SET(__pyx_v_filename, __pyx_t_11);
        __pyx_t_11 = 0;

        /* "srctools/_tokenizer.pyx":400
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
      }
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      goto __pyx_L25_try_end;
      __pyx_L20_error:;
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
      __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "srctools/_tokenizer.pyx":402
 *             try:
 *                 filename = data.name
 *             except AttributeError:             # <<<<<<<<<<<<<<
 *                 # If not, a Falsey filename means nothing is added to any
 *                 # KV exception message.
 */
      __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_AttributeError);
      if (__pyx_t_9) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_11, &__pyx_t_10, &__pyx_t_4) < 0) __PYX_ERR(0, 402, __pyx_L22_except_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_GOTREF(__pyx_t_4);

        /* "srctools/_tokenizer.pyx":405
 *                 # If not, a Falsey filename means nothing is added to any
 *                 # KV exception message.
 *                 filename = None             # <<<<<<<<<<<<<<
 * 
 *         BaseTokenizer.__init__(self, filename, error)
 */
        __Pyx_INCREF(Py_None);
        __Pyx_DECREF_SET(__pyx_v_filename, Py_None);
        __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        goto __pyx_L21_exception_handled;
      }
      goto __pyx_L22_except_error;
      __pyx_L22_except_error:;

      /* "srctools/_tokenizer.pyx":400
 *         if not filename:
 *             # If we're given a file-like object, automatically set the filename.
 *             try:             # <<<<<<<<<<<<<<
 *                 filename = data.name
 *             except AttributeError:
 */
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_7, __pyx_t_6);
      goto __pyx_L1_error;
      __pyx_L21_exception_handled:;
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_7, __pyx_t_6);
      __pyx_L25_try_end:;
    }

    /* "srctools/_tokenizer.pyx":398
 *         self.buf_reset()
 * 
 *         if not filename:             # <<<<<<<<<<<<<<
 *             # If we're given a file-like object, automatically set the filename.
 *             try:
 */
  }

  /* "srctools/_tokenizer.pyx":407
 *                 filename = None
 * 
 *         BaseTokenizer.__init__(self, filename, error)             # <<<<<<<<<<<<<<
 *         self.flags |= flags
 * 
 */
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer), __pyx_n_s_init); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 407, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_11 = NULL;
  __pyx_t_9 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_10))) {
    __pyx_t_11 = PyMethod_GET_SELF(__pyx_t_10);
    if (likely(__pyx_t_11)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_10);
      __Pyx_INCREF(__pyx_t_11);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_10, function);
      __pyx_t_9 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_10)) {
    PyObject *__pyx_temp[4] = {__pyx_t_11, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
    __Pyx_GOTREF(__pyx_t_4);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_10)) {
    PyObject *__pyx_temp[4] = {__pyx_t_11, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_10, __pyx_temp+1-__pyx_t_9, 3+__pyx_t_9); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
    __Pyx_GOTREF(__pyx_t_4);
  } else
  #endif
  {
    __pyx_t_12 = PyTuple_New(3+__pyx_t_9); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);
    if (__pyx_t_11) {
      __Pyx_GIVEREF(__pyx_t_11); PyTuple_SET_ITEM(__pyx_t_12, 0, __pyx_t_11); __pyx_t_11 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_12, 0+__pyx_t_9, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_v_filename);
    __Pyx_GIVEREF(__pyx_v_filename);
    PyTuple_SET_ITEM(__pyx_t_12, 1+__pyx_t_9, __pyx_v_filename);
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    PyTuple_SET_ITEM(__pyx_t_12, 2+__pyx_t_9, __pyx_v_error);
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_10, __pyx_t_12, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 407, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
  }
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "srctools/_tokenizer.pyx":408
 * 
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.flags |= flags             # <<<<<<<<<<<<<<
 * 
 *         # We want to strip a UTF BOM from the start of the file, if it matches.
 */
  __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags | __pyx_v_flags);

  /* "srctools/_tokenizer.pyx":414
 *         # rebuild the cur_chunk to allow them.
 *         # The BOM is b'\xef\xbb\xbf'.
 *         if self._next_char() != 0xef:             # <<<<<<<<<<<<<<
 *             self.char_index -= 1
 *         elif self._next_char() != 0xbb:
 */
  __pyx_t_13 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_13 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 414, __pyx_L1_error)
  __pyx_t_1 = ((__pyx_t_13 != 0xef) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":415
 *         # The BOM is b'\xef\xbb\xbf'.
 *         if self._next_char() != 0xef:
 *             self.char_index -= 1             # <<<<<<<<<<<<<<
 *         elif self._next_char() != 0xbb:
 *             self.char_index -= 2
 */
    __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

    /* "srctools/_tokenizer.pyx":414
 *         # rebuild the cur_chunk to allow them.
 *         # The BOM is b'\xef\xbb\xbf'.
 *         if self._next_char() != 0xef:             # <<<<<<<<<<<<<<
 *             self.char_index -= 1
 *         elif self._next_char() != 0xbb:
 */
    goto __pyx_L28;
  }

  /* "srctools/_tokenizer.pyx":416
 *         if self._next_char() != 0xef:
 *             self.char_index -= 1
 *         elif self._next_char() != 0xbb:             # <<<<<<<<<<<<<<
 *             self.char_index -= 2
 *         elif self._next_char() != 0xbf:
 */
  __pyx_t_13 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_13 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 416, __pyx_L1_error)
  __pyx_t_1 = ((__pyx_t_13 != 0xbb) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":417
 *             self.char_index -= 1
 *         elif self._next_char() != 0xbb:
 *             self.char_index -= 2             # <<<<<<<<<<<<<<
 *         elif self._next_char() != 0xbf:
 *             self.char_index -= 3
 */
    __pyx_v_self->char_index = (__pyx_v_self->char_index - 2);

    /* "srctools/_tokenizer.pyx":416
 *         if self._next_char() != 0xef:
 *             self.char_index -= 1
 *         elif self._next_char() != 0xbb:             # <<<<<<<<<<<<<<
 *             self.char_index -= 2
 *         elif self._next_char() != 0xbf:
 */
    goto __pyx_L28;
  }

  /* "srctools/_tokenizer.pyx":418
 *         elif self._next_char() != 0xbb:
 *             self.char_index -= 2
 *         elif self._next_char() != 0xbf:             # <<<<<<<<<<<<<<
 *             self.char_index -= 3
 * 
 */
  __pyx_t_13 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_13 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 418, __pyx_L1_error)
  __pyx_t_1 = ((__pyx_t_13 != 0xbf) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":419
 *             self.char_index -= 2
 *         elif self._next_char() != 0xbf:
 *             self.char_index -= 3             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
    __pyx_v_self->char_index = (__pyx_v_self->char_index - 3);

    /* "srctools/_tokenizer.pyx":418
 *         elif self._next_char() != 0xbb:
 *             self.char_index -= 2
 *         elif self._next_char() != 0xbf:             # <<<<<<<<<<<<<<
 *             self.char_index -= 3
 * 
 */
  }
  __pyx_L28:;

  /* "srctools/_tokenizer.pyx":346
 *         PyMem_Free(self.val_buffer)
 * 
 *     def __init__(             # <<<<<<<<<<<<<<
 *         self,
 *         data not None,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_filename);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":422
 * 
 *     @property
 *     def string_bracket(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if [bracket] blocks are parsed as a single string-like block.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":427
 *         If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.
 *         """
 *         return self.flags & FL_STRING_BRACKETS != 0             # <<<<<<<<<<<<<<
 * 
 *     @string_bracket.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->__pyx_base.flags & 1) != 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":422
 * 
 *     @property
 *     def string_bracket(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if [bracket] blocks are parsed as a single string-like block.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":430
 * 
 *     @string_bracket.setter
 *     def string_bracket(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if [bracket] blocks are parsed as a single string-like block.
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  int __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyObject_IsTrue(__pyx_arg_value); if (unlikely((__pyx_v_value == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.string_bracket.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((int)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14string_bracket_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "srctools/_tokenizer.pyx":435
 *         If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.
 *         """
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_STRING_BRACKETS
 *         else:
 */
  __pyx_t_1 = (__pyx_v_value != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":436
 *         """
 *         if value:
 *             self.flags |= FL_STRING_BRACKETS             # <<<<<<<<<<<<<<
 *         else:
 *             self.flags &= ~FL_STRING_BRACKETS
 */
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags | 1);

    /* "srctools/_tokenizer.pyx":435
 *         If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.
 *         """
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_STRING_BRACKETS
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":438
 *             self.flags |= FL_STRING_BRACKETS
 *         else:
 *             self.flags &= ~FL_STRING_BRACKETS             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags & (~1));
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":430
 * 
 *     @string_bracket.setter
 *     def string_bracket(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if [bracket] blocks are parsed as a single string-like block.
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":441
 * 
 *     @property
 *     def allow_escapes(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if backslash escapes will be parsed."""
 *         return self.flags & FL_ALLOW_ESCAPES != 0
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":443
 *     def allow_escapes(self) -> bool:
 *         """Check if backslash escapes will be parsed."""
 *         return self.flags & FL_ALLOW_ESCAPES != 0             # <<<<<<<<<<<<<<
 * 
 *     @allow_escapes.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->__pyx_base.flags & 2) != 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":441
 * 
 *     @property
 *     def allow_escapes(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if backslash escapes will be parsed."""
 *         return self.flags & FL_ALLOW_ESCAPES != 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":446
 * 
 *     @allow_escapes.setter
 *     def allow_escapes(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if backslash escapes will be parsed."""
 *         if value:
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  int __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyObject_IsTrue(__pyx_arg_value); if (unlikely((__pyx_v_value == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 446, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_escapes.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((int)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "srctools/_tokenizer.pyx":448
 *     def allow_escapes(self, bint value) -> None:
 *         """Set if backslash escapes will be parsed."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_ALLOW_ESCAPES
 *         else:
 */
  __pyx_t_1 = (__pyx_v_value != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":449
 *         """Set if backslash escapes will be parsed."""
 *         if value:
 *             self.flags |= FL_ALLOW_ESCAPES             # <<<<<<<<<<<<<<
 *         else:
 *             self.flags &= ~FL_ALLOW_ESCAPES
 */
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags | 2);

    /* "srctools/_tokenizer.pyx":448
 *     def allow_escapes(self, bint value) -> None:
 *         """Set if backslash escapes will be parsed."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_ALLOW_ESCAPES
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":451
 *             self.flags |= FL_ALLOW_ESCAPES
 *         else:
 *             self.flags &= ~FL_ALLOW_ESCAPES             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags & (~2));
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":446
 * 
 *     @allow_escapes.setter
 *     def allow_escapes(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if backslash escapes will be parsed."""
 *         if value:
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":454
 * 
 *     @property
 *     def allow_star_comments(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments will be enabled."""
 *         return self.flags & FL_ALLOW_STAR_COMMENTS != 0
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":456
 *     def allow_star_comments(self) -> bool:
 *         """Check if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments will be enabled."""
 *         return self.flags & FL_ALLOW_STAR_COMMENTS != 0             # <<<<<<<<<<<<<<
 * 
 *     @allow_star_comments.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->__pyx_base.flags & 4) != 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":454
 * 
 *     @property
 *     def allow_star_comments(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments will be enabled."""
 *         return self.flags & FL_ALLOW_STAR_COMMENTS != 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":459
 * 
 *     @allow_star_comments.setter
 *     def allow_star_comments(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments are enabled."""
 *         if value:
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  int __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyObject_IsTrue(__pyx_arg_value); if (unlikely((__pyx_v_value == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 459, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.allow_star_comments.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((int)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "srctools/_tokenizer.pyx":461
 *     def allow_star_comments(self, bint value) -> None:
 *         """Set if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments are enabled."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_ALLOW_STAR_COMMENTS
 *         else:
 */
  __pyx_t_1 = (__pyx_v_value != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":462
 *         """Set if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments are enabled."""
 *         if value:
 *             self.flags |= FL_ALLOW_STAR_COMMENTS             # <<<<<<<<<<<<<<
 *         else:
 *             self.flags &= ~FL_ALLOW_STAR_COMMENTS
 */
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags | 4);

    /* "srctools/_tokenizer.pyx":461
 *     def allow_star_comments(self, bint value) -> None:
 *         """Set if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments are enabled."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_ALLOW_STAR_COMMENTS
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":464
 *             self.flags |= FL_ALLOW_STAR_COMMENTS
 *         else:
 *             self.flags &= ~FL_ALLOW_STAR_COMMENTS             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  /*else*/ {
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags & (~4));
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":459
 * 
 *     @allow_star_comments.setter
 *     def allow_star_comments(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if /[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/ style comments are enabled."""
 *         if value:
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":467
 * 
 *     @property
 *     def colon_operator(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if : characters are treated as a COLON token, or part of strings."""
 *         return self.flags & FL_COLON_OPERATOR != 0
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator___get__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator___get__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "srctools/_tokenizer.pyx":469
 *     def colon_operator(self) -> bool:
 *         """Check if : characters are treated as a COLON token, or part of strings."""
 *         return self.flags & FL_COLON_OPERATOR != 0             # <<<<<<<<<<<<<<
 * 
 *     @colon_operator.setter
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->__pyx_base.flags & 8) != 0)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":467
 * 
 *     @property
 *     def colon_operator(self) -> bool:             # <<<<<<<<<<<<<<
 *         """Check if : characters are treated as a COLON token, or part of strings."""
 *         return self.flags & FL_COLON_OPERATOR != 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.colon_operator.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":472
 * 
 *     @colon_operator.setter
 *     def colon_operator(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if : characters are treated as a COLON token, or part of strings."""
 *         if value:
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_arg_value) {
  int __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  assert(__pyx_arg_value); {
    __pyx_v_value = __Pyx_PyObject_IsTrue(__pyx_arg_value); if (unlikely((__pyx_v_value == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 472, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.colon_operator.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self), ((int)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9Tokenizer_14colon_operator_2__set__(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, int __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "srctools/_tokenizer.pyx":474
 *     def colon_operator(self, bint value) -> None:
 *         """Set if : characters are treated as a COLON token, or part of strings."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_COLON_OPERATOR
 *         else:
 */
  __pyx_t_1 = (__pyx_v_value != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":475
 *         """Set if : characters are treated as a COLON token, or part of strings."""
 *         if value:
 *             self.flags |= FL_COLON_OPERATOR             # <<<<<<<<<<<<<<
 *         else:
 *             self.flags &= ~FL_COLON_OPERATOR
 */
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags | 8);

    /* "srctools/_tokenizer.pyx":474
 *     def colon_operator(self, bint value) -> None:
 *         """Set if : characters are treated as a COLON token, or part of strings."""
 *         if value:             # <<<<<<<<<<<<<<
 *             self.flags |= FL_COLON_OPERATOR
 *         else:
 */
    goto __pyx_L3;
  }

  /* "srctools/_tokenizer.pyx":477
 *             self.flags |= FL_COLON_OPERATOR
 *         else:
 *             self.flags &= ~FL_COLON_OPERATOR             # <<<<<<<<<<<<<<
 * 
 *     cdef inline void buf_reset(self):
 */
  /*else*/ {
    __pyx_v_self->__pyx_base.flags = (__pyx_v_self->__pyx_base.flags & (~8));
  }
  __pyx_L3:;

  /* "srctools/_tokenizer.pyx":472
 * 
 *     @colon_operator.setter
 *     def colon_operator(self, bint value) -> None:             # <<<<<<<<<<<<<<
 *         """Set if : characters are treated as a COLON token, or part of strings."""
 *         if value:
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":479
 *             self.flags &= ~FL_COLON_OPERATOR
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 */

static CYTHON_INLINE void __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("buf_reset", 0);

  /* "srctools/_tokenizer.pyx":482
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 * 
 *     cdef inline int buf_add_char(self, char new_char) except -1:
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":479
 *             self.flags &= ~FL_COLON_OPERATOR
 * 
 *     cdef inline void buf_reset(self):             # <<<<<<<<<<<<<<
 *         """Reset the temporary buffer."""
 *         # Don't bother resizing or clearing, the next append will overwrite.
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":484
 *         self.buf_pos = 0
 * 
 *     cdef inline int buf_add_char(self, char new_char) except -1:             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         # Temp, so if memory alloc failure occurs we're still in a valid state.
 */

static CYTHON_INLINE int __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self, char __pyx_v_new_char) {
  Py_ssize_t __pyx_v_new_size;
  unsigned char *__pyx_v_new_buf;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("buf_add_char", 0);

  /* "srctools/_tokenizer.pyx":489
 *         cdef uchar *newbuf
 *         cdef Py_ssize_t new_size
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             new_size = self.buf_size * 2
 *             new_buf = <uchar *>PyMem_Realloc(
 */
  __pyx_t_1 = ((__pyx_v_self->buf_pos >= __pyx_v_self->buf_size) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":490
 *         cdef Py_ssize_t new_size
 *         if self.buf_pos >= self.buf_size:
 *             new_size = self.buf_size * 2             # <<<<<<<<<<<<<<
 *             new_buf = <uchar *>PyMem_Realloc(
 *                 self.val_buffer,
 */
    __pyx_v_new_size = (__pyx_v_self->buf_size * 2);

    /* "srctools/_tokenizer.pyx":491
 *         if self.buf_pos >= self.buf_size:
 *             new_size = self.buf_size * 2
 *             new_buf = <uchar *>PyMem_Realloc(             # <<<<<<<<<<<<<<
 *                 self.val_buffer,
 *                 new_size * sizeof(uchar),
 */
    __pyx_v_new_buf = ((unsigned char *)PyMem_Realloc(__pyx_v_self->val_buffer, (__pyx_v_new_size * (sizeof(unsigned char)))));

    /* "srctools/_tokenizer.pyx":495
 *                 new_size * sizeof(uchar),
 *             )
 *             if new_buf:             # <<<<<<<<<<<<<<
 *                 self.buf_size = new_size
 *                 self.val_buffer = new_buf
 */
    __pyx_t_1 = (__pyx_v_new_buf != 0);
    if (likely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":496
 *             )
 *             if new_buf:
 *                 self.buf_size = new_size             # <<<<<<<<<<<<<<
 *                 self.val_buffer = new_buf
 *             else:
 */
      __pyx_v_self->buf_size = __pyx_v_new_size;

      /* "srctools/_tokenizer.pyx":497
 *             if new_buf:
 *                 self.buf_size = new_size
 *                 self.val_buffer = new_buf             # <<<<<<<<<<<<<<
 *             else:
 *                 raise MemoryError
 */
      __pyx_v_self->val_buffer = __pyx_v_new_buf;

      /* "srctools/_tokenizer.pyx":495
 *                 new_size * sizeof(uchar),
 *             )
 *             if new_buf:             # <<<<<<<<<<<<<<
 *                 self.buf_size = new_size
 *                 self.val_buffer = new_buf
 */
      goto __pyx_L4;
    }

    /* "srctools/_tokenizer.pyx":499
 *                 self.val_buffer = new_buf
 *             else:
 *                 raise MemoryError             # <<<<<<<<<<<<<<
 * 
 *         self.val_buffer[self.buf_pos] = new_char
 */
    /*else*/ {
      PyErr_NoMemory(); __PYX_ERR(0, 499, __pyx_L1_error)
    }
    __pyx_L4:;

    /* "srctools/_tokenizer.pyx":489
 *         cdef uchar *newbuf
 *         cdef Py_ssize_t new_size
 *         if self.buf_pos >= self.buf_size:             # <<<<<<<<<<<<<<
 *             new_size = self.buf_size * 2
 *             new_buf = <uchar *>PyMem_Realloc(
 */
  }

  /* "srctools/_tokenizer.pyx":501
 *                 raise MemoryError
 * 
 *         self.val_buffer[self.buf_pos] = new_char             # <<<<<<<<<<<<<<
 *         self.buf_pos += 1
 * 
 */
  (__pyx_v_self->val_buffer[__pyx_v_self->buf_pos]) = __pyx_v_new_char;

  /* "srctools/_tokenizer.pyx":502
 * 
 *         self.val_buffer[self.buf_pos] = new_char
 *         self.buf_pos += 1             # <<<<<<<<<<<<<<
 * 
 *     cdef str buf_get_text(self):
 */
  __pyx_v_self->buf_pos = (__pyx_v_self->buf_pos + 1);

  /* "srctools/_tokenizer.pyx":484
 *         self.buf_pos = 0
 * 
 *     cdef inline int buf_add_char(self, char new_char) except -1:             # <<<<<<<<<<<<<<
 *         """Add a character to the temporary buffer, reallocating if needed."""
 *         # Temp, so if memory alloc failure occurs we're still in a valid state.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.buf_add_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":504
 *         self.buf_pos += 1
 * 
 *     cdef str buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         out = PyUnicode_FromStringAndSize(self.val_buffer, self.buf_pos)
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_out = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("buf_get_text", 0);

  /* "srctools/_tokenizer.pyx":506
 *     cdef str buf_get_text(self):
 *         """Decode the buffer, and return the text."""
 *         out = PyUnicode_FromStringAndSize(self.val_buffer, self.buf_pos)             # <<<<<<<<<<<<<<
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0
 */
  __pyx_t_1 = PyUnicode_FromStringAndSize(__pyx_v_self->val_buffer, __pyx_v_self->buf_pos); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 506, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_out = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":508
 *         out = PyUnicode_FromStringAndSize(self.val_buffer, self.buf_pos)
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0             # <<<<<<<<<<<<<<
 *         return out
 * 
 */
  __pyx_v_self->buf_pos = 0;

  /* "srctools/_tokenizer.pyx":509
 *         # Don't bother resizing or clearing, the next append will overwrite.
 *         self.buf_pos = 0
 *         return out             # <<<<<<<<<<<<<<
 * 
 *     # We check all the getitem[] accesses, so don't have Cython recheck.
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_out);
  __pyx_r = __pyx_v_out;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":504
 *         self.buf_pos += 1
 * 
 *     cdef str buf_get_text(self):             # <<<<<<<<<<<<<<
 *         """Decode the buffer, and return the text."""
 *         out = PyUnicode_FromStringAndSize(self.val_buffer, self.buf_pos)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.buf_get_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_out);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":514
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef uchar _next_char(self) except? CHR_EOF:             # <<<<<<<<<<<<<<
 *         """Return the next character, or 0 if no more characters are there."""
 *         cdef str chunk
 */

static unsigned char __pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  PyObject *__pyx_v_chunk_obj = 0;
  PyObject *__pyx_v_exc = NULL;
  unsigned char __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  unsigned char const *__pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  int __pyx_t_12;
  char const *__pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  Py_ssize_t __pyx_t_20;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_next_char", 0);

  /* "srctools/_tokenizer.pyx":519
 *         cdef object chunk_obj
 * 
 *         self.char_index += 1             # <<<<<<<<<<<<<<
 *         if self.char_index < self.chunk_size:
 *             return self.chunk_buf[self.char_index]
 */
  __pyx_v_self->char_index = (__pyx_v_self->char_index + 1);

  /* "srctools/_tokenizer.pyx":520
 * 
 *         self.char_index += 1
 *         if self.char_index < self.chunk_size:             # <<<<<<<<<<<<<<
 *             return self.chunk_buf[self.char_index]
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->char_index < __pyx_v_self->chunk_size) != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":521
 *         self.char_index += 1
 *         if self.char_index < self.chunk_size:
 *             return self.chunk_buf[self.char_index]             # <<<<<<<<<<<<<<
 * 
 *         if self.chunk_iter is None:
 */
    __pyx_r = (__pyx_v_self->chunk_buf[__pyx_v_self->char_index]);
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":520
 * 
 *         self.char_index += 1
 *         if self.char_index < self.chunk_size:             # <<<<<<<<<<<<<<
 *             return self.chunk_buf[self.char_index]
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":523
 *             return self.chunk_buf[self.char_index]
 * 
 *         if self.chunk_iter is None:             # <<<<<<<<<<<<<<
 *             return CHR_EOF
 * 
 */
  __pyx_t_1 = (__pyx_v_self->chunk_iter == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":524
 * 
 *         if self.chunk_iter is None:
 *             return CHR_EOF             # <<<<<<<<<<<<<<
 * 
 *         if self.flags & FL_FILE_INPUT:
 */
    __pyx_r = 3;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":523
 *             return self.chunk_buf[self.char_index]
 * 
 *         if self.chunk_iter is None:             # <<<<<<<<<<<<<<
 *             return CHR_EOF
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":526
 *             return CHR_EOF
 * 
 *         if self.flags & FL_FILE_INPUT:             # <<<<<<<<<<<<<<
 *             self.cur_chunk = self.chunk_iter(FILE_BUFFER)
 *             self.char_index = 0
 */
  __pyx_t_2 = ((__pyx_v_self->__pyx_base.flags & 16) != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":527
 * 
 *         if self.flags & FL_FILE_INPUT:
 *             self.cur_chunk = self.chunk_iter(FILE_BUFFER)             # <<<<<<<<<<<<<<
 *             self.char_index = 0
 * 
 */
    __Pyx_INCREF(__pyx_v_self->chunk_iter);
    __pyx_t_4 = __pyx_v_self->chunk_iter; __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_int_1024) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_int_1024);
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 527, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GIVEREF(__pyx_t_3);
    __Pyx_GOTREF(__pyx_v_self->cur_chunk);
    __Pyx_DECREF(__pyx_v_self->cur_chunk);
    __pyx_v_self->cur_chunk = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":528
 *         if self.flags & FL_FILE_INPUT:
 *             self.cur_chunk = self.chunk_iter(FILE_BUFFER)
 *             self.char_index = 0             # <<<<<<<<<<<<<<
 * 
 *             if type(self.cur_chunk) is str:
 */
    __pyx_v_self->char_index = 0;

    /* "srctools/_tokenizer.pyx":530
 *             self.char_index = 0
 * 
 *             if type(self.cur_chunk) is str:             # <<<<<<<<<<<<<<
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 *             else:
 */
    __pyx_t_2 = (((PyObject *)Py_TYPE(__pyx_v_self->cur_chunk)) == ((PyObject *)(&PyUnicode_Type)));
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (likely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":531
 * 
 *             if type(self.cur_chunk) is str:
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)             # <<<<<<<<<<<<<<
 *             else:
 *                 raise ValueError('Expected string, got ' + type(self.cur_chunk).__name__)
 */
      if (!(likely(PyUnicode_CheckExact(__pyx_v_self->cur_chunk))||((__pyx_v_self->cur_chunk) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_self->cur_chunk)->tp_name), 0))) __PYX_ERR(0, 531, __pyx_L1_error)
      __pyx_t_3 = __pyx_v_self->cur_chunk;
      __Pyx_INCREF(__pyx_t_3);
      __pyx_t_6 = PyUnicode_AsUTF8AndSize(((PyObject*)__pyx_t_3), (&__pyx_v_self->chunk_size)); if (unlikely(__pyx_t_6 == ((unsigned char const *)NULL))) __PYX_ERR(0, 531, __pyx_L1_error)
      __pyx_v_self->chunk_buf = __pyx_t_6;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "srctools/_tokenizer.pyx":530
 *             self.char_index = 0
 * 
 *             if type(self.cur_chunk) is str:             # <<<<<<<<<<<<<<
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 *             else:
 */
      goto __pyx_L6;
    }

    /* "srctools/_tokenizer.pyx":533
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 *             else:
 *                 raise ValueError('Expected string, got ' + type(self.cur_chunk).__name__)             # <<<<<<<<<<<<<<
 * 
 *             if self.chunk_size > 0:
 */
    /*else*/ {
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)Py_TYPE(__pyx_v_self->cur_chunk)), __pyx_n_s_name); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 533, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyNumber_Add(__pyx_kp_u_Expected_string_got, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 533, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 533, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 533, __pyx_L1_error)
    }
    __pyx_L6:;

    /* "srctools/_tokenizer.pyx":535
 *                 raise ValueError('Expected string, got ' + type(self.cur_chunk).__name__)
 * 
 *             if self.chunk_size > 0:             # <<<<<<<<<<<<<<
 *                 return self.chunk_buf[0]
 *             else:
 */
    __pyx_t_1 = ((__pyx_v_self->chunk_size > 0) != 0);
    if (__pyx_t_1) {

      /* "srctools/_tokenizer.pyx":536
 * 
 *             if self.chunk_size > 0:
 *                 return self.chunk_buf[0]             # <<<<<<<<<<<<<<
 *             else:
 *                 self.chunk_iter = None
 */
      __pyx_r = (__pyx_v_self->chunk_buf[0]);
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":535
 *                 raise ValueError('Expected string, got ' + type(self.cur_chunk).__name__)
 * 
 *             if self.chunk_size > 0:             # <<<<<<<<<<<<<<
 *                 return self.chunk_buf[0]
 *             else:
 */
    }

    /* "srctools/_tokenizer.pyx":538
 *                 return self.chunk_buf[0]
 *             else:
 *                 self.chunk_iter = None             # <<<<<<<<<<<<<<
 *                 return CHR_EOF
 * 
 */
    /*else*/ {
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      __Pyx_GOTREF(__pyx_v_self->chunk_iter);
      __Pyx_DECREF(__pyx_v_self->chunk_iter);
      __pyx_v_self->chunk_iter = Py_None;

      /* "srctools/_tokenizer.pyx":539
 *             else:
 *                 self.chunk_iter = None
 *                 return CHR_EOF             # <<<<<<<<<<<<<<
 * 
 *         # Retrieve a chunk from the iterable.
 */
      __pyx_r = 3;
      goto __pyx_L0;
    }

    /* "srctools/_tokenizer.pyx":526
 *             return CHR_EOF
 * 
 *         if self.flags & FL_FILE_INPUT:             # <<<<<<<<<<<<<<
 *             self.cur_chunk = self.chunk_iter(FILE_BUFFER)
 *             self.char_index = 0
 */
  }

  /* "srctools/_tokenizer.pyx":545
 *         # Use manual next to avoid re-calling iter() here,
 *         # or using list/tuple optimisations.
 *         while True:             # <<<<<<<<<<<<<<
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":546
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
    {
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __Pyx_ExceptionSave(&__pyx_t_7, &__pyx_t_8, &__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_9);
      /*try:*/ {

        /* "srctools/_tokenizer.pyx":547
 *         while True:
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)             # <<<<<<<<<<<<<<
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 */
        __pyx_t_3 = __pyx_v_self->chunk_iter;
        __Pyx_INCREF(__pyx_t_3);
        __pyx_t_4 = __Pyx_PyIter_Next2(__pyx_t_3, Py_None); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 547, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_XDECREF_SET(__pyx_v_chunk_obj, __pyx_t_4);
        __pyx_t_4 = 0;

        /* "srctools/_tokenizer.pyx":546
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
      }
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      goto __pyx_L17_try_end;
      __pyx_L10_error:;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "srctools/_tokenizer.pyx":548
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:
 */
      __pyx_t_10 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_UnicodeDecodeError);
      if (__pyx_t_10) {
        __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
        if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_3, &__pyx_t_5) < 0) __PYX_ERR(0, 548, __pyx_L12_except_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_3);
        __pyx_v_exc = __pyx_t_3;
        /*try:*/ {

          /* "srctools/_tokenizer.pyx":549
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc             # <<<<<<<<<<<<<<
 *             if chunk_obj is None:
 *                 # Out of characters after empty chunks
 */
          __pyx_t_11 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Could_not_decode_file); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 549, __pyx_L23_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_Raise(__pyx_t_11, 0, 0, __pyx_v_exc);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          __PYX_ERR(0, 549, __pyx_L23_error)
        }

        /* "srctools/_tokenizer.pyx":548
 *             try:
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:             # <<<<<<<<<<<<<<
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:
 */
        /*finally:*/ {
          __pyx_L23_error:;
          /*exception exit:*/{
            __Pyx_PyThreadState_declare
            __Pyx_PyThreadState_assign
            __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
            __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
            if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_17, &__pyx_t_18, &__pyx_t_19);
            if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16) < 0)) __Pyx_ErrFetch(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
            __Pyx_XGOTREF(__pyx_t_14);
            __Pyx_XGOTREF(__pyx_t_15);
            __Pyx_XGOTREF(__pyx_t_16);
            __Pyx_XGOTREF(__pyx_t_17);
            __Pyx_XGOTREF(__pyx_t_18);
            __Pyx_XGOTREF(__pyx_t_19);
            __pyx_t_10 = __pyx_lineno; __pyx_t_12 = __pyx_clineno; __pyx_t_13 = __pyx_filename;
            {
              __Pyx_DECREF(__pyx_v_exc);
              __pyx_v_exc = NULL;
            }
            if (PY_MAJOR_VERSION >= 3) {
              __Pyx_XGIVEREF(__pyx_t_17);
              __Pyx_XGIVEREF(__pyx_t_18);
              __Pyx_XGIVEREF(__pyx_t_19);
              __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
            }
            __Pyx_XGIVEREF(__pyx_t_14);
            __Pyx_XGIVEREF(__pyx_t_15);
            __Pyx_XGIVEREF(__pyx_t_16);
            __Pyx_ErrRestore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
            __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
            __pyx_lineno = __pyx_t_10; __pyx_clineno = __pyx_t_12; __pyx_filename = __pyx_t_13;
            goto __pyx_L12_except_error;
          }
        }
      }
      goto __pyx_L12_except_error;
      __pyx_L12_except_error:;

      /* "srctools/_tokenizer.pyx":546
 *         # or using list/tuple optimisations.
 *         while True:
 *             try:             # <<<<<<<<<<<<<<
 *                 chunk_obj = next(self.chunk_iter, None)
 *             except UnicodeDecodeError as exc:
 */
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_XGIVEREF(__pyx_t_9);
      __Pyx_ExceptionReset(__pyx_t_7, __pyx_t_8, __pyx_t_9);
      goto __pyx_L1_error;
      __pyx_L17_try_end:;
    }

    /* "srctools/_tokenizer.pyx":550
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:             # <<<<<<<<<<<<<<
 *                 # Out of characters after empty chunks
 *                 self.chunk_iter = None
 */
    __pyx_t_1 = (__pyx_v_chunk_obj == Py_None);
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":552
 *             if chunk_obj is None:
 *                 # Out of characters after empty chunks
 *                 self.chunk_iter = None             # <<<<<<<<<<<<<<
 *                 return CHR_EOF
 * 
 */
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      __Pyx_GOTREF(__pyx_v_self->chunk_iter);
      __Pyx_DECREF(__pyx_v_self->chunk_iter);
      __pyx_v_self->chunk_iter = Py_None;

      /* "srctools/_tokenizer.pyx":553
 *                 # Out of characters after empty chunks
 *                 self.chunk_iter = None
 *                 return CHR_EOF             # <<<<<<<<<<<<<<
 * 
 *             if isinstance(chunk_obj, bytes):
 */
      __pyx_r = 3;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":550
 *             except UnicodeDecodeError as exc:
 *                 raise self._error("Could not decode file!") from exc
 *             if chunk_obj is None:             # <<<<<<<<<<<<<<
 *                 # Out of characters after empty chunks
 *                 self.chunk_iter = None
 */
    }

    /* "srctools/_tokenizer.pyx":555
 *                 return CHR_EOF
 * 
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:
 */
    __pyx_t_2 = PyBytes_Check(__pyx_v_chunk_obj); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (unlikely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":556
 * 
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *             if type(chunk_obj) is not str:
 *                 raise ValueError("Data was not a string!")
 */
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__19, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 556, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_Raise(__pyx_t_5, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __PYX_ERR(0, 556, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":555
 *                 return CHR_EOF
 * 
 *             if isinstance(chunk_obj, bytes):             # <<<<<<<<<<<<<<
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:
 */
    }

    /* "srctools/_tokenizer.pyx":557
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    __pyx_t_1 = (((PyObject *)Py_TYPE(__pyx_v_chunk_obj)) != ((PyObject *)(&PyUnicode_Type)));
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (unlikely(__pyx_t_2)) {

      /* "srctools/_tokenizer.pyx":558
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:
 *                 raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *             if len(<str>chunk_obj) > 0:
 */
      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__20, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 558, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_Raise(__pyx_t_5, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __PYX_ERR(0, 558, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":557
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:             # <<<<<<<<<<<<<<
 *                 raise ValueError("Data was not a string!")
 * 
 */
    }

    /* "srctools/_tokenizer.pyx":560
 *                 raise ValueError("Data was not a string!")
 * 
 *             if len(<str>chunk_obj) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = chunk_obj
 *                 self.char_index = 0
 */
    if (unlikely(__pyx_v_chunk_obj == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 560, __pyx_L1_error)
    }
    __pyx_t_20 = __Pyx_PyUnicode_GET_LENGTH(((PyObject*)__pyx_v_chunk_obj)); if (unlikely(__pyx_t_20 == ((Py_ssize_t)-1))) __PYX_ERR(0, 560, __pyx_L1_error)
    __pyx_t_2 = ((__pyx_t_20 > 0) != 0);
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":561
 * 
 *             if len(<str>chunk_obj) > 0:
 *                 self.cur_chunk = chunk_obj             # <<<<<<<<<<<<<<
 *                 self.char_index = 0
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 */
      __Pyx_INCREF(__pyx_v_chunk_obj);
      __Pyx_GIVEREF(__pyx_v_chunk_obj);
      __Pyx_GOTREF(__pyx_v_self->cur_chunk);
      __Pyx_DECREF(__pyx_v_self->cur_chunk);
      __pyx_v_self->cur_chunk = __pyx_v_chunk_obj;

      /* "srctools/_tokenizer.pyx":562
 *             if len(<str>chunk_obj) > 0:
 *                 self.cur_chunk = chunk_obj
 *                 self.char_index = 0             # <<<<<<<<<<<<<<
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 *                 return self.chunk_buf[0]
 */
      __pyx_v_self->char_index = 0;

      /* "srctools/_tokenizer.pyx":563
 *                 self.cur_chunk = chunk_obj
 *                 self.char_index = 0
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)             # <<<<<<<<<<<<<<
 *                 return self.chunk_buf[0]
 * 
 */
      if (!(likely(PyUnicode_CheckExact(__pyx_v_self->cur_chunk))||((__pyx_v_self->cur_chunk) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "unicode", Py_TYPE(__pyx_v_self->cur_chunk)->tp_name), 0))) __PYX_ERR(0, 563, __pyx_L1_error)
      __pyx_t_5 = __pyx_v_self->cur_chunk;
      __Pyx_INCREF(__pyx_t_5);
      __pyx_t_6 = PyUnicode_AsUTF8AndSize(((PyObject*)__pyx_t_5), (&__pyx_v_self->chunk_size)); if (unlikely(__pyx_t_6 == ((unsigned char const *)NULL))) __PYX_ERR(0, 563, __pyx_L1_error)
      __pyx_v_self->chunk_buf = __pyx_t_6;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "srctools/_tokenizer.pyx":564
 *                 self.char_index = 0
 *                 self.chunk_buf = PyUnicode_AsUTF8AndSize(self.cur_chunk, &self.chunk_size)
 *                 return self.chunk_buf[0]             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
      __pyx_r = (__pyx_v_self->chunk_buf[0]);
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":560
 *                 raise ValueError("Data was not a string!")
 * 
 *             if len(<str>chunk_obj) > 0:             # <<<<<<<<<<<<<<
 *                 self.cur_chunk = chunk_obj
 *                 self.char_index = 0
 */
    }
  }

  /* "srctools/_tokenizer.pyx":514
 *     @cython.boundscheck(False)
 *     @cython.wraparound(False)
 *     cdef uchar _next_char(self) except? CHR_EOF:             # <<<<<<<<<<<<<<
 *         """Return the next character, or 0 if no more characters are there."""
 *         cdef str chunk
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer._next_char", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 3;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_chunk_obj);
  __Pyx_XDECREF(__pyx_v_exc);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":566
 *                 return self.chunk_buf[0]
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *__pyx_v_self) {
  unsigned char __pyx_v_next_char;
  unsigned char __pyx_v_escape_char;
  unsigned char __pyx_v_peek_char;
  int __pyx_v_start_line;
  int __pyx_v_ascii_only;
  unsigned char __pyx_v_decode[5];
  PyObject *__pyx_v_output = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  unsigned char __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  Py_UCS4 __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  unsigned char __pyx_t_11;
  unsigned char __pyx_t_12;
  unsigned char __pyx_t_13[5];
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":576
 *             uchar decode[5]
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  __pyx_t_1 = (__pyx_v_self->__pyx_base.pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":577
 * 
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val             # <<<<<<<<<<<<<<
 *             self.pushback_tok = self.pushback_val = None
 *             return output
 */
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 577, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_tok);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_val);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_output = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":578
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *             return output
 * 
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_tok);
    __pyx_v_self->__pyx_base.pushback_tok = Py_None;
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_self->__pyx_base.pushback_val = Py_None;

    /* "srctools/_tokenizer.pyx":579
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 *             return output             # <<<<<<<<<<<<<<
 * 
 *         while True:
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_output);
    __pyx_r = __pyx_v_output;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":576
 *             uchar decode[5]
 * 
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  }

  /* "srctools/_tokenizer.pyx":581
 *             return output
 * 
 *         while True:             # <<<<<<<<<<<<<<
 *             next_char = self._next_char()
 *             if next_char == CHR_EOF:
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":582
 * 
 *         while True:
 *             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *             if next_char == CHR_EOF:
 *                 return EOF_TUP
 */
    __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 582, __pyx_L1_error)
    __pyx_v_next_char = __pyx_t_4;

    /* "srctools/_tokenizer.pyx":583
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
    switch (__pyx_v_next_char) {
      case 3:

      /* "srctools/_tokenizer.pyx":584
 *             next_char = self._next_char()
 *             if next_char == CHR_EOF:
 *                 return EOF_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == b'{':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":583
 *         while True:
 *             next_char = self._next_char()
 *             if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                 return EOF_TUP
 * 
 */
      break;
      case '{':

        /* "srctools/_tokenizer.pyx":587
 * 
 *             elif next_char == b'{':
 *                 return BRACE_OPEN_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == b'}':
 *                 return BRACE_CLOSE_TUP
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
        __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":586
 *                 return EOF_TUP
 * 
 *             elif next_char == b'{':             # <<<<<<<<<<<<<<
 *                 return BRACE_OPEN_TUP
 *             elif next_char == b'}':
 */
        break;
      case '}':

      /* "srctools/_tokenizer.pyx":589
 *                 return BRACE_OPEN_TUP
 *             elif next_char == b'}':
 *                 return BRACE_CLOSE_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == b'+':
 *                 return PLUS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":588
 *             elif next_char == b'{':
 *                 return BRACE_OPEN_TUP
 *             elif next_char == b'}':             # <<<<<<<<<<<<<<
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == b'+':
 */
      break;
      case '+':

      /* "srctools/_tokenizer.pyx":591
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == b'+':
 *                 return PLUS_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == b'=':
 *                 return EQUALS_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_PLUS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":590
 *             elif next_char == b'}':
 *                 return BRACE_CLOSE_TUP
 *             elif next_char == b'+':             # <<<<<<<<<<<<<<
 *                 return PLUS_TUP
 *             elif next_char == b'=':
 */
      break;
      case '=':

      /* "srctools/_tokenizer.pyx":593
 *                 return PLUS_TUP
 *             elif next_char == b'=':
 *                 return EQUALS_TUP             # <<<<<<<<<<<<<<
 *             elif next_char == b',':
 *                 return COMMA_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EQUALS_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":592
 *             elif next_char == b'+':
 *                 return PLUS_TUP
 *             elif next_char == b'=':             # <<<<<<<<<<<<<<
 *                 return EQUALS_TUP
 *             elif next_char == b',':
 */
      break;
      case ',':

      /* "srctools/_tokenizer.pyx":595
 *                 return EQUALS_TUP
 *             elif next_char == b',':
 *                 return COMMA_TUP             # <<<<<<<<<<<<<<
 *             # First try simple operators & EOF.
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_COMMA_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_COMMA_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":594
 *             elif next_char == b'=':
 *                 return EQUALS_TUP
 *             elif next_char == b',':             # <<<<<<<<<<<<<<
 *                 return COMMA_TUP
 *             # First try simple operators & EOF.
 */
      break;
      case '\n':

      /* "srctools/_tokenizer.pyx":599
 * 
 *             elif next_char == b'\n':
 *                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                 return NEWLINE_TUP
 * 
 */
      __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

      /* "srctools/_tokenizer.pyx":600
 *             elif next_char == b'\n':
 *                 self.line_num += 1
 *                 return NEWLINE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char in b' \t':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":598
 *             # First try simple operators & EOF.
 * 
 *             elif next_char == b'\n':             # <<<<<<<<<<<<<<
 *                 self.line_num += 1
 *                 return NEWLINE_TUP
 */
      break;
      case '\t':

      /* "srctools/_tokenizer.pyx":602
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in b' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      case ' ':

      /* "srctools/_tokenizer.pyx":604
 *             elif next_char in b' \t':
 *                 # Ignore whitespace..
 *                 continue             # <<<<<<<<<<<<<<
 * 
 *             # Comments
 */
      goto __pyx_L4_continue;

      /* "srctools/_tokenizer.pyx":602
 *                 return NEWLINE_TUP
 * 
 *             elif next_char in b' \t':             # <<<<<<<<<<<<<<
 *                 # Ignore whitespace..
 *                 continue
 */
      break;
      case '/':

      /* "srctools/_tokenizer.pyx":609
 *             elif next_char == b'/':
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:
 */
      __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 609, __pyx_L1_error)
      __pyx_v_next_char = __pyx_t_4;

      /* "srctools/_tokenizer.pyx":610
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:
 *                         start_line = self.line_num
 */
      switch (__pyx_v_next_char) {
        case '*':

        /* "srctools/_tokenizer.pyx":611
 *                 next_char = self._next_char()
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
        __pyx_t_2 = ((__pyx_v_self->__pyx_base.flags & 4) != 0);
        if (likely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":612
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:
 *                         start_line = self.line_num             # <<<<<<<<<<<<<<
 *                         while True:
 *                             next_char = self._next_char()
 */
          __pyx_t_5 = __pyx_v_self->__pyx_base.line_num;
          __pyx_v_start_line = __pyx_t_5;

          /* "srctools/_tokenizer.pyx":613
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:
 *                         start_line = self.line_num
 *                         while True:             # <<<<<<<<<<<<<<
 *                             next_char = self._next_char()
 *                             if next_char == CHR_EOF:
 */
          while (1) {

            /* "srctools/_tokenizer.pyx":614
 *                         start_line = self.line_num
 *                         while True:
 *                             next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                             if next_char == CHR_EOF:
 *                                 raise self._error(
 */
            __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 614, __pyx_L1_error)
            __pyx_v_next_char = __pyx_t_4;

            /* "srctools/_tokenizer.pyx":615
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
            switch (__pyx_v_next_char) {
              case 3:

              /* "srctools/_tokenizer.pyx":617
 *                             if next_char == CHR_EOF:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 617, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __pyx_t_6 = 0;
              __pyx_t_7 = 127;
              __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              __pyx_t_6 += 38;
              __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
              PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

              /* "srctools/_tokenizer.pyx":618
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                 )
 *                             elif next_char == b'\n':
 */
              __pyx_t_8 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 618, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_8);
              __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_8);
              __Pyx_GIVEREF(__pyx_t_8);
              PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
              __pyx_t_8 = 0;
              __Pyx_INCREF(__pyx_kp_u__5);
              __pyx_t_6 += 2;
              __Pyx_GIVEREF(__pyx_kp_u__5);
              PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__5);

              /* "srctools/_tokenizer.pyx":617
 *                             if next_char == CHR_EOF:
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                     f'(starting on line {start_line})!',
 *                                 )
 */
              __pyx_t_8 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 617, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_8);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

              /* "srctools/_tokenizer.pyx":616
 *                             next_char = self._next_char()
 *                             if next_char == CHR_EOF:
 *                                 raise self._error(             # <<<<<<<<<<<<<<
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                     f'(starting on line {start_line})!',
 */
              __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_8)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 616, __pyx_L1_error)
              __Pyx_GOTREF(__pyx_t_3);
              __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
              __Pyx_Raise(__pyx_t_3, 0, 0, 0);
              __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
              __PYX_ERR(0, 616, __pyx_L1_error)

              /* "srctools/_tokenizer.pyx":615
 *                         while True:
 *                             next_char = self._next_char()
 *                             if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                                 raise self._error(
 *                                     f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              break;
              case '\n':

              /* "srctools/_tokenizer.pyx":621
 *                                 )
 *                             elif next_char == b'\n':
 *                                 self.line_num += 1             # <<<<<<<<<<<<<<
 *                             elif next_char == b'*':
 *                                 # Check next next character!
 */
              __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

              /* "srctools/_tokenizer.pyx":620
 *                                     f'(starting on line {start_line})!',
 *                                 )
 *                             elif next_char == b'\n':             # <<<<<<<<<<<<<<
 *                                 self.line_num += 1
 *                             elif next_char == b'*':
 */
              break;
              case '*':

              /* "srctools/_tokenizer.pyx":624
 *                             elif next_char == b'*':
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()             # <<<<<<<<<<<<<<
 *                                 if peek_char == CHR_EOF:
 *                                     raise self._error(
 */
              __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 624, __pyx_L1_error)
              __pyx_v_peek_char = __pyx_t_4;

              /* "srctools/_tokenizer.pyx":625
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
              switch (__pyx_v_peek_char) {
                case 3:

                /* "srctools/_tokenizer.pyx":627
 *                                 if peek_char == CHR_EOF:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 627, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __pyx_t_6 = 0;
                __pyx_t_7 = 127;
                __Pyx_INCREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                __pyx_t_6 += 38;
                __Pyx_GIVEREF(__pyx_kp_u_Unclosed_comment_starting_on_lin);
                PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed_comment_starting_on_lin);

                /* "srctools/_tokenizer.pyx":628
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',             # <<<<<<<<<<<<<<
 *                                     )
 *                                 elif peek_char == b'/':
 */
                __pyx_t_8 = __Pyx_PyUnicode_From_int(__pyx_v_start_line, 0, ' ', 'd'); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 628, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_8);
                __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_8);
                __Pyx_GIVEREF(__pyx_t_8);
                PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
                __pyx_t_8 = 0;
                __Pyx_INCREF(__pyx_kp_u__5);
                __pyx_t_6 += 2;
                __Pyx_GIVEREF(__pyx_kp_u__5);
                PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__5);

                /* "srctools/_tokenizer.pyx":627
 *                                 if peek_char == CHR_EOF:
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '             # <<<<<<<<<<<<<<
 *                                         f'(starting on line {start_line})!',
 *                                     )
 */
                __pyx_t_8 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 627, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_8);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

                /* "srctools/_tokenizer.pyx":626
 *                                 peek_char = self._next_char()
 *                                 if peek_char == CHR_EOF:
 *                                     raise self._error(             # <<<<<<<<<<<<<<
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 *                                         f'(starting on line {start_line})!',
 */
                __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_8)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 626, __pyx_L1_error)
                __Pyx_GOTREF(__pyx_t_3);
                __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
                __Pyx_Raise(__pyx_t_3, 0, 0, 0);
                __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
                __PYX_ERR(0, 626, __pyx_L1_error)

                /* "srctools/_tokenizer.pyx":625
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 *                                 if peek_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                                     raise self._error(
 *                                         f'Unclosed /[inserted by cython to avoid comment start]* comment '
 */
                break;
                case '/':

                /* "srctools/_tokenizer.pyx":631
 *                                     )
 *                                 elif peek_char == b'/':
 *                                     break             # <<<<<<<<<<<<<<
 *                                 else:
 *                                     # We need to reparse this, to ensure
 */
                goto __pyx_L8_break;

                /* "srctools/_tokenizer.pyx":630
 *                                         f'(starting on line {start_line})!',
 *                                     )
 *                                 elif peek_char == b'/':             # <<<<<<<<<<<<<<
 *                                     break
 *                                 else:
 */
                break;
                default:

                /* "srctools/_tokenizer.pyx":635
 *                                     # We need to reparse this, to ensure
 *                                     # "**[inserted by cython to avoid comment closer]/" parses correctly!
 *                                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                     else:
 *                         raise self._error(
 */
                __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);
                break;
              }

              /* "srctools/_tokenizer.pyx":622
 *                             elif next_char == b'\n':
 *                                 self.line_num += 1
 *                             elif next_char == b'*':             # <<<<<<<<<<<<<<
 *                                 # Check next next character!
 *                                 peek_char = self._next_char()
 */
              break;
              default: break;
            }
          }
          __pyx_L8_break:;

          /* "srctools/_tokenizer.pyx":611
 *                 next_char = self._next_char()
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:             # <<<<<<<<<<<<<<
 *                         start_line = self.line_num
 *                         while True:
 */
          goto __pyx_L6;
        }

        /* "srctools/_tokenizer.pyx":637
 *                                     self.char_index -= 1
 *                     else:
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 */
        /*else*/ {
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_style_comments_are_not_allowed); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 637, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 637, __pyx_L1_error)
        }
        __pyx_L6:;

        /* "srctools/_tokenizer.pyx":610
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 *                 if next_char == b'*': # /[inserted by cython to avoid comment start]* comment.             # <<<<<<<<<<<<<<
 *                     if self.flags & FL_ALLOW_STAR_COMMENTS:
 *                         start_line = self.line_num
 */
        break;
        case '/':

        /* "srctools/_tokenizer.pyx":642
 *                 elif next_char == b'/':
 *                     # Skip to end of line
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF or next_char == b'\n':
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":643
 *                     # Skip to end of line
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == CHR_EOF or next_char == b'\n':
 *                             break
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 643, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":644
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF or next_char == b'\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
          switch (__pyx_v_next_char) {
            case 3:
            case '\n':

            /* "srctools/_tokenizer.pyx":645
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF or next_char == b'\n':
 *                             break             # <<<<<<<<<<<<<<
 * 
 *                     # We want to produce the token for the end character -
 */
            goto __pyx_L10_break;

            /* "srctools/_tokenizer.pyx":644
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF or next_char == b'\n':             # <<<<<<<<<<<<<<
 *                             break
 * 
 */
            break;
            default: break;
          }
        }
        __pyx_L10_break:;

        /* "srctools/_tokenizer.pyx":649
 *                     # We want to produce the token for the end character -
 *                     # EOF or NEWLINE.
 *                     self.char_index -= 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise self._error(
 */
        __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

        /* "srctools/_tokenizer.pyx":640
 *                             '/[inserted by cython to avoid comment start]**[inserted by cython to avoid comment closer]/-style comments are not allowed!'
 *                         )
 *                 elif next_char == b'/':             # <<<<<<<<<<<<<<
 *                     # Skip to end of line
 *                     while True:
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":654
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 *                         if self.flags & FL_ALLOW_STAR_COMMENTS else             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (//)!'
 */
        if (((__pyx_v_self->__pyx_base.flags & 4) != 0)) {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw;
        } else {
          __Pyx_INCREF(__pyx_kp_u_Single_slash_found_instead_of_tw_2);
          __pyx_t_3 = __pyx_kp_u_Single_slash_found_instead_of_tw_2;
        }

        /* "srctools/_tokenizer.pyx":651
 *                     self.char_index -= 1
 *                 else:
 *                     raise self._error(             # <<<<<<<<<<<<<<
 *                         'Single slash found, '
 *                         'instead of two for a comment (// or /[inserted by cython to avoid comment start]* *[inserted by cython to avoid comment closer]/)!'
 */
        __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 651, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_Raise(__pyx_t_8, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __PYX_ERR(0, 651, __pyx_L1_error)
        break;
      }

      /* "srctools/_tokenizer.pyx":607
 * 
 *             # Comments
 *             elif next_char == b'/':             # <<<<<<<<<<<<<<
 *                 # The next must be another slash! (//)
 *                 next_char = self._next_char()
 */
      break;
      case '"':

      /* "srctools/_tokenizer.pyx":661
 *             # Strings
 *             elif next_char == b'"':
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":662
 *             elif next_char == b'"':
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":663
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated string!')
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 663, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":664
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == b'"':
 */
        __pyx_t_2 = ((__pyx_v_next_char == 3) != 0);
        if (unlikely(__pyx_t_2)) {

          /* "srctools/_tokenizer.pyx":665
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 *                     elif next_char == b'"':
 *                         return STRING, self.buf_get_text()
 */
          __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 665, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_Raise(__pyx_t_8, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __PYX_ERR(0, 665, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":664
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == b'"':
 */
        }

        /* "srctools/_tokenizer.pyx":666
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == b'"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == b'\n':
 */
        __pyx_t_2 = ((__pyx_v_next_char == '"') != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":667
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == b'"':
 *                         return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == b'\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_8 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 667, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 667, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_STRING);
          __Pyx_GIVEREF(__pyx_t_8);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
          __pyx_t_8 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":666
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated string!')
 *                     elif next_char == b'"':             # <<<<<<<<<<<<<<
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == b'\n':
 */
        }

        /* "srctools/_tokenizer.pyx":668
 *                     elif next_char == b'"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == b'\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:
 */
        __pyx_t_2 = ((__pyx_v_next_char == '\n') != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":669
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == b'\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:
 *                         # Escape text
 */
          __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

          /* "srctools/_tokenizer.pyx":668
 *                     elif next_char == b'"':
 *                         return STRING, self.buf_get_text()
 *                     elif next_char == b'\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:
 */
          goto __pyx_L13;
        }

        /* "srctools/_tokenizer.pyx":670
 *                     elif next_char == b'\n':
 *                         self.line_num += 1
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        __pyx_t_1 = ((__pyx_v_next_char == '\\') != 0);
        if (__pyx_t_1) {
        } else {
          __pyx_t_2 = __pyx_t_1;
          goto __pyx_L14_bool_binop_done;
        }
        __pyx_t_1 = ((__pyx_v_self->__pyx_base.flags & 2) != 0);
        __pyx_t_2 = __pyx_t_1;
        __pyx_L14_bool_binop_done:;
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":672
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:
 *                         # Escape text
 *                         escape_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if escape_char == CHR_EOF:
 *                             raise self._error('Unterminated string!')
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 672, __pyx_L1_error)
          __pyx_v_escape_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":673
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          __pyx_t_2 = ((__pyx_v_escape_char == 3) != 0);
          if (unlikely(__pyx_t_2)) {

            /* "srctools/_tokenizer.pyx":674
 *                         escape_char = self._next_char()
 *                         if escape_char == CHR_EOF:
 *                             raise self._error('Unterminated string!')             # <<<<<<<<<<<<<<
 * 
 *                         if escape_char == b'n':
 */
            __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_string); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 674, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_Raise(__pyx_t_3, 0, 0, 0);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __PYX_ERR(0, 674, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":673
 *                         # Escape text
 *                         escape_char = self._next_char()
 *                         if escape_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                             raise self._error('Unterminated string!')
 * 
 */
          }

          /* "srctools/_tokenizer.pyx":676
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == b'n':             # <<<<<<<<<<<<<<
 *                             next_char = b'\n'
 *                         elif escape_char == b't':
 */
          switch (__pyx_v_escape_char) {
            case 'n':

            /* "srctools/_tokenizer.pyx":677
 * 
 *                         if escape_char == b'n':
 *                             next_char = b'\n'             # <<<<<<<<<<<<<<
 *                         elif escape_char == b't':
 *                             next_char = b'\t'
 */
            __pyx_v_next_char = '\n';

            /* "srctools/_tokenizer.pyx":676
 *                             raise self._error('Unterminated string!')
 * 
 *                         if escape_char == b'n':             # <<<<<<<<<<<<<<
 *                             next_char = b'\n'
 *                         elif escape_char == b't':
 */
            break;
            case 't':

            /* "srctools/_tokenizer.pyx":679
 *                             next_char = b'\n'
 *                         elif escape_char == b't':
 *                             next_char = b'\t'             # <<<<<<<<<<<<<<
 *                         elif escape_char == b'\n':
 *                             # \ at end of line ignores the newline.
 */
            __pyx_v_next_char = '\t';

            /* "srctools/_tokenizer.pyx":678
 *                         if escape_char == b'n':
 *                             next_char = b'\n'
 *                         elif escape_char == b't':             # <<<<<<<<<<<<<<
 *                             next_char = b'\t'
 *                         elif escape_char == b'\n':
 */
            break;
            case '\n':

            /* "srctools/_tokenizer.pyx":682
 *                         elif escape_char == b'\n':
 *                             # \ at end of line ignores the newline.
 *                             continue             # <<<<<<<<<<<<<<
 *                         elif escape_char in (b'"', b'\\', b'/'):
 *                             # For these, we escape to give the literal value.
 */
            goto __pyx_L11_continue;

            /* "srctools/_tokenizer.pyx":680
 *                         elif escape_char == b't':
 *                             next_char = b'\t'
 *                         elif escape_char == b'\n':             # <<<<<<<<<<<<<<
 *                             # \ at end of line ignores the newline.
 *                             continue
 */
            break;
            case '"':

            /* "srctools/_tokenizer.pyx":683
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in (b'"', b'\\', b'/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            case '\\':
            case '/':

            /* "srctools/_tokenizer.pyx":685
 *                         elif escape_char in (b'"', b'\\', b'/'):
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char             # <<<<<<<<<<<<<<
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 */
            __pyx_v_next_char = __pyx_v_escape_char;

            /* "srctools/_tokenizer.pyx":683
 *                             # \ at end of line ignores the newline.
 *                             continue
 *                         elif escape_char in (b'"', b'\\', b'/'):             # <<<<<<<<<<<<<<
 *                             # For these, we escape to give the literal value.
 *                             next_char = escape_char
 */
            break;
            default:

            /* "srctools/_tokenizer.pyx":688
 *                         else:
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char(b'\\')             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(escape_char)
 *                             continue
 */
            __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, '\\'); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 688, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":689
 *                             # For unknown escape_chars, escape the \ automatically.
 *                             self.buf_add_char(b'\\')
 *                             self.buf_add_char(escape_char)             # <<<<<<<<<<<<<<
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 */
            __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_escape_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 689, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":690
 *                             self.buf_add_char(b'\\')
 *                             self.buf_add_char(escape_char)
 *                             continue             # <<<<<<<<<<<<<<
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)
 */
            goto __pyx_L11_continue;
            break;
          }

          /* "srctools/_tokenizer.pyx":670
 *                     elif next_char == b'\n':
 *                         self.line_num += 1
 *                     elif next_char == b'\\' and self.flags & FL_ALLOW_ESCAPES:             # <<<<<<<<<<<<<<
 *                         # Escape text
 *                         escape_char = self._next_char()
 */
        }
        __pyx_L13:;

        /* "srctools/_tokenizer.pyx":692
 *                             continue
 *                             # raise self.error('Unknown escape_char "\\{}" in {}!', escape_char, self.cur_chunk)
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == b'[':
 */
        __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 692, __pyx_L1_error)
        __pyx_L11_continue:;
      }

      /* "srctools/_tokenizer.pyx":660
 * 
 *             # Strings
 *             elif next_char == b'"':             # <<<<<<<<<<<<<<
 *                 self.buf_reset()
 *                 while True:
 */
      break;
      case '[':

      /* "srctools/_tokenizer.pyx":696
 *             elif next_char == b'[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.flags & FL_STRING_BRACKETS:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      __pyx_t_2 = ((!((__pyx_v_self->__pyx_base.flags & 1) != 0)) != 0);
      if (__pyx_t_2) {

        /* "srctools/_tokenizer.pyx":697
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.flags & FL_STRING_BRACKETS:
 *                     return BRACK_OPEN_TUP             # <<<<<<<<<<<<<<
 * 
 *                 self.buf_reset()
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
        __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":696
 *             elif next_char == b'[':
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.flags & FL_STRING_BRACKETS:             # <<<<<<<<<<<<<<
 *                     return BRACK_OPEN_TUP
 * 
 */
      }

      /* "srctools/_tokenizer.pyx":699
 *                     return BRACK_OPEN_TUP
 * 
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":700
 * 
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == b'[':
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":701
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == b'[':
 *                         # Don't allow nesting, that's bad.
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 701, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":702
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == b'[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
        switch (__pyx_v_next_char) {
          case '[':

          /* "srctools/_tokenizer.pyx":704
 *                     if next_char == b'[':
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == b']':
 *                         return PROP_FLAG, self.buf_get_text()
 */
          __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Cannot_nest_brackets); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 704, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 704, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":702
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == b'[':             # <<<<<<<<<<<<<<
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 */
          break;
          case ']':

          /* "srctools/_tokenizer.pyx":706
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == b']':
 *                         return PROP_FLAG, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     # Must be one line!
 *                     elif next_char == CHR_EOF or next_char == b'\n':
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 706, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_8srctools_10_tokenizer_PROP_FLAG);
          __Pyx_GIVEREF(__pyx_t_3);
          PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_3);
          __pyx_t_3 = 0;
          __pyx_r = __pyx_t_8;
          __pyx_t_8 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":705
 *                         # Don't allow nesting, that's bad.
 *                         raise self._error('Cannot nest [] brackets!')
 *                     elif next_char == b']':             # <<<<<<<<<<<<<<
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 */
          break;
          case 3:

          /* "srctools/_tokenizer.pyx":708
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == CHR_EOF or next_char == b'\n':             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          case '\n':

          /* "srctools/_tokenizer.pyx":709
 *                     # Must be one line!
 *                     elif next_char == CHR_EOF or next_char == b'\n':
 *                         raise self._error(             # <<<<<<<<<<<<<<
 *                             'Reached end of line '
 *                             'without closing "]"!'
 */
          __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Reached_end_of_line_without_clos); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 709, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_Raise(__pyx_t_8, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __PYX_ERR(0, 709, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":708
 *                         return PROP_FLAG, self.buf_get_text()
 *                     # Must be one line!
 *                     elif next_char == CHR_EOF or next_char == b'\n':             # <<<<<<<<<<<<<<
 *                         raise self._error(
 *                             'Reached end of line '
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":713
 *                             'without closing "]"!'
 *                         )
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == b']':
 */
        __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 713, __pyx_L1_error)
      }

      /* "srctools/_tokenizer.pyx":694
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == b'[':             # <<<<<<<<<<<<<<
 *                 # FGDs use [] for grouping, Properties use it for flags.
 *                 if not self.flags & FL_STRING_BRACKETS:
 */
      break;
      case ']':

      /* "srctools/_tokenizer.pyx":716
 * 
 *             elif next_char == b']':
 *                 if self.flags & FL_STRING_BRACKETS:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      __pyx_t_2 = ((__pyx_v_self->__pyx_base.flags & 1) != 0);
      if (unlikely(__pyx_t_2)) {

        /* "srctools/_tokenizer.pyx":719
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')             # <<<<<<<<<<<<<<
 *                 return BRACK_CLOSE_TUP
 * 
 */
        __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_No_open_to_close_with); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 719, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_Raise(__pyx_t_8, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __PYX_ERR(0, 719, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":716
 * 
 *             elif next_char == b']':
 *                 if self.flags & FL_STRING_BRACKETS:             # <<<<<<<<<<<<<<
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 *                     # syntax error - we don't have an open one to close!
 */
      }

      /* "srctools/_tokenizer.pyx":720
 *                     # syntax error - we don't have an open one to close!
 *                     raise self._error('No open [] to close with "]"!')
 *                 return BRACK_CLOSE_TUP             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == b'(':
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":715
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == b']':             # <<<<<<<<<<<<<<
 *                 if self.flags & FL_STRING_BRACKETS:
 *                     # If string_bracket is set (using PROP_FLAG), this is a
 */
      break;
      case '(':

      /* "srctools/_tokenizer.pyx":724
 *             elif next_char == b'(':
 *                 # Parentheses around text...
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":725
 *                 # Parentheses around text...
 *                 self.buf_reset()
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":726
 *                 self.buf_reset()
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated parentheses!')
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 726, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":727
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == b'(':
 */
        switch (__pyx_v_next_char) {
          case 3:

          /* "srctools/_tokenizer.pyx":728
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated parentheses!')             # <<<<<<<<<<<<<<
 *                     elif next_char == b'(':
 *                         raise self._error('Cannot nest () brackets!')
 */
          __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Unterminated_parentheses); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 728, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_Raise(__pyx_t_8, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __PYX_ERR(0, 728, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":727
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == b'(':
 */
          break;
          case '(':

          /* "srctools/_tokenizer.pyx":730
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == b'(':
 *                         raise self._error('Cannot nest () brackets!')             # <<<<<<<<<<<<<<
 *                     elif next_char == b')':
 *                         return PAREN_ARGS, self.buf_get_text()
 */
          __pyx_t_8 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_Cannot_nest_brackets_2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 730, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_Raise(__pyx_t_8, 0, 0, 0);
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __PYX_ERR(0, 730, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":729
 *                     if next_char == CHR_EOF:
 *                         raise self._error('Unterminated parentheses!')
 *                     elif next_char == b'(':             # <<<<<<<<<<<<<<
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == b')':
 */
          break;
          case ')':

          /* "srctools/_tokenizer.pyx":732
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == b')':
 *                         return PAREN_ARGS, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                     elif next_char == b'\n':
 *                         self.line_num += 1
 */
          __Pyx_XDECREF(__pyx_r);
          __pyx_t_8 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 732, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
          __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 732, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
          __Pyx_GIVEREF(__pyx_t_8);
          PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
          __pyx_t_8 = 0;
          __pyx_r = __pyx_t_3;
          __pyx_t_3 = 0;
          goto __pyx_L0;

          /* "srctools/_tokenizer.pyx":731
 *                     elif next_char == b'(':
 *                         raise self._error('Cannot nest () brackets!')
 *                     elif next_char == b')':             # <<<<<<<<<<<<<<
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == b'\n':
 */
          break;
          case '\n':

          /* "srctools/_tokenizer.pyx":734
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == b'\n':
 *                         self.line_num += 1             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 * 
 */
          __pyx_v_self->__pyx_base.line_num = (__pyx_v_self->__pyx_base.line_num + 1);

          /* "srctools/_tokenizer.pyx":733
 *                     elif next_char == b')':
 *                         return PAREN_ARGS, self.buf_get_text()
 *                     elif next_char == b'\n':             # <<<<<<<<<<<<<<
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)
 */
          break;
          default: break;
        }

        /* "srctools/_tokenizer.pyx":735
 *                     elif next_char == b'\n':
 *                         self.line_num += 1
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             elif next_char == b')':
 */
        __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 735, __pyx_L1_error)
      }

      /* "srctools/_tokenizer.pyx":722
 *                 return BRACK_CLOSE_TUP
 * 
 *             elif next_char == b'(':             # <<<<<<<<<<<<<<
 *                 # Parentheses around text...
 *                 self.buf_reset()
 */
      break;
      case ')':

      /* "srctools/_tokenizer.pyx":738
 * 
 *             elif next_char == b')':
 *                 raise self._error('No open () to close with ")"!')             # <<<<<<<<<<<<<<
 * 
 *             # Directives
 */
      __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), __pyx_kp_u_No_open_to_close_with_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 738, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 738, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":737
 *                     self.buf_add_char(next_char)
 * 
 *             elif next_char == b')':             # <<<<<<<<<<<<<<
 *                 raise self._error('No open () to close with ")"!')
 * 
 */
      break;
      case '#':

      /* "srctools/_tokenizer.pyx":742
 *             # Directives
 *             elif next_char == b'#':
 *                 self.buf_reset()             # <<<<<<<<<<<<<<
 *                 ascii_only = True
 *                 while True:
 */
      __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

      /* "srctools/_tokenizer.pyx":743
 *             elif next_char == b'#':
 *                 self.buf_reset()
 *                 ascii_only = True             # <<<<<<<<<<<<<<
 *                 while True:
 *                     next_char = self._next_char()
 */
      __pyx_v_ascii_only = 1;

      /* "srctools/_tokenizer.pyx":744
 *                 self.buf_reset()
 *                 ascii_only = True
 *                 while True:             # <<<<<<<<<<<<<<
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:
 */
      while (1) {

        /* "srctools/_tokenizer.pyx":745
 *                 ascii_only = True
 *                 while True:
 *                     next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                     if next_char == CHR_EOF:
 *                         # A directive could be the last value in the file.
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 745, __pyx_L1_error)
        __pyx_v_next_char = __pyx_t_4;

        /* "srctools/_tokenizer.pyx":746
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         # A directive could be the last value in the file.
 *                         if ascii_only:
 */
        __pyx_t_2 = ((__pyx_v_next_char == 3) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":748
 *                     if next_char == CHR_EOF:
 *                         # A directive could be the last value in the file.
 *                         if ascii_only:             # <<<<<<<<<<<<<<
 *                             return DIRECTIVE, self.buf_get_text()
 *                         else:
 */
          __pyx_t_2 = (__pyx_v_ascii_only != 0);
          if (__pyx_t_2) {

            /* "srctools/_tokenizer.pyx":749
 *                         # A directive could be the last value in the file.
 *                         if ascii_only:
 *                             return DIRECTIVE, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                         else:
 *                             return DIRECTIVE, self.buf_get_text().casefold()
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 749, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 749, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_t_3);
            PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_3);
            __pyx_t_3 = 0;
            __pyx_r = __pyx_t_8;
            __pyx_t_8 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":748
 *                     if next_char == CHR_EOF:
 *                         # A directive could be the last value in the file.
 *                         if ascii_only:             # <<<<<<<<<<<<<<
 *                             return DIRECTIVE, self.buf_get_text()
 *                         else:
 */
          }

          /* "srctools/_tokenizer.pyx":751
 *                             return DIRECTIVE, self.buf_get_text()
 *                         else:
 *                             return DIRECTIVE, self.buf_get_text().casefold()             # <<<<<<<<<<<<<<
 * 
 *                     elif (
 */
          /*else*/ {
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 751, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_casefold); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 751, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_9);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __pyx_t_3 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_9))) {
              __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_9);
              if (likely(__pyx_t_3)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_9);
                __Pyx_INCREF(__pyx_t_3);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_9, function);
              }
            }
            __pyx_t_8 = (__pyx_t_3) ? __Pyx_PyObject_CallOneArg(__pyx_t_9, __pyx_t_3) : __Pyx_PyObject_CallNoArg(__pyx_t_9);
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 751, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
            __pyx_t_9 = PyTuple_New(2); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 751, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_9);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_t_8);
            PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_8);
            __pyx_t_8 = 0;
            __pyx_r = __pyx_t_9;
            __pyx_t_9 = 0;
            goto __pyx_L0;
          }

          /* "srctools/_tokenizer.pyx":746
 *                 while True:
 *                     next_char = self._next_char()
 *                     if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                         # A directive could be the last value in the file.
 *                         if ascii_only:
 */
        }

        /* "srctools/_tokenizer.pyx":754
 * 
 *                     elif (
 *                         next_char in BARE_DISALLOWED or             # <<<<<<<<<<<<<<
 *                         (next_char == b':' and self.flags & FL_COLON_OPERATOR)
 *                     ):
 */
        switch (__pyx_v_next_char) {
          case '\t':
          case '\n':
          case ' ':
          case '"':
          case '\'':
          case '(':
          case ')':
          case ',':
          case ';':
          case '[':
          case ']':
          case '{':
          case '}':
          __pyx_t_1 = 1;
          break;
          default:
          __pyx_t_1 = 0;
          break;
        }
        __pyx_t_10 = (__pyx_t_1 != 0);
        if (!__pyx_t_10) {
        } else {
          __pyx_t_2 = __pyx_t_10;
          goto __pyx_L27_bool_binop_done;
        }

        /* "srctools/_tokenizer.pyx":755
 *                     elif (
 *                         next_char in BARE_DISALLOWED or
 *                         (next_char == b':' and self.flags & FL_COLON_OPERATOR)             # <<<<<<<<<<<<<<
 *                     ):
 *                         # We need to repeat this so we return the ending
 */
        __pyx_t_10 = ((__pyx_v_next_char == ':') != 0);
        if (__pyx_t_10) {
        } else {
          __pyx_t_2 = __pyx_t_10;
          goto __pyx_L27_bool_binop_done;
        }
        __pyx_t_10 = ((__pyx_v_self->__pyx_base.flags & 8) != 0);
        __pyx_t_2 = __pyx_t_10;
        __pyx_L27_bool_binop_done:;

        /* "srctools/_tokenizer.pyx":753
 *                             return DIRECTIVE, self.buf_get_text().casefold()
 * 
 *                     elif (             # <<<<<<<<<<<<<<
 *                         next_char in BARE_DISALLOWED or
 *                         (next_char == b':' and self.flags & FL_COLON_OPERATOR)
 */
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":760
 *                         # char next. If it's not allowed, that'll error on
 *                         # next call.
 *                         self.char_index -= 1             # <<<<<<<<<<<<<<
 *                         # And return the directive.
 *                         if ascii_only:
 */
          __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

          /* "srctools/_tokenizer.pyx":762
 *                         self.char_index -= 1
 *                         # And return the directive.
 *                         if ascii_only:             # <<<<<<<<<<<<<<
 *                             return DIRECTIVE, self.buf_get_text()
 *                         else:
 */
          __pyx_t_2 = (__pyx_v_ascii_only != 0);
          if (__pyx_t_2) {

            /* "srctools/_tokenizer.pyx":763
 *                         # And return the directive.
 *                         if ascii_only:
 *                             return DIRECTIVE, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                         else:
 *                             # Have to go through Unicode lowering.
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_9 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 763, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_9);
            __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 763, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_t_9);
            PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_9);
            __pyx_t_9 = 0;
            __pyx_r = __pyx_t_8;
            __pyx_t_8 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":762
 *                         self.char_index -= 1
 *                         # And return the directive.
 *                         if ascii_only:             # <<<<<<<<<<<<<<
 *                             return DIRECTIVE, self.buf_get_text()
 *                         else:
 */
          }

          /* "srctools/_tokenizer.pyx":766
 *                         else:
 *                             # Have to go through Unicode lowering.
 *                             return DIRECTIVE, self.buf_get_text().casefold()             # <<<<<<<<<<<<<<
 *                     elif next_char >= 128:
 *                         # This is non-ASCII, run through the full
 */
          /*else*/ {
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_9 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 766, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_9);
            __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_9, __pyx_n_s_casefold); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 766, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
            __pyx_t_9 = NULL;
            if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
              __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_3);
              if (likely(__pyx_t_9)) {
                PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
                __Pyx_INCREF(__pyx_t_9);
                __Pyx_INCREF(function);
                __Pyx_DECREF_SET(__pyx_t_3, function);
              }
            }
            __pyx_t_8 = (__pyx_t_9) ? __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_9) : __Pyx_PyObject_CallNoArg(__pyx_t_3);
            __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
            if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 766, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
            __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 766, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_DIRECTIVE);
            __Pyx_GIVEREF(__pyx_t_8);
            PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
            __pyx_t_8 = 0;
            __pyx_r = __pyx_t_3;
            __pyx_t_3 = 0;
            goto __pyx_L0;
          }

          /* "srctools/_tokenizer.pyx":753
 *                             return DIRECTIVE, self.buf_get_text().casefold()
 * 
 *                     elif (             # <<<<<<<<<<<<<<
 *                         next_char in BARE_DISALLOWED or
 *                         (next_char == b':' and self.flags & FL_COLON_OPERATOR)
 */
        }

        /* "srctools/_tokenizer.pyx":767
 *                             # Have to go through Unicode lowering.
 *                             return DIRECTIVE, self.buf_get_text().casefold()
 *                     elif next_char >= 128:             # <<<<<<<<<<<<<<
 *                         # This is non-ASCII, run through the full
 *                         # Unicode-compliant conversion.
 */
        __pyx_t_2 = ((__pyx_v_next_char >= 0x80) != 0);
        if (__pyx_t_2) {

          /* "srctools/_tokenizer.pyx":770
 *                         # This is non-ASCII, run through the full
 *                         # Unicode-compliant conversion.
 *                         ascii_only = False             # <<<<<<<<<<<<<<
 *                         self.buf_add_char(next_char)
 *                     else:
 */
          __pyx_v_ascii_only = 0;

          /* "srctools/_tokenizer.pyx":771
 *                         # Unicode-compliant conversion.
 *                         ascii_only = False
 *                         self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                     else:
 *                         # If ASCII, use bit math to convert over.
 */
          __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 771, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":767
 *                             # Have to go through Unicode lowering.
 *                             return DIRECTIVE, self.buf_get_text().casefold()
 *                     elif next_char >= 128:             # <<<<<<<<<<<<<<
 *                         # This is non-ASCII, run through the full
 *                         # Unicode-compliant conversion.
 */
          goto __pyx_L25;
        }

        /* "srctools/_tokenizer.pyx":774
 *                     else:
 *                         # If ASCII, use bit math to convert over.
 *                         if b'A' <= next_char <= b'Z':             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(next_char + 0x20)
 *                         else:
 */
        /*else*/ {
          __pyx_t_2 = ('A' <= __pyx_v_next_char);
          if (__pyx_t_2) {
            __pyx_t_2 = (__pyx_v_next_char <= 'Z');
          }
          __pyx_t_10 = (__pyx_t_2 != 0);
          if (__pyx_t_10) {

            /* "srctools/_tokenizer.pyx":775
 *                         # If ASCII, use bit math to convert over.
 *                         if b'A' <= next_char <= b'Z':
 *                             self.buf_add_char(next_char + 0x20)             # <<<<<<<<<<<<<<
 *                         else:
 *                             self.buf_add_char(next_char)
 */
            __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, (__pyx_v_next_char + 0x20)); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 775, __pyx_L1_error)

            /* "srctools/_tokenizer.pyx":774
 *                     else:
 *                         # If ASCII, use bit math to convert over.
 *                         if b'A' <= next_char <= b'Z':             # <<<<<<<<<<<<<<
 *                             self.buf_add_char(next_char + 0x20)
 *                         else:
 */
            goto __pyx_L31;
          }

          /* "srctools/_tokenizer.pyx":777
 *                             self.buf_add_char(next_char + 0x20)
 *                         else:
 *                             self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 * 
 *             else:  # These complex checks can't be in a switch, so we need to nest this.
 */
          /*else*/ {
            __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 777, __pyx_L1_error)
          }
          __pyx_L31:;
        }
        __pyx_L25:;
      }

      /* "srctools/_tokenizer.pyx":741
 * 
 *             # Directives
 *             elif next_char == b'#':             # <<<<<<<<<<<<<<
 *                 self.buf_reset()
 *                 ascii_only = True
 */
      break;
      default:

      /* "srctools/_tokenizer.pyx":780
 * 
 *             else:  # These complex checks can't be in a switch, so we need to nest this.
 *                 if next_char == b':' and FL_COLON_OPERATOR & self.flags:             # <<<<<<<<<<<<<<
 *                     return COLON_TUP
 *                 # Bare names
 */
      __pyx_t_2 = ((__pyx_v_next_char == ':') != 0);
      if (__pyx_t_2) {
      } else {
        __pyx_t_10 = __pyx_t_2;
        goto __pyx_L33_bool_binop_done;
      }
      __pyx_t_2 = ((8 & __pyx_v_self->__pyx_base.flags) != 0);
      __pyx_t_10 = __pyx_t_2;
      __pyx_L33_bool_binop_done:;
      if (__pyx_t_10) {

        /* "srctools/_tokenizer.pyx":781
 *             else:  # These complex checks can't be in a switch, so we need to nest this.
 *                 if next_char == b':' and FL_COLON_OPERATOR & self.flags:
 *                     return COLON_TUP             # <<<<<<<<<<<<<<
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
        __pyx_r = __pyx_v_8srctools_10_tokenizer_COLON_TUP;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":780
 * 
 *             else:  # These complex checks can't be in a switch, so we need to nest this.
 *                 if next_char == b':' and FL_COLON_OPERATOR & self.flags:             # <<<<<<<<<<<<<<
 *                     return COLON_TUP
 *                 # Bare names
 */
      }

      /* "srctools/_tokenizer.pyx":783
 *                     return COLON_TUP
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
      switch (__pyx_v_next_char) {
        case '\t':
        case '\n':
        case ' ':
        case '"':
        case '\'':
        case '(':
        case ')':
        case ',':
        case ';':
        case '[':
        case ']':
        case '{':
        case '}':
        __pyx_t_10 = 0;
        break;
        default:
        __pyx_t_10 = 1;
        break;
      }
      __pyx_t_2 = (__pyx_t_10 != 0);
      if (likely(__pyx_t_2)) {

        /* "srctools/_tokenizer.pyx":784
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()             # <<<<<<<<<<<<<<
 *                     self.buf_add_char(next_char)
 *                     while True:
 */
        __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset(__pyx_v_self);

        /* "srctools/_tokenizer.pyx":785
 *                 if next_char not in BARE_DISALLOWED:
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                     while True:
 *                         next_char = self._next_char()
 */
        __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 785, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":786
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 *                     while True:             # <<<<<<<<<<<<<<
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF:
 */
        while (1) {

          /* "srctools/_tokenizer.pyx":787
 *                     self.buf_add_char(next_char)
 *                     while True:
 *                         next_char = self._next_char()             # <<<<<<<<<<<<<<
 *                         if next_char == CHR_EOF:
 *                             # Bare names at the end are actually fine.
 */
          __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 787, __pyx_L1_error)
          __pyx_v_next_char = __pyx_t_4;

          /* "srctools/_tokenizer.pyx":788
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
          __pyx_t_2 = ((__pyx_v_next_char == 3) != 0);
          if (__pyx_t_2) {

            /* "srctools/_tokenizer.pyx":791
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 *                             return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 * 
 *                         elif (
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_3 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 791, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 791, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
            PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_t_3);
            PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_3);
            __pyx_t_3 = 0;
            __pyx_r = __pyx_t_8;
            __pyx_t_8 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":788
 *                     while True:
 *                         next_char = self._next_char()
 *                         if next_char == CHR_EOF:             # <<<<<<<<<<<<<<
 *                             # Bare names at the end are actually fine.
 *                             # It could be a value for the last prop.
 */
          }

          /* "srctools/_tokenizer.pyx":794
 * 
 *                         elif (
 *                             next_char in BARE_DISALLOWED or             # <<<<<<<<<<<<<<
 *                             (next_char == b':' and FL_COLON_OPERATOR & self.flags)
 *                         ):  # We need to repeat this so we return the ending
 */
          switch (__pyx_v_next_char) {
            case '\t':
            case '\n':
            case ' ':
            case '"':
            case '\'':
            case '(':
            case ')':
            case ',':
            case ';':
            case '[':
            case ']':
            case '{':
            case '}':
            __pyx_t_10 = 1;
            break;
            default:
            __pyx_t_10 = 0;
            break;
          }
          __pyx_t_1 = (__pyx_t_10 != 0);
          if (!__pyx_t_1) {
          } else {
            __pyx_t_2 = __pyx_t_1;
            goto __pyx_L39_bool_binop_done;
          }

          /* "srctools/_tokenizer.pyx":795
 *                         elif (
 *                             next_char in BARE_DISALLOWED or
 *                             (next_char == b':' and FL_COLON_OPERATOR & self.flags)             # <<<<<<<<<<<<<<
 *                         ):  # We need to repeat this so we return the ending
 *                             # char next. If it's not allowed, that'll error on
 */
          __pyx_t_1 = ((__pyx_v_next_char == ':') != 0);
          if (__pyx_t_1) {
          } else {
            __pyx_t_2 = __pyx_t_1;
            goto __pyx_L39_bool_binop_done;
          }
          __pyx_t_1 = ((8 & __pyx_v_self->__pyx_base.flags) != 0);
          __pyx_t_2 = __pyx_t_1;
          __pyx_L39_bool_binop_done:;

          /* "srctools/_tokenizer.pyx":793
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif (             # <<<<<<<<<<<<<<
 *                             next_char in BARE_DISALLOWED or
 *                             (next_char == b':' and FL_COLON_OPERATOR & self.flags)
 */
          if (__pyx_t_2) {

            /* "srctools/_tokenizer.pyx":800
 *                             # next call.
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1             # <<<<<<<<<<<<<<
 *                             return STRING, self.buf_get_text()
 *                         else:
 */
            __pyx_v_self->char_index = (__pyx_v_self->char_index - 1);

            /* "srctools/_tokenizer.pyx":801
 *                             # We need to repeat this so we return the newline.
 *                             self.char_index -= 1
 *                             return STRING, self.buf_get_text()             # <<<<<<<<<<<<<<
 *                         else:
 *                             self.buf_add_char(next_char)
 */
            __Pyx_XDECREF(__pyx_r);
            __pyx_t_8 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->buf_get_text(__pyx_v_self); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 801, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_8);
            __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 801, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_STRING);
            PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_8srctools_10_tokenizer_STRING);
            __Pyx_GIVEREF(__pyx_t_8);
            PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
            __pyx_t_8 = 0;
            __pyx_r = __pyx_t_3;
            __pyx_t_3 = 0;
            goto __pyx_L0;

            /* "srctools/_tokenizer.pyx":793
 *                             return STRING, self.buf_get_text()
 * 
 *                         elif (             # <<<<<<<<<<<<<<
 *                             next_char in BARE_DISALLOWED or
 *                             (next_char == b':' and FL_COLON_OPERATOR & self.flags)
 */
          }

          /* "srctools/_tokenizer.pyx":803
 *                             return STRING, self.buf_get_text()
 *                         else:
 *                             self.buf_add_char(next_char)             # <<<<<<<<<<<<<<
 *                 else:
 *                     # Add in a few more bytes so we can decode the UTF8 fully.
 */
          /*else*/ {
            __pyx_t_5 = __pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char(__pyx_v_self, __pyx_v_next_char); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 803, __pyx_L1_error)
          }
        }

        /* "srctools/_tokenizer.pyx":783
 *                     return COLON_TUP
 *                 # Bare names
 *                 if next_char not in BARE_DISALLOWED:             # <<<<<<<<<<<<<<
 *                     self.buf_reset()
 *                     self.buf_add_char(next_char)
 */
        goto __pyx_L35;
      }

      /* "srctools/_tokenizer.pyx":806
 *                 else:
 *                     # Add in a few more bytes so we can decode the UTF8 fully.
 *                     decode = [             # <<<<<<<<<<<<<<
 *                         next_char,
 *                         self._next_char(),
 */
      /*else*/ {

        /* "srctools/_tokenizer.pyx":808
 *                     decode = [
 *                         next_char,
 *                         self._next_char(),             # <<<<<<<<<<<<<<
 *                         self._next_char(),
 *                         self._next_char(),
 */
        __pyx_t_4 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_4 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 808, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":809
 *                         next_char,
 *                         self._next_char(),
 *                         self._next_char(),             # <<<<<<<<<<<<<<
 *                         self._next_char(),
 *                         0x00,
 */
        __pyx_t_11 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_11 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 809, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":810
 *                         self._next_char(),
 *                         self._next_char(),
 *                         self._next_char(),             # <<<<<<<<<<<<<<
 *                         0x00,
 *                     ]
 */
        __pyx_t_12 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer *)__pyx_v_self->__pyx_base.__pyx_vtab)->_next_char(__pyx_v_self); if (unlikely(__pyx_t_12 == ((unsigned char)3) && PyErr_Occurred())) __PYX_ERR(0, 810, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":806
 *                 else:
 *                     # Add in a few more bytes so we can decode the UTF8 fully.
 *                     decode = [             # <<<<<<<<<<<<<<
 *                         next_char,
 *                         self._next_char(),
 */
        __pyx_t_13[0] = __pyx_v_next_char;
        __pyx_t_13[1] = __pyx_t_4;
        __pyx_t_13[2] = __pyx_t_11;
        __pyx_t_13[3] = __pyx_t_12;
        __pyx_t_13[4] = 0x00;
        memcpy(&(__pyx_v_decode[0]), __pyx_t_13, sizeof(__pyx_v_decode[0]) * (5));

        /* "srctools/_tokenizer.pyx":813
 *                         0x00,
 *                     ]
 *                     raise self._error(f'Unexpected character "{decode[:4].decode("utf8", "backslashreplace")}"' '!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
        __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 813, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_6 = 0;
        __pyx_t_7 = 127;
        __Pyx_INCREF(__pyx_kp_u_Unexpected_character);
        __pyx_t_6 += 22;
        __Pyx_GIVEREF(__pyx_kp_u_Unexpected_character);
        PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unexpected_character);
        __pyx_t_8 = __Pyx_decode_c_string(((char const *)__pyx_v_decode), 0, 4, NULL, ((char const *)"backslashreplace"), PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 813, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_7 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_8) > __pyx_t_7) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_8) : __pyx_t_7;
        __pyx_t_6 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_8);
        __Pyx_GIVEREF(__pyx_t_8);
        PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_8);
        __pyx_t_8 = 0;
        __Pyx_INCREF(__pyx_kp_u_);
        __pyx_t_6 += 2;
        __Pyx_GIVEREF(__pyx_kp_u_);
        PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u_);
        __pyx_t_8 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_6, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 813, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self), ((PyObject*)__pyx_t_8)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 813, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(0, 813, __pyx_L1_error)
      }
      __pyx_L35:;
      break;
    }
    __pyx_L4_continue:;
  }

  /* "srctools/_tokenizer.pyx":566
 *                 return self.chunk_buf[0]
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         """Return the next token, value pair - this is the C version."""
 *         cdef:
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("srctools._tokenizer.Tokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_output);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":823
 *     """
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:             # <<<<<<<<<<<<<<
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_source = 0;
  PyObject *__pyx_v_filename = 0;
  PyObject *__pyx_v_error = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_source,&__pyx_n_s_filename,&__pyx_n_s_error,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject *)__pyx_kp_u__8);
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_source)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_filename);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_error);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 823, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_source = values[0];
    __pyx_v_filename = values[1];
    __pyx_v_error = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 823, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self), __pyx_v_source, __pyx_v_filename, __pyx_v_error);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer___init__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_filename, PyObject *__pyx_v_error) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":824
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)             # <<<<<<<<<<<<<<
 *         self.source = iter(source)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer), __pyx_n_s_init); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 824, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_3, ((PyObject *)__pyx_v_self), __pyx_v_filename, __pyx_v_error};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_3) {
      __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_3); __pyx_t_3 = NULL;
    }
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, ((PyObject *)__pyx_v_self));
    __Pyx_INCREF(__pyx_v_filename);
    __Pyx_GIVEREF(__pyx_v_filename);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_filename);
    __Pyx_INCREF(__pyx_v_error);
    __Pyx_GIVEREF(__pyx_v_error);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_error);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 824, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":825
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __pyx_t_1 = PyObject_GetIter(__pyx_v_source); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 825, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":823
 *     """
 *     cdef public object source
 *     def __init__(self, source, filename='', error=None) -> None:             # <<<<<<<<<<<<<<
 *         BaseTokenizer.__init__(self, filename, error)
 *         self.source = iter(source)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":827
 *         self.source = iter(source)
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  Py_UCS4 __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "srctools/_tokenizer.pyx":828
 * 
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:             # <<<<<<<<<<<<<<
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 */
  __pyx_t_1 = (__pyx_v_self->__pyx_base.error_type == __pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":829
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'             # <<<<<<<<<<<<<<
 *         else:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = PyTuple_New(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 829, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_IterTokenizer);
    __pyx_t_4 += 14;
    __Pyx_GIVEREF(__pyx_kp_u_IterTokenizer);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_IterTokenizer);
    __pyx_t_6 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->source), __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 829, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_kp_u__21);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__21);
    PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u__21);
    __pyx_t_6 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.filename), __pyx_empty_unicode); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 829, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_6) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_3, 3, __pyx_t_6);
    __pyx_t_6 = 0;
    __Pyx_INCREF(__pyx_kp_u__22);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__22);
    PyTuple_SET_ITEM(__pyx_t_3, 4, __pyx_kp_u__22);
    __pyx_t_6 = __Pyx_PyUnicode_Join(__pyx_t_3, 5, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 829, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_6;
    __pyx_t_6 = 0;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":828
 * 
 *     def __repr__(self):
 *         if self.error_type is TokenSyntaxError:             # <<<<<<<<<<<<<<
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 */
  }

  /* "srctools/_tokenizer.pyx":831
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 *         else:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'             # <<<<<<<<<<<<<<
 * 
 *     cdef next_token(self):
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_6 = PyTuple_New(7); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 831, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_4 = 0;
    __pyx_t_5 = 127;
    __Pyx_INCREF(__pyx_kp_u_IterTokenizer);
    __pyx_t_4 += 14;
    __Pyx_GIVEREF(__pyx_kp_u_IterTokenizer);
    PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_kp_u_IterTokenizer);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->source), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 831, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__21);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__21);
    PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_kp_u__21);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.filename), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 831, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__21);
    __pyx_t_4 += 2;
    __Pyx_GIVEREF(__pyx_kp_u__21);
    PyTuple_SET_ITEM(__pyx_t_6, 4, __pyx_kp_u__21);
    __pyx_t_3 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_self->__pyx_base.error_type), __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 831, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_5) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_5;
    __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_6, 5, __pyx_t_3);
    __pyx_t_3 = 0;
    __Pyx_INCREF(__pyx_kp_u__22);
    __pyx_t_4 += 1;
    __Pyx_GIVEREF(__pyx_kp_u__22);
    PyTuple_SET_ITEM(__pyx_t_6, 6, __pyx_kp_u__22);
    __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_6, 7, __pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 831, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;
  }

  /* "srctools/_tokenizer.pyx":827
 *         self.source = iter(source)
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         if self.error_type is TokenSyntaxError:
 *             return f'IterTokenizer({self.source!r}, {self.filename!r})'
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":833
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 */

static PyObject *__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_v_output = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("next_token", 0);

  /* "srctools/_tokenizer.pyx":834
 * 
 *     cdef next_token(self):
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  __pyx_t_1 = (__pyx_v_self->__pyx_base.pushback_tok != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "srctools/_tokenizer.pyx":835
 *     cdef next_token(self):
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val             # <<<<<<<<<<<<<<
 *             self.pushback_tok = self.pushback_val = None
 *             return output
 */
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 835, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_tok);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_INCREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_GIVEREF(__pyx_v_self->__pyx_base.pushback_val);
    PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_output = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "srctools/_tokenizer.pyx":836
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None             # <<<<<<<<<<<<<<
 *             return output
 * 
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_tok);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_tok);
    __pyx_v_self->__pyx_base.pushback_tok = Py_None;
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_self->__pyx_base.pushback_val);
    __Pyx_DECREF(__pyx_v_self->__pyx_base.pushback_val);
    __pyx_v_self->__pyx_base.pushback_val = Py_None;

    /* "srctools/_tokenizer.pyx":837
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 *             return output             # <<<<<<<<<<<<<<
 * 
 *         try:
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_output);
    __pyx_r = __pyx_v_output;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":834
 * 
 *     cdef next_token(self):
 *         if self.pushback_tok is not None:             # <<<<<<<<<<<<<<
 *             output = self.pushback_tok, self.pushback_val
 *             self.pushback_tok = self.pushback_val = None
 */
  }

  /* "srctools/_tokenizer.pyx":839
 *             return output
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_4, &__pyx_t_5, &__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    /*try:*/ {

      /* "srctools/_tokenizer.pyx":840
 * 
 *         try:
 *             return next(self.source)             # <<<<<<<<<<<<<<
 *         except StopIteration:
 *             return EOF_TUP
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __pyx_v_self->source;
      __Pyx_INCREF(__pyx_t_3);
      __pyx_t_7 = __Pyx_PyIter_Next(__pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 840, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_r = __pyx_t_7;
      __pyx_t_7 = 0;
      goto __pyx_L8_try_return;

      /* "srctools/_tokenizer.pyx":839
 *             return output
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
    }
    __pyx_L4_error:;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "srctools/_tokenizer.pyx":841
 *         try:
 *             return next(self.source)
 *         except StopIteration:             # <<<<<<<<<<<<<<
 *             return EOF_TUP
 * 
 */
    __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_StopIteration);
    if (__pyx_t_8) {
      __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_7, &__pyx_t_3, &__pyx_t_9) < 0) __PYX_ERR(0, 841, __pyx_L6_except_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GOTREF(__pyx_t_9);

      /* "srctools/_tokenizer.pyx":842
 *             return next(self.source)
 *         except StopIteration:
 *             return EOF_TUP             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
      __pyx_r = __pyx_v_8srctools_10_tokenizer_EOF_TUP;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      goto __pyx_L7_except_return;
    }
    goto __pyx_L6_except_error;
    __pyx_L6_except_error:;

    /* "srctools/_tokenizer.pyx":839
 *             return output
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             return next(self.source)
 *         except StopIteration:
 */
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L1_error;
    __pyx_L8_try_return:;
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L0;
    __pyx_L7_except_return:;
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L0;
  }

  /* "srctools/_tokenizer.pyx":833
 *             return f'IterTokenizer({self.source!r}, {self.filename!r}, {self.error_type!r})'
 * 
 *     cdef next_token(self):             # <<<<<<<<<<<<<<
 *         if self.pushback_tok is not None:
 *             output = self.pushback_tok, self.pushback_val
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("srctools._tokenizer.IterTokenizer.next_token", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_output);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":822
 *     code.
 *     """
 *     cdef public object source             # <<<<<<<<<<<<<<
 *     def __init__(self, source, filename='', error=None) -> None:
 *         BaseTokenizer.__init__(self, filename, error)
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source___get__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->source);
  __pyx_r = __pyx_v_self->source;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self), ((PyObject *)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_2__set__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self, PyObject *__pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__", 0);
  __Pyx_INCREF(__pyx_v_value);
  __Pyx_GIVEREF(__pyx_v_value);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = __pyx_v_value;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13IterTokenizer_6source_4__del__(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__del__", 0);
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->source);
  __Pyx_DECREF(__pyx_v_self->source);
  __pyx_v_self->source = Py_None;

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":853
 *     cdef BaseTokenizer tok
 * 
 *     def __cinit__(self, BaseTokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(0, 853, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)values[0]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 853, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tok), __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer, 0, "tok", 0))) __PYX_ERR(0, 853, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":854
 * 
 *     def __cinit__(self, BaseTokenizer tok not None):
 *         self.tok = tok             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_tok));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_tok));
  __Pyx_GOTREF(__pyx_v_self->tok);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->tok));
  __pyx_v_self->tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":853
 *     cdef BaseTokenizer tok
 * 
 *     def __cinit__(self, BaseTokenizer tok not None):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":856
 *         self.tok = tok
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  Py_UCS4 __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "srctools/_tokenizer.pyx":857
 * 
 *     def __repr__(self):
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, tok):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 857, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = 0;
  __pyx_t_3 = 127;
  __Pyx_INCREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize);
  __pyx_t_2 += 57;
  __Pyx_GIVEREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_srctools_tokenizer_BaseTokenize);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_id, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 857, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_Format(__pyx_t_4, __pyx_n_u_X); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 857, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) > __pyx_t_3) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) : __pyx_t_3;
  __pyx_t_2 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_5);
  __pyx_t_5 = 0;
  __Pyx_INCREF(__pyx_kp_u__23);
  __pyx_t_2 += 1;
  __Pyx_GIVEREF(__pyx_kp_u__23);
  PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__23);
  __pyx_t_5 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 857, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":856
 *         self.tok = tok
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":859
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  CYTHON_UNUSED PyObject *__pyx_v_tok = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 859, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 859, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":860
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create '_NewlinesIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__24, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 860, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 860, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":859
 *         return f'<srctools.tokenizer.BaseTokenizer.skipping_newlines() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":862
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":863
 * 
 *     def __iter__(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":862
 *         raise TypeError("Cannot create '_NewlinesIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":865
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_v_tok_and_val = NULL;
  PyObject *__pyx_v_token = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":866
 * 
 *     def __next__(self):
 *         while True:             # <<<<<<<<<<<<<<
 *             tok_and_val = self.tok.next_token()
 *             token = (<tuple?>tok_and_val)[0]
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":867
 *     def __next__(self):
 *         while True:
 *             tok_and_val = self.tok.next_token()             # <<<<<<<<<<<<<<
 *             token = (<tuple?>tok_and_val)[0]
 * 
 */
    __pyx_t_1 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->tok->__pyx_vtab)->next_token(__pyx_v_self->tok); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 867, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_tok_and_val, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":868
 *         while True:
 *             tok_and_val = self.tok.next_token()
 *             token = (<tuple?>tok_and_val)[0]             # <<<<<<<<<<<<<<
 * 
 *             # Only our code is doing next_token here, so the tuples are
 */
    if (!(likely(PyTuple_CheckExact(__pyx_v_tok_and_val))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v_tok_and_val)->tp_name), 0))) __PYX_ERR(0, 868, __pyx_L1_error)
    if (unlikely(__pyx_v_tok_and_val == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 868, __pyx_L1_error)
    }
    __pyx_t_1 = __Pyx_GetItemInt_Tuple(((PyObject*)__pyx_v_tok_and_val), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 868, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_token, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":872
 *             # Only our code is doing next_token here, so the tuples are
 *             # going to be this same instance.
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    __pyx_t_2 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_EOF);
    __pyx_t_3 = (__pyx_t_2 != 0);
    if (unlikely(__pyx_t_3)) {

      /* "srctools/_tokenizer.pyx":873
 *             # going to be this same instance.
 *             if token is EOF:
 *                 raise StopIteration             # <<<<<<<<<<<<<<
 *             elif token is not NEWLINE:
 *                 return tok_and_val
 */
      __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
      __PYX_ERR(0, 873, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":872
 *             # Only our code is doing next_token here, so the tuples are
 *             # going to be this same instance.
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    }

    /* "srctools/_tokenizer.pyx":874
 *             if token is EOF:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    __pyx_t_3 = (__pyx_v_token != __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_2 = (__pyx_t_3 != 0);
    if (__pyx_t_2) {

      /* "srctools/_tokenizer.pyx":875
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 *                 return tok_and_val             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_tok_and_val);
      __pyx_r = __pyx_v_tok_and_val;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":874
 *             if token is EOF:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 return tok_and_val
 * 
 */
    }
  }

  /* "srctools/_tokenizer.pyx":865
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         while True:
 *             tok_and_val = self.tok.next_token()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_tok_and_val);
  __Pyx_XDECREF(__pyx_v_token);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":877
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__[] = "This cannot be pickled - the Python version does not have this class.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__};
static PyObject *__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":879
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__25, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 879, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 879, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":877
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer._NewlinesIter.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":891
 *     cdef bint expect_brace
 * 
 *     def __cinit__(self, BaseTokenizer tok, str name, bint expect_brace, *):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 *         self.name = name
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9BlockIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9BlockIter_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok = 0;
  PyObject *__pyx_v_name = 0;
  int __pyx_v_expect_brace;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,&__pyx_n_s_name_2,&__pyx_n_s_expect_brace,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_name_2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 3, 3, 1); __PYX_ERR(0, 891, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_expect_brace)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 3, 3, 2); __PYX_ERR(0, 891, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(0, 891, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)values[0]);
    __pyx_v_name = ((PyObject*)values[1]);
    __pyx_v_expect_brace = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_expect_brace == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 891, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 891, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tok), __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer, 1, "tok", 0))) __PYX_ERR(0, 891, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_name), (&PyUnicode_Type), 1, "name", 1))) __PYX_ERR(0, 891, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter___cinit__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self), __pyx_v_tok, __pyx_v_name, __pyx_v_expect_brace);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9BlockIter___cinit__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self, struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *__pyx_v_tok, PyObject *__pyx_v_name, int __pyx_v_expect_brace) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":892
 * 
 *     def __cinit__(self, BaseTokenizer tok, str name, bint expect_brace, *):
 *         self.tok = tok             # <<<<<<<<<<<<<<
 *         self.name = name
 *         self.expect_brace = expect_brace
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_tok));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_tok));
  __Pyx_GOTREF(__pyx_v_self->tok);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->tok));
  __pyx_v_self->tok = __pyx_v_tok;

  /* "srctools/_tokenizer.pyx":893
 *     def __cinit__(self, BaseTokenizer tok, str name, bint expect_brace, *):
 *         self.tok = tok
 *         self.name = name             # <<<<<<<<<<<<<<
 *         self.expect_brace = expect_brace
 * 
 */
  __Pyx_INCREF(__pyx_v_name);
  __Pyx_GIVEREF(__pyx_v_name);
  __Pyx_GOTREF(__pyx_v_self->name);
  __Pyx_DECREF(__pyx_v_self->name);
  __pyx_v_self->name = __pyx_v_name;

  /* "srctools/_tokenizer.pyx":894
 *         self.tok = tok
 *         self.name = name
 *         self.expect_brace = expect_brace             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __pyx_v_self->expect_brace = __pyx_v_expect_brace;

  /* "srctools/_tokenizer.pyx":891
 *     cdef bint expect_brace
 * 
 *     def __cinit__(self, BaseTokenizer tok, str name, bint expect_brace, *):             # <<<<<<<<<<<<<<
 *         self.tok = tok
 *         self.name = name
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":896
 *         self.expect_brace = expect_brace
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.block() at {id(self):X}>'
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_3__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_3__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter_2__repr__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_2__repr__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  Py_UCS4 __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "srctools/_tokenizer.pyx":897
 * 
 *     def __repr__(self):
 *         return f'<srctools.tokenizer.BaseTokenizer.block() at {id(self):X}>'             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, tok):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 897, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = 0;
  __pyx_t_3 = 127;
  __Pyx_INCREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize_2);
  __pyx_t_2 += 45;
  __Pyx_GIVEREF(__pyx_kp_u_srctools_tokenizer_BaseTokenize_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_srctools_tokenizer_BaseTokenize_2);
  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_id, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 897, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_Format(__pyx_t_4, __pyx_n_u_X); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 897, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) > __pyx_t_3) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_5) : __pyx_t_3;
  __pyx_t_2 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_5);
  __Pyx_GIVEREF(__pyx_t_5);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_5);
  __pyx_t_5 = 0;
  __Pyx_INCREF(__pyx_kp_u__23);
  __pyx_t_2 += 1;
  __Pyx_GIVEREF(__pyx_kp_u__23);
  PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__23);
  __pyx_t_5 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 897, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":896
 *         self.expect_brace = expect_brace
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return f'<srctools.tokenizer.BaseTokenizer.block() at {id(self):X}>'
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":899
 *         return f'<srctools.tokenizer.BaseTokenizer.block() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create 'BlockIter' instances")
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_9BlockIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_9BlockIter_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  CYTHON_UNUSED PyObject *__pyx_v_tok = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_tok,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_tok)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 899, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_tok = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 899, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter_4__init__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self), __pyx_v_tok);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_9BlockIter_4__init__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_tok) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":900
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create 'BlockIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__26, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 900, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 900, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":899
 *         return f'<srctools.tokenizer.BaseTokenizer.block() at {id(self):X}>'
 * 
 *     def __init__(self, tok):             # <<<<<<<<<<<<<<
 *         raise TypeError("Cannot create 'BlockIter' instances")
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":902
 *         raise TypeError("Cannot create 'BlockIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_7__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_7__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter_6__iter__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_6__iter__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":903
 * 
 *     def __iter__(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":902
 *         raise TypeError("Cannot create 'BlockIter' instances")
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":905
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         if self.expect_brace:
 *             self.expect_brace = False
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter_8__next__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_8__next__(struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self) {
  PyObject *__pyx_v_next_token = NULL;
  PyObject *__pyx_v_token = NULL;
  PyObject *__pyx_v_value = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  Py_UCS4 __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":906
 * 
 *     def __next__(self):
 *         if self.expect_brace:             # <<<<<<<<<<<<<<
 *             self.expect_brace = False
 *             next_token = <tuple> self.tok.next_token()[0]
 */
  __pyx_t_1 = (__pyx_v_self->expect_brace != 0);
  if (__pyx_t_1) {

    /* "srctools/_tokenizer.pyx":907
 *     def __next__(self):
 *         if self.expect_brace:
 *             self.expect_brace = False             # <<<<<<<<<<<<<<
 *             next_token = <tuple> self.tok.next_token()[0]
 *             while next_token is NEWLINE:
 */
    __pyx_v_self->expect_brace = 0;

    /* "srctools/_tokenizer.pyx":908
 *         if self.expect_brace:
 *             self.expect_brace = False
 *             next_token = <tuple> self.tok.next_token()[0]             # <<<<<<<<<<<<<<
 *             while next_token is NEWLINE:
 *                 next_token = <tuple> self.tok.next_token()[0]
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->tok->__pyx_vtab)->next_token(__pyx_v_self->tok); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 908, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 908, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __pyx_t_3;
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_next_token = ((PyObject*)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "srctools/_tokenizer.pyx":909
 *             self.expect_brace = False
 *             next_token = <tuple> self.tok.next_token()[0]
 *             while next_token is NEWLINE:             # <<<<<<<<<<<<<<
 *                 next_token = <tuple> self.tok.next_token()[0]
 *             if next_token is not BRACE_OPEN:
 */
    while (1) {
      __pyx_t_1 = (__pyx_v_next_token == ((PyObject*)__pyx_v_8srctools_10_tokenizer_NEWLINE));
      __pyx_t_4 = (__pyx_t_1 != 0);
      if (!__pyx_t_4) break;

      /* "srctools/_tokenizer.pyx":910
 *             next_token = <tuple> self.tok.next_token()[0]
 *             while next_token is NEWLINE:
 *                 next_token = <tuple> self.tok.next_token()[0]             # <<<<<<<<<<<<<<
 *             if next_token is not BRACE_OPEN:
 *                 raise self.tok._error(f'Expected BRACE_OPEN, but got {next_token}' '!')
 */
      __pyx_t_2 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->tok->__pyx_vtab)->next_token(__pyx_v_self->tok); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 910, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 910, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __pyx_t_3;
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF_SET(__pyx_v_next_token, ((PyObject*)__pyx_t_2));
      __pyx_t_2 = 0;
    }

    /* "srctools/_tokenizer.pyx":911
 *             while next_token is NEWLINE:
 *                 next_token = <tuple> self.tok.next_token()[0]
 *             if next_token is not BRACE_OPEN:             # <<<<<<<<<<<<<<
 *                 raise self.tok._error(f'Expected BRACE_OPEN, but got {next_token}' '!')
 * 
 */
    __pyx_t_4 = (__pyx_v_next_token != ((PyObject*)__pyx_v_8srctools_10_tokenizer_BRACE_OPEN));
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (unlikely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":912
 *                 next_token = <tuple> self.tok.next_token()[0]
 *             if next_token is not BRACE_OPEN:
 *                 raise self.tok._error(f'Expected BRACE_OPEN, but got {next_token}' '!')             # <<<<<<<<<<<<<<
 * 
 *         while True:
 */
      __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 912, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_5 = 0;
      __pyx_t_6 = 127;
      __Pyx_INCREF(__pyx_kp_u_Expected_BRACE_OPEN_but_got);
      __pyx_t_5 += 29;
      __Pyx_GIVEREF(__pyx_kp_u_Expected_BRACE_OPEN_but_got);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_kp_u_Expected_BRACE_OPEN_but_got);
      __pyx_t_3 = __Pyx_PyObject_FormatSimple(__pyx_v_next_token, __pyx_empty_unicode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 912, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) > __pyx_t_6) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_3) : __pyx_t_6;
      __pyx_t_5 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_3);
      __pyx_t_3 = 0;
      __Pyx_INCREF(__pyx_kp_u__6);
      __pyx_t_5 += 1;
      __Pyx_GIVEREF(__pyx_kp_u__6);
      PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_kp_u__6);
      __pyx_t_3 = __Pyx_PyUnicode_Join(__pyx_t_2, 3, __pyx_t_5, __pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 912, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self->tok, ((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 912, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 912, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":911
 *             while next_token is NEWLINE:
 *                 next_token = <tuple> self.tok.next_token()[0]
 *             if next_token is not BRACE_OPEN:             # <<<<<<<<<<<<<<
 *                 raise self.tok._error(f'Expected BRACE_OPEN, but got {next_token}' '!')
 * 
 */
    }

    /* "srctools/_tokenizer.pyx":906
 * 
 *     def __next__(self):
 *         if self.expect_brace:             # <<<<<<<<<<<<<<
 *             self.expect_brace = False
 *             next_token = <tuple> self.tok.next_token()[0]
 */
  }

  /* "srctools/_tokenizer.pyx":914
 *                 raise self.tok._error(f'Expected BRACE_OPEN, but got {next_token}' '!')
 * 
 *         while True:             # <<<<<<<<<<<<<<
 *             token, value = <tuple>self.tok.next_token()
 * 
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":915
 * 
 *         while True:
 *             token, value = <tuple>self.tok.next_token()             # <<<<<<<<<<<<<<
 * 
 *             if token is EOF:
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer *)__pyx_v_self->tok->__pyx_vtab)->next_token(__pyx_v_self->tok); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __pyx_t_2;
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (likely(__pyx_t_3 != Py_None)) {
      PyObject* sequence = __pyx_t_3;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 915, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_7 = PyTuple_GET_ITEM(sequence, 1); 
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_7);
      #else
      __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 915, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      #endif
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    } else {
      __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(0, 915, __pyx_L1_error)
    }
    __Pyx_XDECREF_SET(__pyx_v_token, __pyx_t_2);
    __pyx_t_2 = 0;
    __Pyx_XDECREF_SET(__pyx_v_value, __pyx_t_7);
    __pyx_t_7 = 0;

    /* "srctools/_tokenizer.pyx":917
 *             token, value = <tuple>self.tok.next_token()
 * 
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise self.tok._error(f'Unclosed {self.name} block!')
 *             elif token is STRING:
 */
    __pyx_t_1 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_EOF);
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (unlikely(__pyx_t_4)) {

      /* "srctools/_tokenizer.pyx":918
 * 
 *             if token is EOF:
 *                 raise self.tok._error(f'Unclosed {self.name} block!')             # <<<<<<<<<<<<<<
 *             elif token is STRING:
 *                 return value
 */
      __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 918, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = 0;
      __pyx_t_6 = 127;
      __Pyx_INCREF(__pyx_kp_u_Unclosed);
      __pyx_t_5 += 9;
      __Pyx_GIVEREF(__pyx_kp_u_Unclosed);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_kp_u_Unclosed);
      __pyx_t_7 = __Pyx_PyUnicode_Unicode(__pyx_v_self->name); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 918, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_6 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) > __pyx_t_6) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_7) : __pyx_t_6;
      __pyx_t_5 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_7);
      __pyx_t_7 = 0;
      __Pyx_INCREF(__pyx_kp_u_block);
      __pyx_t_5 += 7;
      __Pyx_GIVEREF(__pyx_kp_u_block);
      PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_kp_u_block);
      __pyx_t_7 = __Pyx_PyUnicode_Join(__pyx_t_3, 3, __pyx_t_5, __pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 918, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error(__pyx_v_self->tok, ((PyObject*)__pyx_t_7)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 918, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 918, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":917
 *             token, value = <tuple>self.tok.next_token()
 * 
 *             if token is EOF:             # <<<<<<<<<<<<<<
 *                 raise self.tok._error(f'Unclosed {self.name} block!')
 *             elif token is STRING:
 */
    }

    /* "srctools/_tokenizer.pyx":919
 *             if token is EOF:
 *                 raise self.tok._error(f'Unclosed {self.name} block!')
 *             elif token is STRING:             # <<<<<<<<<<<<<<
 *                 return value
 *             elif token is BRACE_CLOSE:
 */
    __pyx_t_4 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_STRING);
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (__pyx_t_1) {

      /* "srctools/_tokenizer.pyx":920
 *                 raise self.tok._error(f'Unclosed {self.name} block!')
 *             elif token is STRING:
 *                 return value             # <<<<<<<<<<<<<<
 *             elif token is BRACE_CLOSE:
 *                 raise StopIteration
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_v_value);
      __pyx_r = __pyx_v_value;
      goto __pyx_L0;

      /* "srctools/_tokenizer.pyx":919
 *             if token is EOF:
 *                 raise self.tok._error(f'Unclosed {self.name} block!')
 *             elif token is STRING:             # <<<<<<<<<<<<<<
 *                 return value
 *             elif token is BRACE_CLOSE:
 */
    }

    /* "srctools/_tokenizer.pyx":921
 *             elif token is STRING:
 *                 return value
 *             elif token is BRACE_CLOSE:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    __pyx_t_1 = (__pyx_v_token == __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE);
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (unlikely(__pyx_t_4)) {

      /* "srctools/_tokenizer.pyx":922
 *                 return value
 *             elif token is BRACE_CLOSE:
 *                 raise StopIteration             # <<<<<<<<<<<<<<
 *             elif token is not NEWLINE:
 *                 raise self.tok.error(token, value)
 */
      __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
      __PYX_ERR(0, 922, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":921
 *             elif token is STRING:
 *                 return value
 *             elif token is BRACE_CLOSE:             # <<<<<<<<<<<<<<
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 */
    }

    /* "srctools/_tokenizer.pyx":923
 *             elif token is BRACE_CLOSE:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 raise self.tok.error(token, value)
 * 
 */
    __pyx_t_4 = (__pyx_v_token != __pyx_v_8srctools_10_tokenizer_NEWLINE);
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (unlikely(__pyx_t_1)) {

      /* "srctools/_tokenizer.pyx":924
 *                 raise StopIteration
 *             elif token is not NEWLINE:
 *                 raise self.tok.error(token, value)             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self->tok), __pyx_n_s_error); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 924, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_2 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_7))) {
        __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_7);
        if (likely(__pyx_t_2)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
          __Pyx_INCREF(__pyx_t_2);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_7, function);
          __pyx_t_8 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_token, __pyx_v_value};
        __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
        PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_token, __pyx_v_value};
        __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else
      #endif
      {
        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 924, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_9);
        if (__pyx_t_2) {
          __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_2); __pyx_t_2 = NULL;
        }
        __Pyx_INCREF(__pyx_v_token);
        __Pyx_GIVEREF(__pyx_v_token);
        PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_v_token);
        __Pyx_INCREF(__pyx_v_value);
        __Pyx_GIVEREF(__pyx_v_value);
        PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_v_value);
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_9, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 924, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      }
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 924, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":923
 *             elif token is BRACE_CLOSE:
 *                 raise StopIteration
 *             elif token is not NEWLINE:             # <<<<<<<<<<<<<<
 *                 raise self.tok.error(token, value)
 * 
 */
    }
  }

  /* "srctools/_tokenizer.pyx":905
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         if self.expect_brace:
 *             self.expect_brace = False
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_next_token);
  __Pyx_XDECREF(__pyx_v_token);
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":926
 *                 raise self.tok.error(token, value)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_9BlockIter_10__reduce__[] = "This cannot be pickled - the Python version does not have this class.";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_9BlockIter_11__reduce__ = {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_9BlockIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_9BlockIter_10__reduce__};
static PyObject *__pyx_pw_8srctools_10_tokenizer_9BlockIter_11__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_9BlockIter_10__reduce__(((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_9BlockIter_10__reduce__(CYTHON_UNUSED struct __pyx_obj_8srctools_10_tokenizer_BlockIter *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "srctools/_tokenizer.pyx":928
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_NotImplementedError, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 928, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":926
 *                 raise self.tok.error(token, value)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("srctools._tokenizer.BlockIter.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":932
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text); /*proto*/
static char __pyx_doc_8srctools_10_tokenizer_escape_text[] = "escape_text(unicode text: str) -> str\nEscape special characters and backslashes, so tokenising reproduces them.\n\n    Specifically, \\, \", tab, and newline.\n    ";
static PyMethodDef __pyx_mdef_8srctools_10_tokenizer_1escape_text = {"escape_text", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_1escape_text, METH_O, __pyx_doc_8srctools_10_tokenizer_escape_text};
static PyObject *__pyx_pw_8srctools_10_tokenizer_1escape_text(PyObject *__pyx_self, PyObject *__pyx_v_text) {
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("escape_text (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_text), (&PyUnicode_Type), 0, "text", 1))) __PYX_ERR(0, 932, __pyx_L1_error)
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_escape_text(__pyx_self, ((PyObject*)__pyx_v_text));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_escape_text(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_text) {
  Py_ssize_t __pyx_v_size;
  Py_ssize_t __pyx_v_final_size;
  int __pyx_v_i;
  int __pyx_v_j;
  unsigned char __pyx_v_letter;
  unsigned char const *__pyx_v_in_buf;
  unsigned char *__pyx_v_out_buff;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  unsigned char const *__pyx_t_1;
  Py_ssize_t __pyx_t_2;
  Py_ssize_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  char const *__pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("escape_text", 0);

  /* "srctools/_tokenizer.pyx":939
 *     # UTF8 = ASCII for the chars we care about, so we can just loop over the
 *     # UTF8 data.
 *     cdef Py_ssize_t size = 0             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t final_size = 0
 *     cdef int i, j
 */
  __pyx_v_size = 0;

  /* "srctools/_tokenizer.pyx":940
 *     # UTF8 data.
 *     cdef Py_ssize_t size = 0
 *     cdef Py_ssize_t final_size = 0             # <<<<<<<<<<<<<<
 *     cdef int i, j
 *     cdef uchar letter
 */
  __pyx_v_final_size = 0;

  /* "srctools/_tokenizer.pyx":943
 *     cdef int i, j
 *     cdef uchar letter
 *     cdef const uchar *in_buf = PyUnicode_AsUTF8AndSize(text, &size)             # <<<<<<<<<<<<<<
 *     final_size = size
 * 
 */
  __pyx_t_1 = PyUnicode_AsUTF8AndSize(__pyx_v_text, (&__pyx_v_size)); if (unlikely(__pyx_t_1 == ((unsigned char const *)NULL))) __PYX_ERR(0, 943, __pyx_L1_error)
  __pyx_v_in_buf = __pyx_t_1;

  /* "srctools/_tokenizer.pyx":944
 *     cdef uchar letter
 *     cdef const uchar *in_buf = PyUnicode_AsUTF8AndSize(text, &size)
 *     final_size = size             # <<<<<<<<<<<<<<
 * 
 *     # First loop to compute the full string length, and check if we need to
 */
  __pyx_v_final_size = __pyx_v_size;

  /* "srctools/_tokenizer.pyx":948
 *     # First loop to compute the full string length, and check if we need to
 *     # escape at all.
 *     for i in range(size):             # <<<<<<<<<<<<<<
 *         if in_buf[i] in b'\\"\t\n':
 *             final_size += 1
 */
  __pyx_t_2 = __pyx_v_size;
  __pyx_t_3 = __pyx_t_2;
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "srctools/_tokenizer.pyx":949
 *     # escape at all.
 *     for i in range(size):
 *         if in_buf[i] in b'\\"\t\n':             # <<<<<<<<<<<<<<
 *             final_size += 1
 * 
 */
    switch ((__pyx_v_in_buf[__pyx_v_i])) {
      case '\t':
      case '\n':
      case '"':
      case '\\':

      /* "srctools/_tokenizer.pyx":950
 *     for i in range(size):
 *         if in_buf[i] in b'\\"\t\n':
 *             final_size += 1             # <<<<<<<<<<<<<<
 * 
 *     if size == final_size:  # Unchanged, return original
 */
      __pyx_v_final_size = (__pyx_v_final_size + 1);

      /* "srctools/_tokenizer.pyx":949
 *     # escape at all.
 *     for i in range(size):
 *         if in_buf[i] in b'\\"\t\n':             # <<<<<<<<<<<<<<
 *             final_size += 1
 * 
 */
      break;
      default: break;
    }
  }

  /* "srctools/_tokenizer.pyx":952
 *             final_size += 1
 * 
 *     if size == final_size:  # Unchanged, return original             # <<<<<<<<<<<<<<
 *         return text
 * 
 */
  __pyx_t_5 = ((__pyx_v_size == __pyx_v_final_size) != 0);
  if (__pyx_t_5) {

    /* "srctools/_tokenizer.pyx":953
 * 
 *     if size == final_size:  # Unchanged, return original
 *         return text             # <<<<<<<<<<<<<<
 * 
 *     cdef uchar *out_buff
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_text);
    __pyx_r = __pyx_v_text;
    goto __pyx_L0;

    /* "srctools/_tokenizer.pyx":952
 *             final_size += 1
 * 
 *     if size == final_size:  # Unchanged, return original             # <<<<<<<<<<<<<<
 *         return text
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":956
 * 
 *     cdef uchar *out_buff
 *     j = 0             # <<<<<<<<<<<<<<
 *     try:
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))
 */
  __pyx_v_j = 0;

  /* "srctools/_tokenizer.pyx":957
 *     cdef uchar *out_buff
 *     j = 0
 *     try:             # <<<<<<<<<<<<<<
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))
 *         if out_buff is NULL:
 */
  /*try:*/ {

    /* "srctools/_tokenizer.pyx":958
 *     j = 0
 *     try:
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))             # <<<<<<<<<<<<<<
 *         if out_buff is NULL:
 *             raise MemoryError
 */
    __pyx_v_out_buff = ((unsigned char *)PyMem_Malloc((__pyx_v_final_size + (1 * (sizeof(unsigned char))))));

    /* "srctools/_tokenizer.pyx":959
 *     try:
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))
 *         if out_buff is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         for i in range(size):
 */
    __pyx_t_5 = ((__pyx_v_out_buff == NULL) != 0);
    if (unlikely(__pyx_t_5)) {

      /* "srctools/_tokenizer.pyx":960
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))
 *         if out_buff is NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 *         for i in range(size):
 *             letter = in_buf[i]
 */
      PyErr_NoMemory(); __PYX_ERR(0, 960, __pyx_L7_error)

      /* "srctools/_tokenizer.pyx":959
 *     try:
 *         out_buff = <uchar *>PyMem_Malloc(final_size+1 * sizeof(uchar))
 *         if out_buff is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         for i in range(size):
 */
    }

    /* "srctools/_tokenizer.pyx":961
 *         if out_buff is NULL:
 *             raise MemoryError
 *         for i in range(size):             # <<<<<<<<<<<<<<
 *             letter = in_buf[i]
 *             if letter == b'\\':
 */
    __pyx_t_2 = __pyx_v_size;
    __pyx_t_3 = __pyx_t_2;
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "srctools/_tokenizer.pyx":962
 *             raise MemoryError
 *         for i in range(size):
 *             letter = in_buf[i]             # <<<<<<<<<<<<<<
 *             if letter == b'\\':
 *                 out_buff[j] = b'\\'
 */
      __pyx_v_letter = (__pyx_v_in_buf[__pyx_v_i]);

      /* "srctools/_tokenizer.pyx":963
 *         for i in range(size):
 *             letter = in_buf[i]
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *                 j += 1
 */
      switch (__pyx_v_letter) {
        case '\\':

        /* "srctools/_tokenizer.pyx":964
 *             letter = in_buf[i]
 *             if letter == b'\\':
 *                 out_buff[j] = b'\\'             # <<<<<<<<<<<<<<
 *                 j += 1
 *                 out_buff[j] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '\\';

        /* "srctools/_tokenizer.pyx":965
 *             if letter == b'\\':
 *                 out_buff[j] = b'\\'
 *                 j += 1             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *             elif letter == b'"':
 */
        __pyx_v_j = (__pyx_v_j + 1);

        /* "srctools/_tokenizer.pyx":966
 *                 out_buff[j] = b'\\'
 *                 j += 1
 *                 out_buff[j] = b'\\'             # <<<<<<<<<<<<<<
 *             elif letter == b'"':
 *                 out_buff[j] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '\\';

        /* "srctools/_tokenizer.pyx":963
 *         for i in range(size):
 *             letter = in_buf[i]
 *             if letter == b'\\':             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *                 j += 1
 */
        break;
        case '"':

        /* "srctools/_tokenizer.pyx":968
 *                 out_buff[j] = b'\\'
 *             elif letter == b'"':
 *                 out_buff[j] = b'\\'             # <<<<<<<<<<<<<<
 *                 j += 1
 *                 out_buff[j] = b'"'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '\\';

        /* "srctools/_tokenizer.pyx":969
 *             elif letter == b'"':
 *                 out_buff[j] = b'\\'
 *                 j += 1             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'"'
 *             elif letter == b'\t':
 */
        __pyx_v_j = (__pyx_v_j + 1);

        /* "srctools/_tokenizer.pyx":970
 *                 out_buff[j] = b'\\'
 *                 j += 1
 *                 out_buff[j] = b'"'             # <<<<<<<<<<<<<<
 *             elif letter == b'\t':
 *                 out_buff[j] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '"';

        /* "srctools/_tokenizer.pyx":967
 *                 j += 1
 *                 out_buff[j] = b'\\'
 *             elif letter == b'"':             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *                 j += 1
 */
        break;
        case '\t':

        /* "srctools/_tokenizer.pyx":972
 *                 out_buff[j] = b'"'
 *             elif letter == b'\t':
 *                 out_buff[j] = b'\\'             # <<<<<<<<<<<<<<
 *                 j += 1
 *                 out_buff[j] = b't'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '\\';

        /* "srctools/_tokenizer.pyx":973
 *             elif letter == b'\t':
 *                 out_buff[j] = b'\\'
 *                 j += 1             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b't'
 *             elif letter == b'\n':
 */
        __pyx_v_j = (__pyx_v_j + 1);

        /* "srctools/_tokenizer.pyx":974
 *                 out_buff[j] = b'\\'
 *                 j += 1
 *                 out_buff[j] = b't'             # <<<<<<<<<<<<<<
 *             elif letter == b'\n':
 *                 out_buff[j] = b'\\'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = 't';

        /* "srctools/_tokenizer.pyx":971
 *                 j += 1
 *                 out_buff[j] = b'"'
 *             elif letter == b'\t':             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *                 j += 1
 */
        break;
        case '\n':

        /* "srctools/_tokenizer.pyx":976
 *                 out_buff[j] = b't'
 *             elif letter == b'\n':
 *                 out_buff[j] = b'\\'             # <<<<<<<<<<<<<<
 *                 j += 1
 *                 out_buff[j] = b'n'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = '\\';

        /* "srctools/_tokenizer.pyx":977
 *             elif letter == b'\n':
 *                 out_buff[j] = b'\\'
 *                 j += 1             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'n'
 *             else:
 */
        __pyx_v_j = (__pyx_v_j + 1);

        /* "srctools/_tokenizer.pyx":978
 *                 out_buff[j] = b'\\'
 *                 j += 1
 *                 out_buff[j] = b'n'             # <<<<<<<<<<<<<<
 *             else:
 *                 out_buff[j] = letter
 */
        (__pyx_v_out_buff[__pyx_v_j]) = 'n';

        /* "srctools/_tokenizer.pyx":975
 *                 j += 1
 *                 out_buff[j] = b't'
 *             elif letter == b'\n':             # <<<<<<<<<<<<<<
 *                 out_buff[j] = b'\\'
 *                 j += 1
 */
        break;
        default:

        /* "srctools/_tokenizer.pyx":980
 *                 out_buff[j] = b'n'
 *             else:
 *                 out_buff[j] = letter             # <<<<<<<<<<<<<<
 *             j += 1
 *         out_buff[final_size] = b'\0'
 */
        (__pyx_v_out_buff[__pyx_v_j]) = __pyx_v_letter;
        break;
      }

      /* "srctools/_tokenizer.pyx":981
 *             else:
 *                 out_buff[j] = letter
 *             j += 1             # <<<<<<<<<<<<<<
 *         out_buff[final_size] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_size)
 */
      __pyx_v_j = (__pyx_v_j + 1);
    }

    /* "srctools/_tokenizer.pyx":982
 *                 out_buff[j] = letter
 *             j += 1
 *         out_buff[final_size] = b'\0'             # <<<<<<<<<<<<<<
 *         return PyUnicode_FromStringAndSize(out_buff, final_size)
 *     finally:
 */
    (__pyx_v_out_buff[__pyx_v_final_size]) = '\x00';

    /* "srctools/_tokenizer.pyx":983
 *             j += 1
 *         out_buff[final_size] = b'\0'
 *         return PyUnicode_FromStringAndSize(out_buff, final_size)             # <<<<<<<<<<<<<<
 *     finally:
 *         PyMem_Free(out_buff)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_6 = PyUnicode_FromStringAndSize(__pyx_v_out_buff, __pyx_v_final_size); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 983, __pyx_L7_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_r = ((PyObject*)__pyx_t_6);
    __pyx_t_6 = 0;
    goto __pyx_L6_return;
  }

  /* "srctools/_tokenizer.pyx":985
 *         return PyUnicode_FromStringAndSize(out_buff, final_size)
 *     finally:
 *         PyMem_Free(out_buff)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*finally:*/ {
    __pyx_L7_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11) < 0)) __Pyx_ErrFetch(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_10);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __pyx_t_4 = __pyx_lineno; __pyx_t_7 = __pyx_clineno; __pyx_t_8 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_out_buff);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_XGIVEREF(__pyx_t_13);
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_ExceptionReset(__pyx_t_12, __pyx_t_13, __pyx_t_14);
      }
      __Pyx_XGIVEREF(__pyx_t_9);
      __Pyx_XGIVEREF(__pyx_t_10);
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_ErrRestore(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0;
      __pyx_lineno = __pyx_t_4; __pyx_clineno = __pyx_t_7; __pyx_filename = __pyx_t_8;
      goto __pyx_L1_error;
    }
    __pyx_L6_return: {
      __pyx_t_15 = __pyx_r;
      __pyx_r = 0;
      PyMem_Free(__pyx_v_out_buff);
      __pyx_r = __pyx_t_15;
      __pyx_t_15 = 0;
      goto __pyx_L0;
    }
  }

  /* "srctools/_tokenizer.pyx":932
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("srctools._tokenizer.escape_text", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":1001
 *     cdef Py_ssize_t used
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.used = 0
 *         self.size = 64
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr___cinit__(((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr___cinit__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "srctools/_tokenizer.pyx":1002
 * 
 *     def __cinit__(self):
 *         self.used = 0             # <<<<<<<<<<<<<<
 *         self.size = 64
 *         self.chars = <uchar *>PyMem_Malloc(self.size)
 */
  __pyx_v_self->used = 0;

  /* "srctools/_tokenizer.pyx":1003
 *     def __cinit__(self):
 *         self.used = 0
 *         self.size = 64             # <<<<<<<<<<<<<<
 *         self.chars = <uchar *>PyMem_Malloc(self.size)
 *         if self.chars is NULL:
 */
  __pyx_v_self->size = 64;

  /* "srctools/_tokenizer.pyx":1004
 *         self.used = 0
 *         self.size = 64
 *         self.chars = <uchar *>PyMem_Malloc(self.size)             # <<<<<<<<<<<<<<
 *         if self.chars is NULL:
 *             raise MemoryError
 */
  __pyx_v_self->chars = ((unsigned char *)PyMem_Malloc(__pyx_v_self->size));

  /* "srctools/_tokenizer.pyx":1005
 *         self.size = 64
 *         self.chars = <uchar *>PyMem_Malloc(self.size)
 *         if self.chars is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->chars == NULL) != 0);
  if (unlikely(__pyx_t_1)) {

    /* "srctools/_tokenizer.pyx":1006
 *         self.chars = <uchar *>PyMem_Malloc(self.size)
 *         if self.chars is NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
 */
    PyErr_NoMemory(); __PYX_ERR(0, 1006, __pyx_L1_error)

    /* "srctools/_tokenizer.pyx":1005
 *         self.size = 64
 *         self.chars = <uchar *>PyMem_Malloc(self.size)
 *         if self.chars is NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 * 
 */
  }

  /* "srctools/_tokenizer.pyx":1001
 *     cdef Py_ssize_t used
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         self.used = 0
 *         self.size = 64
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("srctools._tokenizer._VPK_IterNullstr.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":1008
 *             raise MemoryError
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.chars)
 * 
 */

/* Python wrapper */
static void __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_2__dealloc__(((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_2__dealloc__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "srctools/_tokenizer.pyx":1009
 * 
 *     def __dealloc__(self):
 *         PyMem_Free(self.chars)             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, file):
 */
  PyMem_Free(__pyx_v_self->chars);

  /* "srctools/_tokenizer.pyx":1008
 *             raise MemoryError
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         PyMem_Free(self.chars)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "srctools/_tokenizer.pyx":1011
 *         PyMem_Free(self.chars)
 * 
 *     def __init__(self, file):             # <<<<<<<<<<<<<<
 *         self.file = file
 * 
 */

/* Python wrapper */
static int __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_file = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_file,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_file)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(0, 1011, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_file = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1011, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("srctools._tokenizer._VPK_IterNullstr.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_4__init__(((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)__pyx_v_self), __pyx_v_file);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_4__init__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self, PyObject *__pyx_v_file) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "srctools/_tokenizer.pyx":1012
 * 
 *     def __init__(self, file):
 *         self.file = file             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __Pyx_INCREF(__pyx_v_file);
  __Pyx_GIVEREF(__pyx_v_file);
  __Pyx_GOTREF(__pyx_v_self->file);
  __Pyx_DECREF(__pyx_v_self->file);
  __pyx_v_self->file = __pyx_v_file;

  /* "srctools/_tokenizer.pyx":1011
 *         PyMem_Free(self.chars)
 * 
 *     def __init__(self, file):             # <<<<<<<<<<<<<<
 *         self.file = file
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":1014
 *         self.file = file
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_7__iter__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_7__iter__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_6__iter__(((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_6__iter__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__iter__", 0);

  /* "srctools/_tokenizer.pyx":1015
 * 
 *     def __iter__(self):
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __next__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "srctools/_tokenizer.pyx":1014
 *         self.file = file
 * 
 *     def __iter__(self):             # <<<<<<<<<<<<<<
 *         return self
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "srctools/_tokenizer.pyx":1017
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         cdef bytes data
 *         cdef uchar *temp
 */

/* Python wrapper */
static PyObject *__pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__next__ (wrapper)", 0);
  __pyx_r = __pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_8__next__(((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_8srctools_10_tokenizer_16_VPK_IterNullstr_8__next__(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *__pyx_v_self) {
  PyObject *__pyx_v_data = 0;
  unsigned char *__pyx_v_temp;
  PyObject *__pyx_v_res = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  Py_UCS4 __pyx_t_6;
  char const *__pyx_t_7;
  int __pyx_t_8;
  char const *__pyx_t_9;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__next__", 0);

  /* "srctools/_tokenizer.pyx":1020
 *         cdef bytes data
 *         cdef uchar *temp
 *         while True:             # <<<<<<<<<<<<<<
 *             data = self.file.read(1)
 *             if len(data) == 0:
 */
  while (1) {

    /* "srctools/_tokenizer.pyx":1021
 *         cdef uchar *temp
 *         while True:
 *             data = self.file.read(1)             # <<<<<<<<<<<<<<
 *             if len(data) == 0:
 *                 res = self.chars[:self.used]
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_self->file, __pyx_n_s_read); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1021, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
      if (likely(__pyx_t_3)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_2, function);
      }
    }
    __pyx_t_1 = (__pyx_t_3) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_3, __pyx_int_1) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_int_1);
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1021, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (!(likely(PyBytes_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_1)->tp_name), 0))) __PYX_ERR(0, 1021, __pyx_L1_error)
    __Pyx_XDECREF_SET(__pyx_v_data, ((PyObject*)__pyx_t_1));
    __pyx_t_1 = 0;

    /* "srctools/_tokenizer.pyx":1022
 *         while True:
 *             data = self.file.read(1)
 *             if len(data) == 0:             # <<<<<<<<<<<<<<
 *                 res = self.chars[:self.used]
 *                 self.used = 0
 */
    if (unlikely(__pyx_v_data == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 1022, __pyx_L1_error)
    }
    __pyx_t_4 = PyBytes_GET_SIZE(__pyx_v_data); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1022, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 == 0) != 0);
    if (unlikely(__pyx_t_5)) {

      /* "srctools/_tokenizer.pyx":1023
 *             data = self.file.read(1)
 *             if len(data) == 0:
 *                 res = self.chars[:self.used]             # <<<<<<<<<<<<<<
 *                 self.used = 0
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 */
      __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(((const char*)__pyx_v_self->chars) + 0, __pyx_v_self->used - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1023, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_v_res = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "srctools/_tokenizer.pyx":1024
 *             if len(data) == 0:
 *                 res = self.chars[:self.used]
 *                 self.used = 0             # <<<<<<<<<<<<<<
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 *             elif len(data) > 1:
 */
      __pyx_v_self->used = 0;

      /* "srctools/_tokenizer.pyx":1025
 *                 res = self.chars[:self.used]
 *                 self.used = 0
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')             # <<<<<<<<<<<<<<
 *             elif len(data) > 1:
 *                 raise ValueError('Asked to read 1 byte, got multiple?')
 */
      __pyx_t_1 = PyTuple_New(3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_4 = 0;
      __pyx_t_6 = 127;
      __Pyx_INCREF(__pyx_kp_u_Reached_EOF_without_null_termina);
      __pyx_t_4 += 39;
      __Pyx_GIVEREF(__pyx_kp_u_Reached_EOF_without_null_termina);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_kp_u_Reached_EOF_without_null_termina);
      __pyx_t_2 = __Pyx_PyObject_FormatSimpleAndDecref(PyObject_Repr(__pyx_v_res), __pyx_empty_unicode); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = (__Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_2) > __pyx_t_6) ? __Pyx_PyUnicode_MAX_CHAR_VALUE(__pyx_t_2) : __pyx_t_6;
      __pyx_t_4 += __Pyx_PyUnicode_GET_LENGTH(__pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_2);
      __pyx_t_2 = 0;
      __Pyx_INCREF(__pyx_kp_u__6);
      __pyx_t_4 += 1;
      __Pyx_GIVEREF(__pyx_kp_u__6);
      PyTuple_SET_ITEM(__pyx_t_1, 2, __pyx_kp_u__6);
      __pyx_t_2 = __Pyx_PyUnicode_Join(__pyx_t_1, 3, __pyx_t_4, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])), __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1025, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 1025, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":1022
 *         while True:
 *             data = self.file.read(1)
 *             if len(data) == 0:             # <<<<<<<<<<<<<<
 *                 res = self.chars[:self.used]
 *                 self.used = 0
 */
    }

    /* "srctools/_tokenizer.pyx":1026
 *                 self.used = 0
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 *             elif len(data) > 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError('Asked to read 1 byte, got multiple?')
 *             elif (<const char *>data)[0] == 0x00:
 */
    if (unlikely(__pyx_v_data == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 1026, __pyx_L1_error)
    }
    __pyx_t_4 = PyBytes_GET_SIZE(__pyx_v_data); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1026, __pyx_L1_error)
    __pyx_t_5 = ((__pyx_t_4 > 1) != 0);
    if (unlikely(__pyx_t_5)) {

      /* "srctools/_tokenizer.pyx":1027
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 *             elif len(data) > 1:
 *                 raise ValueError('Asked to read 1 byte, got multiple?')             # <<<<<<<<<<<<<<
 *             elif (<const char *>data)[0] == 0x00:
 *                 # Blank strings are saved as ' '
 */
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1027, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_Raise(__pyx_t_1, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __PYX_ERR(0, 1027, __pyx_L1_error)

      /* "srctools/_tokenizer.pyx":1026
 *                 self.used = 0
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 *             elif len(data) > 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError('Asked to read 1 byte, got multiple?')
 *             elif (<const char *>data)[0] == 0x00:
 */
    }

    /* "srctools/_tokenizer.pyx":1028
 *             elif len(data) > 1:
 *                 raise ValueError('Asked to read 1 byte, got multiple?')
 *             elif (<const char *>data)[0] == 0x00:             # <<<<<<<<<<<<<<
 *                 # Blank strings are saved as ' '
 *                 if self.used == 1 and self.chars[0] == b' ':
 */
    if (unlikely(__pyx_v_data == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
      __PYX_ERR(0, 1028, __pyx_L1_error)
    }
    __pyx_t_7 = __Pyx_PyBytes_AsString(__pyx_v_data); if (unlikely((!__pyx_t_7) && PyErr_Occurred())) __PYX_ERR(0, 1028, __pyx_L1_error)
    __pyx_t_5 = (((((char const *)__pyx_t_7)[0]) == 0x00) != 0);
    if (__pyx_t_5) {

      /* "srctools/_tokenizer.pyx":1030
 *             elif (<const char *>data)[0] == 0x00:
 *                 # Blank strings are saved as ' '
 *                 if self.used == 1 and self.chars[0] == b' ':             # <<<<<<<<<<<<<<
 *                     self.used = 0
 *                     return ''
 */
      __pyx_t_8 = ((__pyx_v_self->used == 1) != 0);
      if (__pyx_t_8) {
      } else {
        __pyx_t_5 = __pyx_t_8;
        goto __pyx_L7_bool_binop_done;
      }
      __pyx_t_8 = (((__pyx_v_self->chars[0]) == ' ') != 0);
      __pyx_t_5 = __pyx_t_8;
      __pyx_L7_bool_binop_done:;
      if (__pyx_t_5) {

        /* "srctools/_tokenizer.pyx":1031
 *                 # Blank strings are saved as ' '
 *                 if self.used == 1 and self.chars[0] == b' ':
 *                     self.used = 0             # <<<<<<<<<<<<<<
 *                     return ''
 *                 if self.used == 0:  # Blank string, this ends the array.
 */
        __pyx_v_self->used = 0;

        /* "srctools/_tokenizer.pyx":1032
 *                 if self.used == 1 and self.chars[0] == b' ':
 *                     self.used = 0
 *                     return ''             # <<<<<<<<<<<<<<
 *                 if self.used == 0:  # Blank string, this ends the array.
 *                     self.used = 0
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_kp_u__8);
        __pyx_r = __pyx_kp_u__8;
        goto __pyx_L0;

        /* "srctools/_tokenizer.pyx":1030
 *             elif (<const char *>data)[0] == 0x00:
 *                 # Blank strings are saved as ' '
 *                 if self.used == 1 and self.chars[0] == b' ':             # <<<<<<<<<<<<<<
 *                     self.used = 0
 *                     return ''
 */
      }

      /* "srctools/_tokenizer.pyx":1033
 *                     self.used = 0
 *                     return ''
 *                 if self.used == 0:  # Blank string, this ends the array.             # <<<<<<<<<<<<<<
 *                     self.used = 0
 *                     raise StopIteration
 */
      __pyx_t_5 = ((__pyx_v_self->used == 0) != 0);
      if (unlikely(__pyx_t_5)) {

        /* "srctools/_tokenizer.pyx":1034
 *                     return ''
 *                 if self.used == 0:  # Blank string, this ends the array.
 *                     self.used = 0             # <<<<<<<<<<<<<<
 *                     raise StopIteration
 *                 else:
 */
        __pyx_v_self->used = 0;

        /* "srctools/_tokenizer.pyx":1035
 *                 if self.used == 0:  # Blank string, this ends the array.
 *                     self.used = 0
 *                     raise StopIteration             # <<<<<<<<<<<<<<
 *                 else:
 *                     res = self.chars[:self.used].decode('ascii', 'surrogateescape')
 */
        __Pyx_Raise(__pyx_builtin_StopIteration, 0, 0, 0);
        __PYX_ERR(0, 1035, __pyx_L1_error)

        /* "srctools/_tokenizer.pyx":1033
 *                     self.used = 0
 *                     return ''
 *                 if self.used == 0:  # Blank string, this ends the array.             # <<<<<<<<<<<<<<
 *                     self.used = 0
 *                     raise StopIteration
 */
      }

      /* "srctools/_tokenizer.pyx":1037
 *                     raise StopIteration
 *                 else:
 *                     res = self.chars[:self.used].decode('ascii', 'surrogateescape')             # <<<<<<<<<<<<<<
 *                     self.used = 0
 *                     return res
 */
      /*else*/ {
        __pyx_t_1 = __Pyx_decode_c_string(((char const *)__pyx_v_self->chars), 0, __pyx_v_self->used, NULL, ((char const *)"surrogateescape"), PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1037, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_v_res = __pyx_t_1;
        __pyx_t_1 = 0;

        /* "srctools/_tokenizer.pyx":1038
 *                 else:
 *                     res = self.chars[:self.used].decode('ascii', 'surrogateescape')
 *                     self.used = 0             # <<<<<<<<<<<<<<
 *                     return res
 *             else:
 */
        __pyx_v_self->used = 0;

        /* "srctools/_tokenizer.pyx":1039
 *                     res = self.chars[:self.used].decode('ascii', 'surrogateescape')
 *                     self.used = 0
 *                     return res             # <<<<<<<<<<<<<<
 *             else:
 *                 if self.used == self.size:
 */
        __Pyx_XDECREF(__pyx_r);
        __Pyx_INCREF(__pyx_v_res);
        __pyx_r = __pyx_v_res;
        goto __pyx_L0;
      }

      /* "srctools/_tokenizer.pyx":1028
 *             elif len(data) > 1:
 *                 raise ValueError('Asked to read 1 byte, got multiple?')
 *             elif (<const char *>data)[0] == 0x00:             # <<<<<<<<<<<<<<
 *                 # Blank strings are saved as ' '
 *                 if self.used == 1 and self.chars[0] == b' ':
 */
    }

    /* "srctools/_tokenizer.pyx":1041
 *                     return res
 *             else:
 *                 if self.used == self.size:             # <<<<<<<<<<<<<<
 *                     self.size *= 2
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 */
    /*else*/ {
      __pyx_t_5 = ((__pyx_v_self->used == __pyx_v_self->size) != 0);
      if (__pyx_t_5) {

        /* "srctools/_tokenizer.pyx":1042
 *             else:
 *                 if self.used == self.size:
 *                     self.size *= 2             # <<<<<<<<<<<<<<
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 *                     if temp == NULL:
 */
        __pyx_v_self->size = (__pyx_v_self->size * 2);

        /* "srctools/_tokenizer.pyx":1043
 *                 if self.used == self.size:
 *                     self.size *= 2
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)             # <<<<<<<<<<<<<<
 *                     if temp == NULL:
 *                         raise MemoryError
 */
        __pyx_v_temp = ((unsigned char *)PyMem_Realloc(__pyx_v_self->chars, __pyx_v_self->size));

        /* "srctools/_tokenizer.pyx":1044
 *                     self.size *= 2
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 *                     if temp == NULL:             # <<<<<<<<<<<<<<
 *                         raise MemoryError
 *                     self.chars = temp
 */
        __pyx_t_5 = ((__pyx_v_temp == NULL) != 0);
        if (unlikely(__pyx_t_5)) {

          /* "srctools/_tokenizer.pyx":1045
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 *                     if temp == NULL:
 *                         raise MemoryError             # <<<<<<<<<<<<<<
 *                     self.chars = temp
 *                 self.chars[self.used] = (<const char *>data)[0]
 */
          PyErr_NoMemory(); __PYX_ERR(0, 1045, __pyx_L1_error)

          /* "srctools/_tokenizer.pyx":1044
 *                     self.size *= 2
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 *                     if temp == NULL:             # <<<<<<<<<<<<<<
 *                         raise MemoryError
 *                     self.chars = temp
 */
        }

        /* "srctools/_tokenizer.pyx":1046
 *                     if temp == NULL:
 *                         raise MemoryError
 *                     self.chars = temp             # <<<<<<<<<<<<<<
 *                 self.chars[self.used] = (<const char *>data)[0]
 *                 self.used += 1
 */
        __pyx_v_self->chars = __pyx_v_temp;

        /* "srctools/_tokenizer.pyx":1041
 *                     return res
 *             else:
 *                 if self.used == self.size:             # <<<<<<<<<<<<<<
 *                     self.size *= 2
 *                     temp = <uchar *>PyMem_Realloc(self.chars, self.size)
 */
      }

      /* "srctools/_tokenizer.pyx":1047
 *                         raise MemoryError
 *                     self.chars = temp
 *                 self.chars[self.used] = (<const char *>data)[0]             # <<<<<<<<<<<<<<
 *                 self.used += 1
 * 
 */
      if (unlikely(__pyx_v_data == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
        __PYX_ERR(0, 1047, __pyx_L1_error)
      }
      __pyx_t_9 = __Pyx_PyBytes_AsString(__pyx_v_data); if (unlikely((!__pyx_t_9) && PyErr_Occurred())) __PYX_ERR(0, 1047, __pyx_L1_error)
      (__pyx_v_self->chars[__pyx_v_self->used]) = (((char const *)__pyx_t_9)[0]);

      /* "srctools/_tokenizer.pyx":1048
 *                     self.chars = temp
 *                 self.chars[self.used] = (<const char *>data)[0]
 *                 self.used += 1             # <<<<<<<<<<<<<<
 * 
 * # Override the tokenizer's name to match the public one.
 */
      __pyx_v_self->used = (__pyx_v_self->used + 1);
    }
  }

  /* "srctools/_tokenizer.pyx":1017
 *         return self
 * 
 *     def __next__(self):             # <<<<<<<<<<<<<<
 *         cdef bytes data
 *         cdef uchar *temp
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("srctools._tokenizer._VPK_IterNullstr.__next__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_data);
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o);
  p->__pyx_vtab = __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  p->error_type = Py_None; Py_INCREF(Py_None);
  p->filename = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->error_type);
  Py_CLEAR(p->filename);
  Py_CLEAR(p->pushback_tok);
  Py_CLEAR(p->pushback_val);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  if (p->error_type) {
    e = (*v)(p->error_type, a); if (e) return e;
  }
  if (p->pushback_tok) {
    e = (*v)(p->pushback_tok, a); if (e) return e;
  }
  if (p->pushback_val) {
    e = (*v)(p->pushback_val, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)o;
  tmp = ((PyObject*)p->error_type);
  p->error_type = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_tok);
  p->pushback_tok = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->pushback_val);
  p->pushback_val = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_filename(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_filename(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8filename_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_error_type(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_error_type(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_10error_type_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_line_num(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_line_num(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_8line_num_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_BaseTokenizer[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_2__reduce__},
  {"error", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_5error, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_4error},
  {"_get_token", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_9_get_token, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_8_get_token},
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__, METH_NOARGS|METH_COEXIST, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12__next__},
  {"push_back", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_15push_back, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_14push_back},
  {"peek", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_17peek, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_16peek},
  {"skipping_newlines", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_18skipping_newlines},
  {"block", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_21block, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_20block},
  {"expect", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_23expect, METH_VARARGS|METH_KEYWORDS, __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_22expect},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_BaseTokenizer[] = {
  {(char *)"filename", __pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_filename, __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_filename, (char *)"Retrieve the filename used in error messages.", 0},
  {(char *)"error_type", __pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_error_type, __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_error_type, (char *)"Return the TokenSyntaxError subclass raised when errors occur.", 0},
  {(char *)"line_num", __pyx_getprop_8srctools_10_tokenizer_13BaseTokenizer_line_num, __pyx_setprop_8srctools_10_tokenizer_13BaseTokenizer_line_num, (char *)"line_num: 'int'", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_BaseTokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.BaseTokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "BaseTokenizer(filename, error)\nProvides an interface for processing text into tokens.\n\n     It then provides tools for using those to parse data.\n     This is an abstract class, a subclass must be used to provide a source\n     for the tokens.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_BaseTokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_BaseTokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_Tokenizer __pyx_vtable_8srctools_10_tokenizer_Tokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_Tokenizer(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p;
  PyObject *o = __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(t, a, k);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o);
  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer*)__pyx_vtabptr_8srctools_10_tokenizer_Tokenizer;
  p->cur_chunk = Py_None; Py_INCREF(Py_None);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_9Tokenizer_1__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_8srctools_10_tokenizer_9Tokenizer_3__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->cur_chunk);
  Py_CLEAR(p->chunk_iter);
  PyObject_GC_Track(o);
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  e = __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(o, v, a); if (e) return e;
  if (p->cur_chunk) {
    e = (*v)(p->cur_chunk, a); if (e) return e;
  }
  if (p->chunk_iter) {
    e = (*v)(p->chunk_iter, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *)o;
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(o);
  tmp = ((PyObject*)p->cur_chunk);
  p->cur_chunk = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->chunk_iter);
  p->chunk_iter = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14string_bracket_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_13allow_escapes_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_19allow_star_comments_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_9Tokenizer_colon_operator(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_colon_operator(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_9Tokenizer_14colon_operator_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_Tokenizer[] = {
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_Tokenizer[] = {
  {(char *)"string_bracket", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_string_bracket, (char *)"Check if [bracket] blocks are parsed as a single string-like block.\n\n        If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.\n        ", 0},
  {(char *)"allow_escapes", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_escapes, (char *)"Check if backslash escapes will be parsed.", 0},
  {(char *)"allow_star_comments", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_allow_star_comments, (char *)"Check if /**/ style comments will be enabled.", 0},
  {(char *)"colon_operator", __pyx_getprop_8srctools_10_tokenizer_9Tokenizer_colon_operator, __pyx_setprop_8srctools_10_tokenizer_9Tokenizer_colon_operator, (char *)"Check if : characters are treated as a COLON token, or part of strings.", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_Tokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.Tokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_Tokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  #else
  0, /*tp_call*/
  #endif
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Tokenizer(data, filename=None, error=None, bool string_bracket=False, bool allow_escapes=True, bool allow_star_comments=False, bool colon_operator=False)\nProcesses text data into groups of tokens.\n\n    This mainly groups strings and removes comments.\n\n    Due to many inconsistencies in Valve's parsing of files,\n    several options are available to control whether different\n    syntaxes are accepted:\n        * string_bracket parses [bracket] blocks as a single string-like block.\n          If disabled these are parsed as BRACK_OPEN, STRING, BRACK_CLOSE.\n        * allow_escapes controls whether \\n-style escapes are expanded.\n        * allow_star_comments if enabled allows /* */ comments.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_Tokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_Tokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11__iter__, /*tp_iter*/
  #else
  0, /*tp_iter*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__, /*tp_iternext*/
  #else
  0, /*tp_iternext*/
  #endif
  __pyx_methods_8srctools_10_tokenizer_Tokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_Tokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_9Tokenizer_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_Tokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};
static struct __pyx_vtabstruct_8srctools_10_tokenizer_IterTokenizer __pyx_vtable_8srctools_10_tokenizer_IterTokenizer;

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_IterTokenizer(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p;
  PyObject *o = __pyx_tp_new_8srctools_10_tokenizer_BaseTokenizer(t, a, k);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o);
  p->__pyx_base.__pyx_vtab = (struct __pyx_vtabstruct_8srctools_10_tokenizer_BaseTokenizer*)__pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer;
  p->source = Py_None; Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_IterTokenizer(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->source);
  PyObject_GC_Track(o);
  __pyx_tp_dealloc_8srctools_10_tokenizer_BaseTokenizer(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_IterTokenizer(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  e = __pyx_tp_traverse_8srctools_10_tokenizer_BaseTokenizer(o, v, a); if (e) return e;
  if (p->source) {
    e = (*v)(p->source, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_IterTokenizer(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *p = (struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer *)o;
  __pyx_tp_clear_8srctools_10_tokenizer_BaseTokenizer(o);
  tmp = ((PyObject*)p->source);
  p->source = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_8srctools_10_tokenizer_13IterTokenizer_source(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_1__get__(o);
}

static int __pyx_setprop_8srctools_10_tokenizer_13IterTokenizer_source(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_3__set__(o, v);
  }
  else {
    return __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_6source_5__del__(o);
  }
}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_IterTokenizer[] = {
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_8srctools_10_tokenizer_IterTokenizer[] = {
  {(char *)"source", __pyx_getprop_8srctools_10_tokenizer_13IterTokenizer_source, __pyx_setprop_8srctools_10_tokenizer_13IterTokenizer_source, (char *)"source: object", 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_IterTokenizer = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.IterTokenizer", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_IterTokenizer), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_IterTokenizer, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_3__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_7__call__, /*tp_call*/
  #else
  0, /*tp_call*/
  #endif
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "IterTokenizer(source, filename=u'', error=None) -> None\nWraps a token iterator to provide the tokenizer interface.\n\n    This is useful to pre-process a token stream before parsing it with other\n    code.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_IterTokenizer, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_IterTokenizer, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_11__iter__, /*tp_iter*/
  #else
  0, /*tp_iter*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY
  __pyx_pw_8srctools_10_tokenizer_13BaseTokenizer_13__next__, /*tp_iternext*/
  #else
  0, /*tp_iternext*/
  #endif
  __pyx_methods_8srctools_10_tokenizer_IterTokenizer, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_8srctools_10_tokenizer_IterTokenizer, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13IterTokenizer_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_IterTokenizer, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyObject *__pyx_tp_new_8srctools_10_tokenizer__NewlinesIter(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p;
  PyObject *o;
  o = (*t->tp_alloc)(t, 0);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer__NewlinesIter(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->tok);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer__NewlinesIter(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  if (p->tok) {
    e = (*v)(((PyObject *)p->tok), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer__NewlinesIter(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *p = (struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter *)o;
  tmp = ((PyObject*)p->tok);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer__NewlinesIter[] = {
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__, METH_NOARGS|METH_COEXIST, 0},
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_13_NewlinesIter_10__reduce__},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer__NewlinesIter = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer._NewlinesIter", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer__NewlinesIter), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer__NewlinesIter, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_3__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Iterate over the tokens, skipping newlines.", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer__NewlinesIter, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer__NewlinesIter, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_7__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_9__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer__NewlinesIter, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_13_NewlinesIter_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer__NewlinesIter, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyObject *__pyx_tp_new_8srctools_10_tokenizer_BlockIter(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer_BlockIter *p;
  PyObject *o;
  o = (*t->tp_alloc)(t, 0);
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)o);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)Py_None); Py_INCREF(Py_None);
  p->name = ((PyObject*)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_9BlockIter_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer_BlockIter(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer_BlockIter *p = (struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->tok);
  Py_CLEAR(p->name);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer_BlockIter(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer_BlockIter *p = (struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)o;
  if (p->tok) {
    e = (*v)(((PyObject *)p->tok), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer_BlockIter(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer_BlockIter *p = (struct __pyx_obj_8srctools_10_tokenizer_BlockIter *)o;
  tmp = ((PyObject*)p->tok);
  p->tok = ((struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer_BlockIter[] = {
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__, METH_NOARGS|METH_COEXIST, 0},
  {"__reduce__", (PyCFunction)__pyx_pw_8srctools_10_tokenizer_9BlockIter_11__reduce__, METH_NOARGS, __pyx_doc_8srctools_10_tokenizer_9BlockIter_10__reduce__},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer_BlockIter = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer.BlockIter", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer_BlockIter), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer_BlockIter, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_8srctools_10_tokenizer_9BlockIter_3__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "Helper iterator for parsing keyvalue style blocks.", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer_BlockIter, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer_BlockIter, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_9BlockIter_7__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_9BlockIter_9__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer_BlockIter, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_9BlockIter_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer_BlockIter, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyObject *__pyx_tp_new_8srctools_10_tokenizer__VPK_IterNullstr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)o);
  p->file = Py_None; Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_1__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_8srctools_10_tokenizer__VPK_IterNullstr(PyObject *o) {
  struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *p = (struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_3__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->file);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_8srctools_10_tokenizer__VPK_IterNullstr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *p = (struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)o;
  if (p->file) {
    e = (*v)(p->file, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_8srctools_10_tokenizer__VPK_IterNullstr(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *p = (struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr *)o;
  tmp = ((PyObject*)p->file);
  p->file = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__(PyObject *self, CYTHON_UNUSED PyObject *arg) {return __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__(self);}

static PyMethodDef __pyx_methods_8srctools_10_tokenizer__VPK_IterNullstr[] = {
  {"__next__", (PyCFunction)__pyx_specialmethod___pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__, METH_NOARGS|METH_COEXIST, 0},
  {0, 0, 0, 0}
};

static PyTypeObject __pyx_type_8srctools_10_tokenizer__VPK_IterNullstr = {
  PyVarObject_HEAD_INIT(0, 0)
  "srctools._tokenizer._VPK_IterNullstr", /*tp_name*/
  sizeof(struct __pyx_obj_8srctools_10_tokenizer__VPK_IterNullstr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_8srctools_10_tokenizer__VPK_IterNullstr, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "_VPK_IterNullstr(file)\nRead a null-terminated ASCII string from the file.\n\n    This continuously yields strings, with empty strings\n    indicting the end of a section.\n    ", /*tp_doc*/
  __pyx_tp_traverse_8srctools_10_tokenizer__VPK_IterNullstr, /*tp_traverse*/
  __pyx_tp_clear_8srctools_10_tokenizer__VPK_IterNullstr, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_7__iter__, /*tp_iter*/
  __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_9__next__, /*tp_iternext*/
  __pyx_methods_8srctools_10_tokenizer__VPK_IterNullstr, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_8srctools_10_tokenizer_16_VPK_IterNullstr_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_8srctools_10_tokenizer__VPK_IterNullstr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1
  0, /*tp_vectorcall*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
  0, /*tp_print*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec__tokenizer(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec__tokenizer},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "_tokenizer",
    __pyx_k_Cython_version_of_the_Tokenizer, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_kp_u_, __pyx_k_, sizeof(__pyx_k_), 0, 1, 0, 0},
  {&__pyx_kp_u_Asked_to_read_1_byte_got_multipl, __pyx_k_Asked_to_read_1_byte_got_multipl, sizeof(__pyx_k_Asked_to_read_1_byte_got_multipl), 0, 1, 0, 0},
  {&__pyx_n_s_AttributeError, __pyx_k_AttributeError, sizeof(__pyx_k_AttributeError), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_CLOSE, __pyx_k_BRACE_CLOSE, sizeof(__pyx_k_BRACE_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACE_OPEN, __pyx_k_BRACE_OPEN, sizeof(__pyx_k_BRACE_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_CLOSE, __pyx_k_BRACK_CLOSE, sizeof(__pyx_k_BRACK_CLOSE), 0, 0, 1, 1},
  {&__pyx_n_s_BRACK_OPEN, __pyx_k_BRACK_OPEN, sizeof(__pyx_k_BRACK_OPEN), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer, __pyx_k_BaseTokenizer, sizeof(__pyx_k_BaseTokenizer), 0, 0, 1, 1},
  {&__pyx_n_u_BaseTokenizer, __pyx_k_BaseTokenizer, sizeof(__pyx_k_BaseTokenizer), 0, 1, 0, 1},
  {&__pyx_n_s_BaseTokenizer___reduce, __pyx_k_BaseTokenizer___reduce, sizeof(__pyx_k_BaseTokenizer___reduce), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer__get_token, __pyx_k_BaseTokenizer__get_token, sizeof(__pyx_k_BaseTokenizer__get_token), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_block, __pyx_k_BaseTokenizer_block, sizeof(__pyx_k_BaseTokenizer_block), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_error, __pyx_k_BaseTokenizer_error, sizeof(__pyx_k_BaseTokenizer_error), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_expect, __pyx_k_BaseTokenizer_expect, sizeof(__pyx_k_BaseTokenizer_expect), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_peek, __pyx_k_BaseTokenizer_peek, sizeof(__pyx_k_BaseTokenizer_peek), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_push_back, __pyx_k_BaseTokenizer_push_back, sizeof(__pyx_k_BaseTokenizer_push_back), 0, 0, 1, 1},
  {&__pyx_n_s_BaseTokenizer_skipping_newlines, __pyx_k_BaseTokenizer_skipping_newlines, sizeof(__pyx_k_BaseTokenizer_skipping_newlines), 0, 0, 1, 1},
  {&__pyx_n_s_BlockIter___reduce, __pyx_k_BlockIter___reduce, sizeof(__pyx_k_BlockIter___reduce), 0, 0, 1, 1},
  {&__pyx_n_s_COLON, __pyx_k_COLON, sizeof(__pyx_k_COLON), 0, 0, 1, 1},
  {&__pyx_n_s_COMMA, __pyx_k_COMMA, sizeof(__pyx_k_COMMA), 0, 0, 1, 1},
  {&__pyx_kp_u_Cannot_create_BlockIter_instance, __pyx_k_Cannot_create_BlockIter_instance, sizeof(__pyx_k_Cannot_create_BlockIter_instance), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_create__NewlinesIter_inst, __pyx_k_Cannot_create__NewlinesIter_inst, sizeof(__pyx_k_Cannot_create__NewlinesIter_inst), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_nest_brackets, __pyx_k_Cannot_nest_brackets, sizeof(__pyx_k_Cannot_nest_brackets), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_nest_brackets_2, __pyx_k_Cannot_nest_brackets_2, sizeof(__pyx_k_Cannot_nest_brackets_2), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data, __pyx_k_Cannot_parse_binary_data, sizeof(__pyx_k_Cannot_parse_binary_data), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_parse_binary_data_Decode, __pyx_k_Cannot_parse_binary_data_Decode, sizeof(__pyx_k_Cannot_parse_binary_data_Decode), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle_BlockIter, __pyx_k_Cannot_pickle_BlockIter, sizeof(__pyx_k_Cannot_pickle_BlockIter), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle_Tokenizers, __pyx_k_Cannot_pickle_Tokenizers, sizeof(__pyx_k_Cannot_pickle_Tokenizers), 0, 1, 0, 0},
  {&__pyx_kp_u_Cannot_pickle__NewlinesIter, __pyx_k_Cannot_pickle__NewlinesIter, sizeof(__pyx_k_Cannot_pickle__NewlinesIter), 0, 1, 0, 0},
  {&__pyx_kp_u_Could_not_decode_file, __pyx_k_Could_not_decode_file, sizeof(__pyx_k_Could_not_decode_file), 0, 1, 0, 0},
  {&__pyx_n_s_DIRECTIVE, __pyx_k_DIRECTIVE, sizeof(__pyx_k_DIRECTIVE), 0, 0, 1, 1},
  {&__pyx_kp_u_Data_was_not_a_string, __pyx_k_Data_was_not_a_string, sizeof(__pyx_k_Data_was_not_a_string), 0, 1, 0, 0},
  {&__pyx_n_s_EOF, __pyx_k_EOF, sizeof(__pyx_k_EOF), 0, 0, 1, 1},
  {&__pyx_n_s_EQUALS, __pyx_k_EQUALS, sizeof(__pyx_k_EQUALS), 0, 0, 1, 1},
  {&__pyx_kp_u_Expected, __pyx_k_Expected, sizeof(__pyx_k_Expected), 0, 1, 0, 0},
  {&__pyx_kp_u_Expected_BRACE_OPEN_but_got, __pyx_k_Expected_BRACE_OPEN_but_got, sizeof(__pyx_k_Expected_BRACE_OPEN_but_got), 0, 1, 0, 0},
  {&__pyx_kp_u_Expected_string_got, __pyx_k_Expected_string_got, sizeof(__pyx_k_Expected_string_got), 0, 1, 0, 0},
  {&__pyx_kp_u_Invalid_error_instance, __pyx_k_Invalid_error_instance, sizeof(__pyx_k_Invalid_error_instance), 0, 1, 0, 0},
  {&__pyx_kp_u_IterTokenizer, __pyx_k_IterTokenizer, sizeof(__pyx_k_IterTokenizer), 0, 1, 0, 0},
  {&__pyx_n_s_IterTokenizer_2, __pyx_k_IterTokenizer_2, sizeof(__pyx_k_IterTokenizer_2), 0, 0, 1, 1},
  {&__pyx_n_u_IterTokenizer_2, __pyx_k_IterTokenizer_2, sizeof(__pyx_k_IterTokenizer_2), 0, 1, 0, 1},
  {&__pyx_n_s_MemoryError, __pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 0, 1, 1},
  {&__pyx_n_s_NEWLINE, __pyx_k_NEWLINE, sizeof(__pyx_k_NEWLINE), 0, 0, 1, 1},
  {&__pyx_n_s_NewlinesIter___reduce, __pyx_k_NewlinesIter___reduce, sizeof(__pyx_k_NewlinesIter___reduce), 0, 0, 1, 1},
  {&__pyx_kp_u_No_open_to_close_with, __pyx_k_No_open_to_close_with, sizeof(__pyx_k_No_open_to_close_with), 0, 1, 0, 0},
  {&__pyx_kp_u_No_open_to_close_with_2, __pyx_k_No_open_to_close_with_2, sizeof(__pyx_k_No_open_to_close_with_2), 0, 1, 0, 0},
  {&__pyx_kp_u_None, __pyx_k_None, sizeof(__pyx_k_None), 0, 1, 0, 0},
  {&__pyx_n_s_NotImplementedError, __pyx_k_NotImplementedError, sizeof(__pyx_k_NotImplementedError), 0, 0, 1, 1},
  {&__pyx_n_s_PAREN_ARGS, __pyx_k_PAREN_ARGS, sizeof(__pyx_k_PAREN_ARGS), 0, 0, 1, 1},
  {&__pyx_n_s_PLUS, __pyx_k_PLUS, sizeof(__pyx_k_PLUS), 0, 0, 1, 1},
  {&__pyx_n_s_PROP_FLAG, __pyx_k_PROP_FLAG, sizeof(__pyx_k_PROP_FLAG), 0, 0, 1, 1},
  {&__pyx_kp_u_Reached_EOF_without_null_termina, __pyx_k_Reached_EOF_without_null_termina, sizeof(__pyx_k_Reached_EOF_without_null_termina), 0, 1, 0, 0},
  {&__pyx_kp_u_Reached_end_of_line_without_clos, __pyx_k_Reached_end_of_line_without_clos, sizeof(__pyx_k_Reached_end_of_line_without_clos), 0, 1, 0, 0},
  {&__pyx_n_s_STRING, __pyx_k_STRING, sizeof(__pyx_k_STRING), 0, 0, 1, 1},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw, __pyx_k_Single_slash_found_instead_of_tw, sizeof(__pyx_k_Single_slash_found_instead_of_tw), 0, 1, 0, 0},
  {&__pyx_kp_u_Single_slash_found_instead_of_tw_2, __pyx_k_Single_slash_found_instead_of_tw_2, sizeof(__pyx_k_Single_slash_found_instead_of_tw_2), 0, 1, 0, 0},
  {&__pyx_n_s_StopIteration, __pyx_k_StopIteration, sizeof(__pyx_k_StopIteration), 0, 0, 1, 1},
  {&__pyx_kp_u_The_error_type_must_be_a_TokenSy, __pyx_k_The_error_type_must_be_a_TokenSy, sizeof(__pyx_k_The_error_type_must_be_a_TokenSy), 0, 1, 0, 0},
  {&__pyx_kp_u_Token, __pyx_k_Token, sizeof(__pyx_k_Token), 0, 1, 0, 0},
  {&__pyx_n_s_TokenSyntaxError, __pyx_k_TokenSyntaxError, sizeof(__pyx_k_TokenSyntaxError), 0, 0, 1, 1},
  {&__pyx_n_s_Token_2, __pyx_k_Token_2, sizeof(__pyx_k_Token_2), 0, 0, 1, 1},
  {&__pyx_kp_u_Token_already_pushed_back, __pyx_k_Token_already_pushed_back, sizeof(__pyx_k_Token_already_pushed_back), 0, 1, 0, 0},
  {&__pyx_n_s_Tokenizer, __pyx_k_Tokenizer, sizeof(__pyx_k_Tokenizer), 0, 0, 1, 1},
  {&__pyx_n_u_Tokenizer, __pyx_k_Tokenizer, sizeof(__pyx_k_Tokenizer), 0, 1, 0, 1},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_kp_u_Unclosed, __pyx_k_Unclosed, sizeof(__pyx_k_Unclosed), 0, 1, 0, 0},
  {&__pyx_kp_u_Unclosed_comment_starting_on_lin, __pyx_k_Unclosed_comment_starting_on_lin, sizeof(__pyx_k_Unclosed_comment_starting_on_lin), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_character, __pyx_k_Unexpected_character, sizeof(__pyx_k_Unexpected_character), 0, 1, 0, 0},
  {&__pyx_kp_u_Unexpected_token, __pyx_k_Unexpected_token, sizeof(__pyx_k_Unexpected_token), 0, 1, 0, 0},
  {&__pyx_n_s_UnicodeDecodeError, __pyx_k_UnicodeDecodeError, sizeof(__pyx_k_UnicodeDecodeError), 0, 0, 1, 1},
  {&__pyx_kp_u_Unknown_token, __pyx_k_Unknown_token, sizeof(__pyx_k_Unknown_token), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_parentheses, __pyx_k_Unterminated_parentheses, sizeof(__pyx_k_Unterminated_parentheses), 0, 1, 0, 0},
  {&__pyx_kp_u_Unterminated_string, __pyx_k_Unterminated_string, sizeof(__pyx_k_Unterminated_string), 0, 1, 0, 0},
  {&__pyx_n_s_VPK_IterNullstr, __pyx_k_VPK_IterNullstr, sizeof(__pyx_k_VPK_IterNullstr), 0, 0, 1, 1},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_u_Value_required_for, __pyx_k_Value_required_for, sizeof(__pyx_k_Value_required_for), 0, 1, 0, 0},
  {&__pyx_n_u_X, __pyx_k_X, sizeof(__pyx_k_X), 0, 1, 0, 1},
  {&__pyx_kp_u__10, __pyx_k__10, sizeof(__pyx_k__10), 0, 1, 0, 0},
  {&__pyx_kp_u__11, __pyx_k__11, sizeof(__pyx_k__11), 0, 1, 0, 0},
  {&__pyx_kp_u__12, __pyx_k__12, sizeof(__pyx_k__12), 0, 1, 0, 0},
  {&__pyx_kp_u__13, __pyx_k__13, sizeof(__pyx_k__13), 0, 1, 0, 0},
  {&__pyx_kp_u__14, __pyx_k__14, sizeof(__pyx_k__14), 0, 1, 0, 0},
  {&__pyx_kp_u__15, __pyx_k__15, sizeof(__pyx_k__15), 0, 1, 0, 0},
  {&__pyx_kp_u__16, __pyx_k__16, sizeof(__pyx_k__16), 0, 1, 0, 0},
  {&__pyx_kp_u__17, __pyx_k__17, sizeof(__pyx_k__17), 0, 1, 0, 0},
  {&__pyx_kp_u__21, __pyx_k__21, sizeof(__pyx_k__21), 0, 1, 0, 0},
  {&__pyx_kp_u__22, __pyx_k__22, sizeof(__pyx_k__22), 0, 1, 0, 0},
  {&__pyx_kp_u__23, __pyx_k__23, sizeof(__pyx_k__23), 0, 1, 0, 0},
  {&__pyx_kp_u__3, __pyx_k__3, sizeof(__pyx_k__3), 0, 1, 0, 0},
  {&__pyx_kp_u__4, __pyx_k__4, sizeof(__pyx_k__4), 0, 1, 0, 0},
  {&__pyx_kp_u__5, __pyx_k__5, sizeof(__pyx_k__5), 0, 1, 0, 0},
  {&__pyx_kp_u__6, __pyx_k__6, sizeof(__pyx_k__6), 0, 1, 0, 0},
  {&__pyx_kp_u__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 1, 0, 0},
  {&__pyx_kp_u__9, __pyx_k__9, sizeof(__pyx_k__9), 0, 1, 0, 0},
  {&__pyx_n_s_all, __pyx_k_all, sizeof(__pyx_k_all), 0, 0, 1, 1},
  {&__pyx_n_s_allow_escapes, __pyx_k_allow_escapes, sizeof(__pyx_k_allow_escapes), 0, 0, 1, 1},
  {&__pyx_n_s_allow_star_comments, __pyx_k_allow_star_comments, sizeof(__pyx_k_allow_star_comments), 0, 0, 1, 1},
  {&__pyx_n_s_args, __pyx_k_args, sizeof(__pyx_k_args), 0, 0, 1, 1},
  {&__pyx_kp_u_block, __pyx_k_block, sizeof(__pyx_k_block), 0, 1, 0, 0},
  {&__pyx_n_s_block_2, __pyx_k_block_2, sizeof(__pyx_k_block_2), 0, 0, 1, 1},
  {&__pyx_kp_u_but_got, __pyx_k_but_got, sizeof(__pyx_k_but_got), 0, 1, 0, 0},
  {&__pyx_n_s_casefold, __pyx_k_casefold, sizeof(__pyx_k_casefold), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_colon_operator, __pyx_k_colon_operator, sizeof(__pyx_k_colon_operator), 0, 0, 1, 1},
  {&__pyx_n_s_consume_brace, __pyx_k_consume_brace, sizeof(__pyx_k_consume_brace), 0, 0, 1, 1},
  {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
  {&__pyx_n_s_error, __pyx_k_error, sizeof(__pyx_k_error), 0, 0, 1, 1},
  {&__pyx_n_s_escape_text, __pyx_k_escape_text, sizeof(__pyx_k_escape_text), 0, 0, 1, 1},
  {&__pyx_n_u_escape_text, __pyx_k_escape_text, sizeof(__pyx_k_escape_text), 0, 1, 0, 1},
  {&__pyx_n_s_expect, __pyx_k_expect, sizeof(__pyx_k_expect), 0, 0, 1, 1},
  {&__pyx_n_s_expect_brace, __pyx_k_expect_brace, sizeof(__pyx_k_expect_brace), 0, 0, 1, 1},
  {&__pyx_n_s_file, __pyx_k_file, sizeof(__pyx_k_file), 0, 0, 1, 1},
  {&__pyx_n_s_filename, __pyx_k_filename, sizeof(__pyx_k_filename), 0, 0, 1, 1},
  {&__pyx_n_s_final_size, __pyx_k_final_size, sizeof(__pyx_k_final_size), 0, 0, 1, 1},
  {&__pyx_n_s_format, __pyx_k_format, sizeof(__pyx_k_format), 0, 0, 1, 1},
  {&__pyx_n_s_fspath, __pyx_k_fspath, sizeof(__pyx_k_fspath), 0, 0, 1, 1},
  {&__pyx_n_s_get_token, __pyx_k_get_token, sizeof(__pyx_k_get_token), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_in_buf, __pyx_k_in_buf, sizeof(__pyx_k_in_buf), 0, 0, 1, 1},
  {&__pyx_n_s_init, __pyx_k_init, sizeof(__pyx_k_init), 0, 0, 1, 1},
  {&__pyx_kp_u_is_not_a_Token, __pyx_k_is_not_a_Token, sizeof(__pyx_k_is_not_a_Token), 0, 1, 0, 0},
  {&__pyx_n_s_j, __pyx_k_j, sizeof(__pyx_k_j), 0, 0, 1, 1},
  {&__pyx_n_s_letter, __pyx_k_letter, sizeof(__pyx_k_letter), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_message, __pyx_k_message, sizeof(__pyx_k_message), 0, 0, 1, 1},
  {&__pyx_n_s_module, __pyx_k_module, sizeof(__pyx_k_module), 0, 0, 1, 1},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_name_2, __pyx_k_name_2, sizeof(__pyx_k_name_2), 0, 0, 1, 1},
  {&__pyx_n_s_next_token, __pyx_k_next_token, sizeof(__pyx_k_next_token), 0, 0, 1, 1},
  {&__pyx_n_s_os, __pyx_k_os, sizeof(__pyx_k_os), 0, 0, 1, 1},
  {&__pyx_n_s_out_buff, __pyx_k_out_buff, sizeof(__pyx_k_out_buff), 0, 0, 1, 1},
  {&__pyx_kp_u_passed_with_multiple_values, __pyx_k_passed_with_multiple_values, sizeof(__pyx_k_passed_with_multiple_values), 0, 1, 0, 0},
  {&__pyx_n_s_peek, __pyx_k_peek, sizeof(__pyx_k_peek), 0, 0, 1, 1},
  {&__pyx_n_s_push_back, __pyx_k_push_back, sizeof(__pyx_k_push_back), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_read, __pyx_k_read, sizeof(__pyx_k_read), 0, 0, 1, 1},
  {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
  {&__pyx_n_s_return, __pyx_k_return, sizeof(__pyx_k_return), 0, 0, 1, 1},
  {&__pyx_n_s_self, __pyx_k_self, sizeof(__pyx_k_self), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_skip_newline, __pyx_k_skip_newline, sizeof(__pyx_k_skip_newline), 0, 0, 1, 1},
  {&__pyx_n_s_skipping_newlines, __pyx_k_skipping_newlines, sizeof(__pyx_k_skipping_newlines), 0, 0, 1, 1},
  {&__pyx_n_s_source, __pyx_k_source, sizeof(__pyx_k_source), 0, 0, 1, 1},
  {&__pyx_n_s_srctools__tokenizer, __pyx_k_srctools__tokenizer, sizeof(__pyx_k_srctools__tokenizer), 0, 0, 1, 1},
  {&__pyx_kp_s_srctools__tokenizer_pyx, __pyx_k_srctools__tokenizer_pyx, sizeof(__pyx_k_srctools__tokenizer_pyx), 0, 0, 1, 0},
  {&__pyx_n_s_srctools_tokenizer, __pyx_k_srctools_tokenizer, sizeof(__pyx_k_srctools_tokenizer), 0, 0, 1, 1},
  {&__pyx_kp_u_srctools_tokenizer, __pyx_k_srctools_tokenizer, sizeof(__pyx_k_srctools_tokenizer), 0, 1, 0, 0},
  {&__pyx_kp_u_srctools_tokenizer_BaseTokenize, __pyx_k_srctools_tokenizer_BaseTokenize, sizeof(__pyx_k_srctools_tokenizer_BaseTokenize), 0, 1, 0, 0},
  {&__pyx_kp_u_srctools_tokenizer_BaseTokenize_2, __pyx_k_srctools_tokenizer_BaseTokenize_2, sizeof(__pyx_k_srctools_tokenizer_BaseTokenize_2), 0, 1, 0, 0},
  {&__pyx_n_s_str_msg, __pyx_k_str_msg, sizeof(__pyx_k_str_msg), 0, 0, 1, 1},
  {&__pyx_n_s_string_bracket, __pyx_k_string_bracket, sizeof(__pyx_k_string_bracket), 0, 0, 1, 1},
  {&__pyx_kp_u_style_comments_are_not_allowed, __pyx_k_style_comments_are_not_allowed, sizeof(__pyx_k_style_comments_are_not_allowed), 0, 1, 0, 0},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_text, __pyx_k_text, sizeof(__pyx_k_text), 0, 0, 1, 1},
  {&__pyx_n_s_tok, __pyx_k_tok, sizeof(__pyx_k_tok), 0, 0, 1, 1},
  {&__pyx_n_s_tok_and_val, __pyx_k_tok_and_val, sizeof(__pyx_k_tok_and_val), 0, 0, 1, 1},
  {&__pyx_n_s_tok_val, __pyx_k_tok_val, sizeof(__pyx_k_tok_val), 0, 0, 1, 1},
  {&__pyx_n_s_token, __pyx_k_token, sizeof(__pyx_k_token), 0, 0, 1, 1},
  {&__pyx_n_u_unicode, __pyx_k_unicode, sizeof(__pyx_k_unicode), 0, 1, 0, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_value_2, __pyx_k_value_2, sizeof(__pyx_k_value_2), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(0, 111, __pyx_L1_error)
  __pyx_builtin_NotImplementedError = __Pyx_GetBuiltinName(__pyx_n_s_NotImplementedError); if (!__pyx_builtin_NotImplementedError) __PYX_ERR(0, 211, __pyx_L1_error)
  __pyx_builtin_StopIteration = __Pyx_GetBuiltinName(__pyx_n_s_StopIteration); if (!__pyx_builtin_StopIteration) __PYX_ERR(0, 221, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 232, __pyx_L1_error)
  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(0, 341, __pyx_L1_error)
  __pyx_builtin_AttributeError = __Pyx_GetBuiltinName(__pyx_n_s_AttributeError); if (!__pyx_builtin_AttributeError) __PYX_ERR(0, 388, __pyx_L1_error)
  __pyx_builtin_UnicodeDecodeError = __Pyx_GetBuiltinName(__pyx_n_s_UnicodeDecodeError); if (!__pyx_builtin_UnicodeDecodeError) __PYX_ERR(0, 548, __pyx_L1_error)
  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(0, 857, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 948, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "srctools/_tokenizer.pyx":125
 *         There is also the issue with recreating the C/Python versions.
 *         """
 *         raise TypeError('Cannot pickle Tokenizers!')             # <<<<<<<<<<<<<<
 * 
 *     @property
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle_Tokenizers); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "srctools/_tokenizer.pyx":232
 *         """
 *         if self.pushback_tok is not None:
 *             raise ValueError('Token already pushed back!')             # <<<<<<<<<<<<<<
 *         if not isinstance(tok, Token):
 *             raise ValueError(f'{tok!r} is not a Token!')
 */
  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_u_Token_already_pushed_back); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(0, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__7);
  __Pyx_GIVEREF(__pyx_tuple__7);

  /* "srctools/_tokenizer.pyx":358
 *         # Early warning for this particular error.
 *         if isinstance(data, bytes) or isinstance(data, bytearray):
 *             raise TypeError(             # <<<<<<<<<<<<<<
 *                 'Cannot parse binary data! Decode to the desired encoding, '
 *                 'or wrap in io.TextIOWrapper() to decode gradually.'
 */
  __pyx_tuple__18 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data_Decode); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 358, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);

  /* "srctools/_tokenizer.pyx":556
 * 
 *             if isinstance(chunk_obj, bytes):
 *                 raise ValueError('Cannot parse binary data!')             # <<<<<<<<<<<<<<
 *             if type(chunk_obj) is not str:
 *                 raise ValueError("Data was not a string!")
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_kp_u_Cannot_parse_binary_data); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 556, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "srctools/_tokenizer.pyx":558
 *                 raise ValueError('Cannot parse binary data!')
 *             if type(chunk_obj) is not str:
 *                 raise ValueError("Data was not a string!")             # <<<<<<<<<<<<<<
 * 
 *             if len(<str>chunk_obj) > 0:
 */
  __pyx_tuple__20 = PyTuple_Pack(1, __pyx_kp_u_Data_was_not_a_string); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(0, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);

  /* "srctools/_tokenizer.pyx":860
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create '_NewlinesIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_tuple__24 = PyTuple_Pack(1, __pyx_kp_u_Cannot_create__NewlinesIter_inst); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 860, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);

  /* "srctools/_tokenizer.pyx":879
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__25 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle__NewlinesIter); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 879, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__25);
  __Pyx_GIVEREF(__pyx_tuple__25);

  /* "srctools/_tokenizer.pyx":900
 * 
 *     def __init__(self, tok):
 *         raise TypeError("Cannot create 'BlockIter' instances")             # <<<<<<<<<<<<<<
 * 
 *     def __iter__(self):
 */
  __pyx_tuple__26 = PyTuple_Pack(1, __pyx_kp_u_Cannot_create_BlockIter_instance); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 900, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);

  /* "srctools/_tokenizer.pyx":928
 *     def __reduce__(self):
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_tuple__27 = PyTuple_Pack(1, __pyx_kp_u_Cannot_pickle_BlockIter); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 928, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);

  /* "srctools/_tokenizer.pyx":1027
 *                 raise Exception(f'Reached EOF without null-terminator in {res!r}' '!')
 *             elif len(data) > 1:
 *                 raise ValueError('Asked to read 1 byte, got multiple?')             # <<<<<<<<<<<<<<
 *             elif (<const char *>data)[0] == 0x00:
 *                 # Blank strings are saved as ' '
 */
  __pyx_tuple__28 = PyTuple_Pack(1, __pyx_kp_u_Asked_to_read_1_byte_got_multipl); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(0, 1027, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);

  /* "srctools/_tokenizer.pyx":118
 *         self.flags = 0
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */
  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_GIVEREF(__pyx_tuple__29);
  __pyx_codeobj__30 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__29, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_reduce, 118, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__30)) __PYX_ERR(0, 118, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":159
 *         self.error_type = value
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */
  __pyx_tuple__31 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_message, __pyx_n_s_args, __pyx_n_s_tok_val, __pyx_n_s_str_msg); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_GIVEREF(__pyx_tuple__31);
  __pyx_codeobj__32 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS|CO_VARARGS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__31, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_error, 159, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__32)) __PYX_ERR(0, 159, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":209
 *         return self._get_token()
 * 
 *     def _get_token(self):             # <<<<<<<<<<<<<<
 *         """Compute the next token, must be implemented by subclasses."""
 *         raise NotImplementedError
 */
  __pyx_tuple__33 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_GIVEREF(__pyx_tuple__33);
  __pyx_codeobj__34 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__33, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_get_token, 209, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__34)) __PYX_ERR(0, 209, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":224
 *         return tok_and_val
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */
  __pyx_tuple__35 = PyTuple_Pack(4, __pyx_n_s_self, __pyx_n_s_tok, __pyx_n_s_value, __pyx_n_s_tok_val); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);
  __pyx_codeobj__36 = (PyObject*)__Pyx_PyCode_New(3, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__35, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_push_back, 224, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__36)) __PYX_ERR(0, 224, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":269
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */
  __pyx_tuple__37 = PyTuple_Pack(2, __pyx_n_s_self, __pyx_n_s_tok_and_val); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 269, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);
  __pyx_codeobj__38 = (PyObject*)__Pyx_PyCode_New(1, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__37, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_peek, 269, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__38)) __PYX_ERR(0, 269, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":277
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */
  __pyx_tuple__39 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);
  __pyx_codeobj__40 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__39, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_skipping_newlines, 277, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__40)) __PYX_ERR(0, 277, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":281
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def block(self, str name, consume_brace=True):             # <<<<<<<<<<<<<<
 *         """Helper iterator for parsing keyvalue style blocks.
 * 
 */
  __pyx_tuple__41 = PyTuple_Pack(3, __pyx_n_s_self, __pyx_n_s_name_2, __pyx_n_s_consume_brace); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);
  __pyx_codeobj__42 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__41, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_block_2, 281, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__42)) __PYX_ERR(0, 281, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":291
 *         return BlockIter.__new__(BlockIter, self, name, consume_brace)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */
  __pyx_tuple__43 = PyTuple_Pack(5, __pyx_n_s_self, __pyx_n_s_token, __pyx_n_s_skip_newline, __pyx_n_s_next_token, __pyx_n_s_value); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);
  __pyx_codeobj__44 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__43, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_expect, 291, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__44)) __PYX_ERR(0, 291, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":877
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */
  __pyx_tuple__45 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(0, 877, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);
  __pyx_codeobj__46 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__45, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_reduce, 877, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__46)) __PYX_ERR(0, 877, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":926
 *                 raise self.tok.error(token, value)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')
 */
  __pyx_tuple__47 = PyTuple_Pack(1, __pyx_n_s_self); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);
  __pyx_codeobj__48 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__47, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_reduce, 926, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__48)) __PYX_ERR(0, 926, __pyx_L1_error)

  /* "srctools/_tokenizer.pyx":932
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_tuple__49 = PyTuple_Pack(8, __pyx_n_s_text, __pyx_n_s_size, __pyx_n_s_final_size, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_letter, __pyx_n_s_in_buf, __pyx_n_s_out_buff); if (unlikely(!__pyx_tuple__49)) __PYX_ERR(0, 932, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__49);
  __Pyx_GIVEREF(__pyx_tuple__49);
  __pyx_codeobj__50 = (PyObject*)__Pyx_PyCode_New(1, 0, 8, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__49, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_srctools__tokenizer_pyx, __pyx_n_s_escape_text, 932, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__50)) __PYX_ERR(0, 932, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_1024 = PyInt_FromLong(1024); if (unlikely(!__pyx_int_1024)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(void); /*proto*/

static int __Pyx_modinit_global_init_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __pyx_v_8srctools_10_tokenizer_os_fspath = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_Token = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_TokenSyntaxError = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_STRING = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PAREN_ARGS = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PROP_FLAG = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_DIRECTIVE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_OPEN = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE = Py_None; Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EOF_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_NEWLINE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_COLON_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_EQUALS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_PLUS_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_COMMA_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_type_init_code(void) {
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer = &__pyx_vtable_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer._error = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *, PyObject *))__pyx_f_8srctools_10_tokenizer_13BaseTokenizer__error;
  __pyx_vtable_8srctools_10_tokenizer_BaseTokenizer.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_13BaseTokenizer_next_token;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 74, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer, "__call__"); if (unlikely(!wrapper)) __PYX_ERR(0, 74, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__.doc = __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_6__call__;
    }
  }
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer, "__iter__"); if (unlikely(!wrapper)) __PYX_ERR(0, 74, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_10__iter__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_10__iter__.doc = __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_10__iter__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_10__iter__;
    }
  }
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer, "__next__"); if (unlikely(!wrapper)) __PYX_ERR(0, 74, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_12__next__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_12__next__.doc = __pyx_doc_8srctools_10_tokenizer_13BaseTokenizer_12__next__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_8srctools_10_tokenizer_13BaseTokenizer_12__next__;
    }
  }
  #endif
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_BaseTokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 74, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_BaseTokenizer, (PyObject *)&__pyx_type_8srctools_10_tokenizer_BaseTokenizer) < 0) __PYX_ERR(0, 74, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer = &__pyx_type_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer = &__pyx_vtable_8srctools_10_tokenizer_Tokenizer;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.__pyx_base = *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.__pyx_base.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_next_token;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_reset = (void (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_reset;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_add_char = (int (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *, char))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_add_char;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer.buf_get_text = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer_buf_get_text;
  __pyx_vtable_8srctools_10_tokenizer_Tokenizer._next_char = (unsigned char (*)(struct __pyx_obj_8srctools_10_tokenizer_Tokenizer *))__pyx_f_8srctools_10_tokenizer_9Tokenizer__next_char;
  __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_base = __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 311, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_Tokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_Tokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 311, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_Tokenizer, (PyObject *)&__pyx_type_8srctools_10_tokenizer_Tokenizer) < 0) __PYX_ERR(0, 311, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_Tokenizer = &__pyx_type_8srctools_10_tokenizer_Tokenizer;
  __pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer = &__pyx_vtable_8srctools_10_tokenizer_IterTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_IterTokenizer.__pyx_base = *__pyx_vtabptr_8srctools_10_tokenizer_BaseTokenizer;
  __pyx_vtable_8srctools_10_tokenizer_IterTokenizer.__pyx_base.next_token = (PyObject *(*)(struct __pyx_obj_8srctools_10_tokenizer_BaseTokenizer *))__pyx_f_8srctools_10_tokenizer_13IterTokenizer_next_token;
  __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_base = __pyx_ptype_8srctools_10_tokenizer_BaseTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (__Pyx_SetVtable(__pyx_type_8srctools_10_tokenizer_IterTokenizer.tp_dict, __pyx_vtabptr_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_IterTokenizer_2, (PyObject *)&__pyx_type_8srctools_10_tokenizer_IterTokenizer) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer_IterTokenizer = &__pyx_type_8srctools_10_tokenizer_IterTokenizer;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer__NewlinesIter) < 0) __PYX_ERR(0, 849, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_dictoffset && __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer__NewlinesIter.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  __pyx_ptype_8srctools_10_tokenizer__NewlinesIter = &__pyx_type_8srctools_10_tokenizer__NewlinesIter;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer_BlockIter) < 0) __PYX_ERR(0, 885, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer_BlockIter.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer_BlockIter.tp_dictoffset && __pyx_type_8srctools_10_tokenizer_BlockIter.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer_BlockIter.tp_getattro = __Pyx_PyObject_GenericGetAttrNoDict;
  }
  __pyx_ptype_8srctools_10_tokenizer_BlockIter = &__pyx_type_8srctools_10_tokenizer_BlockIter;
  if (PyType_Ready(&__pyx_type_8srctools_10_tokenizer__VPK_IterNullstr) < 0) __PYX_ERR(0, 990, __pyx_L1_error)
  #if PY_VERSION_HEX < 0x030800B1
  __pyx_type_8srctools_10_tokenizer__VPK_IterNullstr.tp_print = 0;
  #endif
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type_8srctools_10_tokenizer__VPK_IterNullstr.tp_dictoffset && __pyx_type_8srctools_10_tokenizer__VPK_IterNullstr.tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_type_8srctools_10_tokenizer__VPK_IterNullstr.tp_getattro = __Pyx_PyObject_GenericGetAttr;
  }
  if (PyObject_SetAttr(__pyx_m, __pyx_n_s_VPK_IterNullstr, (PyObject *)&__pyx_type_8srctools_10_tokenizer__VPK_IterNullstr) < 0) __PYX_ERR(0, 990, __pyx_L1_error)
  __pyx_ptype_8srctools_10_tokenizer__VPK_IterNullstr = &__pyx_type_8srctools_10_tokenizer__VPK_IterNullstr;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_import_code(void) {
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __pyx_t_1 = PyImport_ImportModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType(__pyx_t_1, __Pyx_BUILTIN_MODULE_NAME, "type", 
  #if defined(PYPY_VERSION_NUM) && PYPY_VERSION_NUM < 0x050B0000
  sizeof(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject),
  #endif
  __Pyx_ImportType_CheckSize_Warn);
   if (!__pyx_ptype_7cpython_4type_type) __PYX_ERR(1, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_variable_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}


#ifndef CYTHON_NO_PYINIT_EXPORT
#define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#elif PY_MAJOR_VERSION < 3
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" void
#else
#define __Pyx_PyMODINIT_FUNC void
#endif
#else
#ifdef __cplusplus
#define __Pyx_PyMODINIT_FUNC extern "C" PyObject *
#else
#define __Pyx_PyMODINIT_FUNC PyObject *
#endif
#endif


#if PY_MAJOR_VERSION < 3
__Pyx_PyMODINIT_FUNC init_tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC init_tokenizer(void)
#else
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    #if PY_VERSION_HEX >= 0x030700A1
    static PY_INT64_T main_interpreter_id = -1;
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return (unlikely(current_id == -1)) ? -1 : 0;
    } else if (unlikely(main_interpreter_id != current_id))
    #else
    static PyInterpreterState *main_interpreter = NULL;
    PyInterpreterState *current_interpreter = PyThreadState_Get()->interp;
    if (!main_interpreter) {
        main_interpreter = current_interpreter;
    } else if (unlikely(main_interpreter != current_interpreter))
    #endif
    {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name, int allow_none) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        if (allow_none || value != Py_None) {
            result = PyDict_SetItemString(moddict, to_name, value);
        }
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__Pyx_check_single_interpreter())
        return NULL;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__", 0) < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec__tokenizer(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module '_tokenizer' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #elif PY_MAJOR_VERSION >= 3
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif
  __Pyx_RefNannySetupContext("__Pyx_PyMODINIT_FUNC PyInit__tokenizer(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(WITH_THREAD) && PY_VERSION_HEX < 0x030700F0 && defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  PyEval_InitThreads();
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("_tokenizer", __pyx_methods, __pyx_k_Cython_version_of_the_Tokenizer, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_b);
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_cython_runtime);
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_srctools___tokenizer) {
    if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name, __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "srctools._tokenizer")) {
      if (unlikely(PyDict_SetItemString(modules, "srctools._tokenizer", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code();
  (void)__Pyx_modinit_variable_export_code();
  (void)__Pyx_modinit_function_export_code();
  if (unlikely(__Pyx_modinit_type_init_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  if (unlikely(__Pyx_modinit_type_import_code() < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
  (void)__Pyx_modinit_variable_import_code();
  (void)__Pyx_modinit_function_import_code();
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "srctools/_tokenizer.pyx":15
 * 
 * cdef object os_fspath
 * from os import fspath as os_fspath             # <<<<<<<<<<<<<<
 * 
 * # Import the Token enum from the Python file, and cache references
 */
  __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_n_s_fspath);
  __Pyx_GIVEREF(__pyx_n_s_fspath);
  PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_fspath);
  __pyx_t_2 = __Pyx_Import(__pyx_n_s_os, __pyx_t_1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_2, __pyx_n_s_fspath); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_os_fspath);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_os_fspath, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":22
 * 
 * cdef object Token, TokenSyntaxError
 * from srctools.tokenizer import Token,  TokenSyntaxError             # <<<<<<<<<<<<<<
 * 
 * __all__ = ['BaseTokenizer', 'Tokenizer', 'IterTokenizer', 'escape_text']
 */
  __pyx_t_2 = PyList_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_n_s_Token_2);
  __Pyx_GIVEREF(__pyx_n_s_Token_2);
  PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_Token_2);
  __Pyx_INCREF(__pyx_n_s_TokenSyntaxError);
  __Pyx_GIVEREF(__pyx_n_s_TokenSyntaxError);
  PyList_SET_ITEM(__pyx_t_2, 1, __pyx_n_s_TokenSyntaxError);
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_srctools_tokenizer, __pyx_t_2, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_1, __pyx_n_s_Token_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_Token);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_Token, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_1, __pyx_n_s_TokenSyntaxError); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_t_2);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_TokenSyntaxError, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":24
 * from srctools.tokenizer import Token,  TokenSyntaxError
 * 
 * __all__ = ['BaseTokenizer', 'Tokenizer', 'IterTokenizer', 'escape_text']             # <<<<<<<<<<<<<<
 * 
 * # Cdef-ed globals become static module vars, which aren't in the module
 */
  __pyx_t_1 = PyList_New(4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_n_u_BaseTokenizer);
  __Pyx_GIVEREF(__pyx_n_u_BaseTokenizer);
  PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_u_BaseTokenizer);
  __Pyx_INCREF(__pyx_n_u_Tokenizer);
  __Pyx_GIVEREF(__pyx_n_u_Tokenizer);
  PyList_SET_ITEM(__pyx_t_1, 1, __pyx_n_u_Tokenizer);
  __Pyx_INCREF(__pyx_n_u_IterTokenizer_2);
  __Pyx_GIVEREF(__pyx_n_u_IterTokenizer_2);
  PyList_SET_ITEM(__pyx_t_1, 2, __pyx_n_u_IterTokenizer_2);
  __Pyx_INCREF(__pyx_n_u_escape_text);
  __Pyx_GIVEREF(__pyx_n_u_escape_text);
  PyList_SET_ITEM(__pyx_t_1, 3, __pyx_n_u_escape_text);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_all, __pyx_t_1) < 0) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":30
 * # lookup.
 * cdef:
 *     object STRING = Token.STRING             # <<<<<<<<<<<<<<
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_STRING); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_STRING);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_STRING, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":31
 * cdef:
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS             # <<<<<<<<<<<<<<
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PAREN_ARGS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PAREN_ARGS, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":32
 *     object STRING = Token.STRING
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]             # <<<<<<<<<<<<<<
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PROP_FLAG); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PROP_FLAG);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PROP_FLAG, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":33
 *     object PAREN_ARGS = Token.PAREN_ARGS
 *     object PROP_FLAG = Token.PROP_FLAG  # [!flag]
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)             # <<<<<<<<<<<<<<
 * 
 *     object EOF = Token.EOF
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_DIRECTIVE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_DIRECTIVE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_DIRECTIVE, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":35
 *     object DIRECTIVE = Token.DIRECTIVE  # #name (automatically casefolded)
 * 
 *     object EOF = Token.EOF             # <<<<<<<<<<<<<<
 *     object NEWLINE = Token.NEWLINE
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 35, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":36
 * 
 *     object EOF = Token.EOF
 *     object NEWLINE = Token.NEWLINE             # <<<<<<<<<<<<<<
 * 
 *     object BRACE_OPEN = Token.BRACE_OPEN
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 36, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":38
 *     object NEWLINE = Token.NEWLINE
 * 
 *     object BRACE_OPEN = Token.BRACE_OPEN             # <<<<<<<<<<<<<<
 *     object BRACE_CLOSE = Token.BRACE_CLOSE
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_OPEN); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":39
 * 
 *     object BRACE_OPEN = Token.BRACE_OPEN
 *     object BRACE_CLOSE = Token.BRACE_CLOSE             # <<<<<<<<<<<<<<
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACE_CLOSE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 39, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":42
 * 
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, '')             # <<<<<<<<<<<<<<
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EOF); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__8);
  __Pyx_GIVEREF(__pyx_kp_u__8);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__8);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EOF_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EOF_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":43
 *     # Reuse a single tuple for these, since the value is constant.
 *     tuple EOF_TUP = (Token.EOF, '')
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')             # <<<<<<<<<<<<<<
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_NEWLINE); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__9);
  __Pyx_GIVEREF(__pyx_kp_u__9);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__9);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_NEWLINE_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":45
 *     tuple NEWLINE_TUP = (Token.NEWLINE, '\n')
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')             # <<<<<<<<<<<<<<
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_COLON); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 45, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__14);
  __Pyx_GIVEREF(__pyx_kp_u__14);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__14);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_COLON_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_COLON_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":46
 * 
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')             # <<<<<<<<<<<<<<
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 *     tuple COMMA_TUP = (Token.COMMA, ',')
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_EQUALS); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__15);
  __Pyx_GIVEREF(__pyx_kp_u__15);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__15);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_EQUALS_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":47
 *     tuple COLON_TUP = (Token.COLON, ':')
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')             # <<<<<<<<<<<<<<
 *     tuple COMMA_TUP = (Token.COMMA, ',')
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_PLUS); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__16);
  __Pyx_GIVEREF(__pyx_kp_u__16);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__16);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_PLUS_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_PLUS_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":48
 *     tuple EQUALS_TUP = (Token.EQUALS, '=')
 *     tuple PLUS_TUP = (Token.PLUS, '+')
 *     tuple COMMA_TUP = (Token.COMMA, ',')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACE_OPEN_TUP = (BRACE_OPEN, '{')
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_COMMA); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 48, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__17);
  __Pyx_GIVEREF(__pyx_kp_u__17);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__17);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_COMMA_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_COMMA_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":50
 *     tuple COMMA_TUP = (Token.COMMA, ',')
 * 
 *     tuple BRACE_OPEN_TUP = (BRACE_OPEN, '{')             # <<<<<<<<<<<<<<
 *     tuple BRACE_CLOSE_TUP = (BRACE_CLOSE, '}')
 * 
 */
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN);
  __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_8srctools_10_tokenizer_BRACE_OPEN);
  __Pyx_INCREF(__pyx_kp_u__10);
  __Pyx_GIVEREF(__pyx_kp_u__10);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__10);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_OPEN_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":51
 * 
 *     tuple BRACE_OPEN_TUP = (BRACE_OPEN, '{')
 *     tuple BRACE_CLOSE_TUP = (BRACE_CLOSE, '}')             # <<<<<<<<<<<<<<
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 */
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE);
  __Pyx_GIVEREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_v_8srctools_10_tokenizer_BRACE_CLOSE);
  __Pyx_INCREF(__pyx_kp_u__11);
  __Pyx_GIVEREF(__pyx_kp_u__11);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__11);
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACE_CLOSE_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":53
 *     tuple BRACE_CLOSE_TUP = (BRACE_CLOSE, '}')
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')             # <<<<<<<<<<<<<<
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_OPEN); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 53, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 53, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_kp_u__12);
  __Pyx_GIVEREF(__pyx_kp_u__12);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_kp_u__12);
  __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_OPEN_TUP, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":54
 * 
 *     tuple BRACK_OPEN_TUP = (Token.BRACK_OPEN, '[')
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')             # <<<<<<<<<<<<<<
 * 
 *     uchar *EMPTY_BUF = b''  # Initial value, just so it's valid.
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_8srctools_10_tokenizer_Token, __pyx_n_s_BRACK_CLOSE); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 54, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 54, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
  __Pyx_INCREF(__pyx_kp_u__13);
  __Pyx_GIVEREF(__pyx_kp_u__13);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_kp_u__13);
  __pyx_t_2 = 0;
  __Pyx_XGOTREF(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP);
  __Pyx_DECREF_SET(__pyx_v_8srctools_10_tokenizer_BRACK_CLOSE_TUP, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "srctools/_tokenizer.pyx":56
 *     tuple BRACK_CLOSE_TUP = (Token.BRACK_CLOSE, ']')
 * 
 *     uchar *EMPTY_BUF = b''  # Initial value, just so it's valid.             # <<<<<<<<<<<<<<
 * 
 * # Characters not allowed for bare names on a line.
 */
  __pyx_v_8srctools_10_tokenizer_EMPTY_BUF = ((unsigned char *)((char const *)""));

  /* "srctools/_tokenizer.pyx":118
 *         self.flags = 0
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """Disallow pickling Tokenizers.
 * 
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_3__reduce__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer___reduce, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__30)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_reduce, __pyx_t_1) < 0) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":159
 *         self.error_type = value
 * 
 *     def error(self, message, *args):             # <<<<<<<<<<<<<<
 *         """Raise a syntax error exception.
 * 
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_5error, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_error, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__32)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_error, __pyx_t_1) < 0) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":209
 *         return self._get_token()
 * 
 *     def _get_token(self):             # <<<<<<<<<<<<<<
 *         """Compute the next token, must be implemented by subclasses."""
 *         raise NotImplementedError
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_9_get_token, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer__get_token, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__34)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_get_token, __pyx_t_1) < 0) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":224
 *         return tok_and_val
 * 
 *     def push_back(self, object tok not None, str value=None):             # <<<<<<<<<<<<<<
 *         """Return a token, so it will be reproduced when called again.
 * 
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_15push_back, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_push_back, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__36)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_push_back, __pyx_t_1) < 0) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":269
 *         self.pushback_val = value
 * 
 *     def peek(self):             # <<<<<<<<<<<<<<
 *         """Peek at the next token, without removing it from the stream."""
 *         # We know this is a valid pushback value, and any existing value was
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_17peek, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_peek, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__38)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 269, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_peek, __pyx_t_1) < 0) __PYX_ERR(0, 269, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":277
 *         return tok_and_val
 * 
 *     def skipping_newlines(self):             # <<<<<<<<<<<<<<
 *         """Iterate over the tokens, skipping newlines."""
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_19skipping_newlines, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_skipping_newlines, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__40)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_skipping_newlines, __pyx_t_1) < 0) __PYX_ERR(0, 277, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":281
 *         return _NewlinesIter.__new__(_NewlinesIter, self)
 * 
 *     def block(self, str name, consume_brace=True):             # <<<<<<<<<<<<<<
 *         """Helper iterator for parsing keyvalue style blocks.
 * 
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_21block, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_block, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__42)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_block_2, __pyx_t_1) < 0) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":291
 *         return BlockIter.__new__(BlockIter, self, name, consume_brace)
 * 
 *     def expect(self, object token, bint skip_newline=True):             # <<<<<<<<<<<<<<
 *         """Consume the next token, which should be the given type.
 * 
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13BaseTokenizer_23expect, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BaseTokenizer_expect, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__44)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer->tp_dict, __pyx_n_s_expect, __pyx_t_1) < 0) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer);

  /* "srctools/_tokenizer.pyx":877
 *                 return tok_and_val
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle _NewlinesIter!')
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_13_NewlinesIter_11__reduce__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_NewlinesIter___reduce, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__46)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 877, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter->tp_dict, __pyx_n_s_reduce, __pyx_t_1) < 0) __PYX_ERR(0, 877, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer__NewlinesIter);

  /* "srctools/_tokenizer.pyx":926
 *                 raise self.tok.error(token, value)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         """This cannot be pickled - the Python version does not have this class."""
 *         raise NotImplementedError('Cannot pickle BlockIter!')
 */
  __pyx_t_1 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_9BlockIter_11__reduce__, __Pyx_CYFUNCTION_CCLASS, __pyx_n_s_BlockIter___reduce, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__48)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem((PyObject *)__pyx_ptype_8srctools_10_tokenizer_BlockIter->tp_dict, __pyx_n_s_reduce, __pyx_t_1) < 0) __PYX_ERR(0, 926, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_8srctools_10_tokenizer_BlockIter);

  /* "srctools/_tokenizer.pyx":932
 * 
 * @cython.nonecheck(False)
 * def escape_text(str text not None: str) -> str:             # <<<<<<<<<<<<<<
 *     r"""Escape special characters and backslashes, so tokenising reproduces them.
 * 
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 932, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_text, __pyx_n_u_unicode) < 0) __PYX_ERR(0, 932, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_return, __pyx_n_u_unicode) < 0) __PYX_ERR(0, 932, __pyx_L1_error)
  __pyx_t_2 = __Pyx_CyFunction_New(&__pyx_mdef_8srctools_10_tokenizer_1escape_text, 0, __pyx_n_s_escape_text, NULL, __pyx_n_s_srctools__tokenizer, __pyx_d, ((PyObject *)__pyx_codeobj__50)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 932, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_CyFunction_SetAnnotationsDict(__pyx_t_2, __pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_escape_text, __pyx_t_2) < 0) __PYX_ERR(0, 932, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "srctools/_tokenizer.pyx":1055
 * cdef extern from *:  # Cython flag indicating if PyTypeObject is safe to access.
 *     cdef bint USE_TYPE_INTERNALS "CYTHON_USE_TYPE_SLOTS"
 * if USE_TYPE_INTERNALS:             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 */
  __pyx_t_3 = (CYTHON_USE_TYPE_SLOTS != 0);
  if (__pyx_t_3) {

    /* "srctools/_tokenizer.pyx":1056
 *     cdef bint USE_TYPE_INTERNALS "CYTHON_USE_TYPE_SLOTS"
 * if USE_TYPE_INTERNALS:
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_BaseTokenizer)->tp_name = ((char const *)"srctools.tokenizer.BaseTokenizer");

    /* "srctools/_tokenizer.pyx":1057
 * if USE_TYPE_INTERNALS:
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 * try:
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer_Tokenizer)->tp_name = ((char const *)"srctools.tokenizer.Tokenizer");

    /* "srctools/_tokenizer.pyx":1058
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"             # <<<<<<<<<<<<<<
 * try:
 *     escape_text.__module__ = 'srctools.tokenizer'
 */
    ((PyTypeObject *)__pyx_ptype_8srctools_10_tokenizer__NewlinesIter)->tp_name = ((char const *)"srctools.tokenizer._skip_newlines_iterator");

    /* "srctools/_tokenizer.pyx":1055
 * cdef extern from *:  # Cython flag indicating if PyTypeObject is safe to access.
 *     cdef bint USE_TYPE_INTERNALS "CYTHON_USE_TYPE_SLOTS"
 * if USE_TYPE_INTERNALS:             # <<<<<<<<<<<<<<
 *     (<PyTypeObject *>BaseTokenizer).tp_name = b"srctools.tokenizer.BaseTokenizer"
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 */
  }

  /* "srctools/_tokenizer.pyx":1059
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 * try:             # <<<<<<<<<<<<<<
 *     escape_text.__module__ = 'srctools.tokenizer'
 * except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_4, &__pyx_t_5, &__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    /*try:*/ {

      /* "srctools/_tokenizer.pyx":1060
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 * try:
 *     escape_text.__module__ = 'srctools.tokenizer'             # <<<<<<<<<<<<<<
 * except Exception:
 *     pass  # Perfectly fine.
 */
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_n_s_escape_text); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1060, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (__Pyx_PyObject_SetAttrStr(__pyx_t_2, __pyx_n_s_module, __pyx_kp_u_srctools_tokenizer) < 0) __PYX_ERR(0, 1060, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "srctools/_tokenizer.pyx":1059
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 * try:             # <<<<<<<<<<<<<<
 *     escape_text.__module__ = 'srctools.tokenizer'
 * except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "srctools/_tokenizer.pyx":1061
 * try:
 *     escape_text.__module__ = 'srctools.tokenizer'
 * except Exception:             # <<<<<<<<<<<<<<
 *     pass  # Perfectly fine.
 */
    __pyx_t_7 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_7) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "srctools/_tokenizer.pyx":1059
 *     (<PyTypeObject *>Tokenizer).tp_name = b"srctools.tokenizer.Tokenizer"
 *     (<PyTypeObject *>_NewlinesIter).tp_name = b"srctools.tokenizer._skip_newlines_iterator"
 * try:             # <<<<<<<<<<<<<<
 *     escape_text.__module__ = 'srctools.tokenizer'
 * except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L1_error;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    __pyx_L8_try_end:;
  }

  /* "srctools/_tokenizer.pyx":1
 * # cython: language_level=3, embedsignature=True, auto_pickle=False             # <<<<<<<<<<<<<<
 * # cython: binding=True
 * """Cython version of the Tokenizer class."""
 */
  __pyx_t_2 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_2) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init srctools._tokenizer", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_CLEAR(__pyx_m);
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init srctools._tokenizer");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (__Pyx_PyUnicode_GET_LENGTH(**name) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (__Pyx_PyUnicode_GET_LENGTH(**argname) != __Pyx_PyUnicode_GET_LENGTH(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* PyCFunctionFastCall */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS | METH_STACKLESS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)(void*)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)(void*)meth)) (self, args, nargs);
    }
}
#endif

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, Py_ssize_t nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = Py_TYPE(func)->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
#if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (__Pyx_PyFastCFunction_Check(func)) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* PyUnicode_Substring */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_Substring(
            PyObject* text, Py_ssize_t start, Py_ssize_t stop) {
    Py_ssize_t length;
    if (unlikely(__Pyx_PyUnicode_READY(text) == -1)) return NULL;
    length = __Pyx_PyUnicode_GET_LENGTH(text);
    if (start < 0) {
        start += length;
        if (start < 0)
            start = 0;
    }
    if (stop < 0)
        stop += length;
    else if (stop > length)
        stop = length;
    if (stop <= start)
        return __Pyx_NewRef(__pyx_empty_unicode);
#if CYTHON_PEP393_ENABLED
    return PyUnicode_FromKindAndData(PyUnicode_KIND(text),
        PyUnicode_1BYTE_DATA(text) + start*PyUnicode_KIND(text), stop-start);
#else
    return PyUnicode_FromUnicode(PyUnicode_AS_UNICODE(text)+start, stop-start);
#endif
}

/* JoinPyUnicode */
static PyObject* __Pyx_PyUnicode_Join(PyObject* value_tuple, Py_ssize_t value_count, Py_ssize_t result_ulength,
                                      CYTHON_UNUSED Py_UCS4 max_char) {
#if CYTHON_USE_UNICODE_INTERNALS && CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    PyObject *result_uval;
    int result_ukind;
    Py_ssize_t i, char_pos;
    void *result_udata;
#if CYTHON_PEP393_ENABLED
    result_uval = PyUnicode_New(result_ulength, max_char);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = (max_char <= 255) ? PyUnicode_1BYTE_KIND : (max_char <= 65535) ? PyUnicode_2BYTE_KIND : PyUnicode_4BYTE_KIND;
    result_udata = PyUnicode_DATA(result_uval);
#else
    result_uval = PyUnicode_FromUnicode(NULL, result_ulength);
    if (unlikely(!result_uval)) return NULL;
    result_ukind = sizeof(Py_UNICODE);
    result_udata = PyUnicode_AS_UNICODE(result_uval);
#endif
    char_pos = 0;
    for (i=0; i < value_count; i++) {
        int ukind;
        Py_ssize_t ulength;
        void *udata;
        PyObject *uval = PyTuple_GET_ITEM(value_tuple, i);
        if (unlikely(__Pyx_PyUnicode_READY(uval)))
            goto bad;
        ulength = __Pyx_PyUnicode_GET_LENGTH(uval);
        if (unlikely(!ulength))
            continue;
        if (unlikely(char_pos + ulength < 0))
            goto overflow;
        ukind = __Pyx_PyUnicode_KIND(uval);
        udata = __Pyx_PyUnicode_DATA(uval);
        if (!CYTHON_PEP393_ENABLED || ukind == result_ukind) {
            memcpy((char *)result_udata + char_pos * result_ukind, udata, (size_t) (ulength * result_ukind));
        } else {
            #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030300F0 || defined(_PyUnicode_FastCopyCharacters)
            _PyUnicode_FastCopyCharacters(result_uval, char_pos, uval, 0, ulength);
            #else
            Py_ssize_t j;
            for (j=0; j < ulength; j++) {
                Py_UCS4 uchar = __Pyx_PyUnicode_READ(ukind, udata, j);
                __Pyx_PyUnicode_WRITE(result_ukind, result_udata, char_pos+j, uchar);
            }
            #endif
        }
        char_pos += ulength;
    }
    return result_uval;
overflow:
    PyErr_SetString(PyExc_OverflowError, "join() result is too long for a Python string");
bad:
    Py_DECREF(result_uval);
    return NULL;
#else
    result_ulength++;
    value_count++;
    return PyUnicode_Join(__pyx_empty_unicode, value_tuple);
#endif
}

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* GetItemInt */
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* PyUnicode_Unicode */
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_Unicode(PyObject *obj) {
    if (unlikely(obj == Py_None))
        obj = __pyx_kp_u_None;
    return __Pyx_NewRef(obj);
}

/* KeywordStringCheck */
static int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* PyObjectCallNoArg */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
#else
    if (likely(PyCFunction_Check(func)))
#endif
    {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
    return 0;
}

/* PyObjectFormatAndDecref */
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatSimpleAndDecref(PyObject* s, PyObject* f) {
    if (unlikely(!s)) return NULL;
    if (likely(PyUnicode_CheckExact(s))) return s;
    #if PY_MAJOR_VERSION < 3
    if (likely(PyString_CheckExact(s))) {
        PyObject *result = PyUnicode_FromEncodedObject(s, NULL, "strict");
        Py_DECREF(s);
        return result;
    }
    #endif
    return __Pyx_PyObject_FormatAndDecref(s, f);
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_FormatAndDecref(PyObject* s, PyObject* f) {
    PyObject *result = PyObject_Format(s, f);
    Py_DECREF(s);
    return result;
}

/* RaiseTooManyValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* RaiseNoneIterError */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* GetTopmostException */
#if CYTHON_USE_EXC_INFO_STACK
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_type == NULL || exc_info->exc_type == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* GetException */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* PyObjectCall2Args */
static CYTHON_UNUSED PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2) {
    PyObject *args, *result = NULL;
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyFunction_FastCall(function, args, 2);
    }
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(function)) {
        PyObject *args[2] = {arg1, arg2};
        return __Pyx_PyCFunction_FastCall(function, args, 2);
    }
    #endif
    args = PyTuple_New(2);
    if (unlikely(!args)) goto done;
    Py_INCREF(arg1);
    PyTuple_SET_ITEM(args, 0, arg1);
    Py_INCREF(arg2);
    PyTuple_SET_ITEM(args, 1, arg2);
    Py_INCREF(function);
    result = __Pyx_PyObject_Call(function, args, NULL);
    Py_DECREF(args);
    Py_DECREF(function);
done:
    return result;
}

/* IterNext */
static PyObject *__Pyx_PyIter_Next2Default(PyObject* defval) {
    PyObject* exc_type;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    exc_type = __Pyx_PyErr_Occurred();
    if (unlikely(exc_type)) {
        if (!defval || unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)))
            return NULL;
        __Pyx_PyErr_Clear();
        Py_INCREF(defval);
        return defval;
    }
    if (defval) {
        Py_INCREF(defval);
        return defval;
    }
    __Pyx_PyErr_SetNone(PyExc_StopIteration);
    return NULL;
}
static void __Pyx_PyIter_Next_ErrorNoIterator(PyObject *iterator) {
    PyErr_Format(PyExc_TypeError,
        "%.200s object is not an iterator", Py_TYPE(iterator)->tp_name);
}
static CYTHON_INLINE PyObject *__Pyx_PyIter_Next2(PyObject* iterator, PyObject* defval) {
    PyObject* next;
    iternextfunc iternext = Py_TYPE(iterator)->tp_iternext;
    if (likely(iternext)) {
#if CYTHON_USE_TYPE_SLOTS
        next = iternext(iterator);
        if (likely(next))
            return next;
        #if PY_VERSION_HEX >= 0x02070000
        if (unlikely(iternext == &_PyObject_NextNotImplemented))
            return NULL;
        #endif
#else
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
#endif
    } else if (CYTHON_USE_TYPE_SLOTS || unlikely(!PyIter_Check(iterator))) {
        __Pyx_PyIter_Next_ErrorNoIterator(iterator);
        return NULL;
    }
#if !CYTHON_USE_TYPE_SLOTS
    else {
        next = PyIter_Next(iterator);
        if (likely(next))
            return next;
    }
#endif
    return __Pyx_PyIter_Next2Default(defval);
}

/* SwapException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = *type;
    exc_info->exc_value = *value;
    exc_info->exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* CIntToDigits */
static const char DIGIT_PAIRS_10[2*10*10+1] = {
    "00010203040506070809"
    "10111213141516171819"
    "20212223242526272829"
    "30313233343536373839"
    "40414243444546474849"
    "50515253545556575859"
    "60616263646566676869"
    "70717273747576777879"
    "80818283848586878889"
    "90919293949596979899"
};
static const char DIGIT_PAIRS_8[2*8*8+1] = {
    "0001020304050607"
    "1011121314151617"
    "2021222324252627"
    "3031323334353637"
    "4041424344454647"
    "5051525354555657"
    "6061626364656667"
    "7071727374757677"
};
static const char DIGITS_HEX[2*16+1] = {
    "0123456789abcdef"
    "0123456789ABCDEF"
};

/* BuildPyUnicode */
static PyObject* __Pyx_PyUnicode_BuildFromAscii(Py_ssize_t ulength, char* chars, int clength,
                                                int prepend_sign, char padding_char) {
    PyObject *uval;
    Py_ssize_t uoffset = ulength - clength;
#if CYTHON_USE_UNICODE_INTERNALS
    Py_ssize_t i;
#if CYTHON_PEP393_ENABLED
    void *udata;
    uval = PyUnicode_New(ulength, 127);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_DATA(uval);
#else
    Py_UNICODE *udata;
    uval = PyUnicode_FromUnicode(NULL, ulength);
    if (unlikely(!uval)) return NULL;
    udata = PyUnicode_AS_UNICODE(uval);
#endif
    if (uoffset > 0) {
        i = 0;
        if (prepend_sign) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, 0, '-');
            i++;
        }
        for (; i < uoffset; i++) {
            __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, i, padding_char);
        }
    }
    for (i=0; i < clength; i++) {
        __Pyx_PyUnicode_WRITE(PyUnicode_1BYTE_KIND, udata, uoffset+i, chars[i]);
    }
#else
    {
        PyObject *sign = NULL, *padding = NULL;
        uval = NULL;
        if (uoffset > 0) {
            prepend_sign = !!prepend_sign;
            if (uoffset > prepend_sign) {
                padding = PyUnicode_FromOrdinal(padding_char);
                if (likely(padding) && uoffset > prepend_sign + 1) {
                    PyObject *tmp;
                    PyObject *repeat = PyInt_FromSize_t(uoffset - prepend_sign);
                    if (unlikely(!repeat)) goto done_or_error;
                    tmp = PyNumber_Multiply(padding, repeat);
                    Py_DECREF(repeat);
                    Py_DECREF(padding);
                    padding = tmp;
                }
                if (unlikely(!padding)) goto done_or_error;
            }
            if (prepend_sign) {
                sign = PyUnicode_FromOrdinal('-');
                if (unlikely(!sign)) goto done_or_error;
            }
        }
        uval = PyUnicode_DecodeASCII(chars, clength, NULL);
        if (likely(uval) && padding) {
            PyObject *tmp = PyNumber_Add(padding, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
        if (likely(uval) && sign) {
            PyObject *tmp = PyNumber_Add(sign, uval);
            Py_DECREF(uval);
            uval = tmp;
        }
done_or_error:
        Py_XDECREF(padding);
        Py_XDECREF(sign);
    }
#endif
    return uval;
}

/* CIntToPyUnicode */
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned short    uint16_t;
        #else
           typedef unsigned __int16  uint16_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_From_int(int value, Py_ssize_t width, char padding_char, char format_char) {
    char digits[sizeof(int)*3+2];
    char *dpos, *end = digits + sizeof(int)*3+2;
    const char *hex_digits = DIGITS_HEX;
    Py_ssize_t length, ulength;
    int prepend_sign, last_one_off;
    int remaining;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (format_char == 'X') {
        hex_digits += 16;
        format_char = 'x';
    }
    remaining = value;
    last_one_off = 0;
    dpos = end;
    do {
        int digit_pos;
        switch (format_char) {
        case 'o':
            digit_pos = abs((int)(remaining % (8*8)));
            remaining = (int) (remaining / (8*8));
            dpos -= 2;
            *(uint16_t*)dpos = ((const uint16_t*)DIGIT_PAIRS_8)[digit_pos];
            last_one_off = (digit_pos < 8);
            break;
        case 'd':
            digit_pos = abs((int)(remaining % (10*10)));
            remaining = (int) (remaining / (10*10));
            dpos -= 2;
            *(uint16_t*)dpos = ((const uint16_t*)DIGIT_PAIRS_10)[digit_pos];
            last_one_off = (digit_pos < 10);
            break;
        case 'x':
            *(--dpos) = hex_digits[abs((int)(remaining % 16))];
            remaining = (int) (remaining / 16);
            break;
        default:
            assert(0);
            break;
        }
    } while (unlikely(remaining != 0));
    if (last_one_off) {
        assert(*dpos == '0');
        dpos++;
    }
    length = end - dpos;
    ulength = length;
    prepend_sign = 0;
    if (!is_unsigned && value <= neg_one) {
        if (padding_char == ' ' || width <= length + 1) {
            *(--dpos) = '-';
            ++length;
        } else {
            prepend_sign = 1;
        }
        ++ulength;
    }
    if (width > ulength) {
        ulength = width;
    }
    if (ulength == 1) {
        return PyUnicode_FromOrdinal(*dpos);
    }
    return __Pyx_PyUnicode_BuildFromAscii(ulength, dpos, (int) length, prepend_sign, padding_char);
}

/* decode_c_string */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    Py_ssize_t length;
    if (unlikely((start < 0) | (stop < 0))) {
        size_t slen = strlen(cstring);
        if (unlikely(slen > (size_t) PY_SSIZE_T_MAX)) {
            PyErr_SetString(PyExc_OverflowError,
                            "c-string too long to convert to Python");
            return NULL;
        }
        length = (Py_ssize_t) slen;
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    if (unlikely(stop <= start))
        return __Pyx_NewRef(__pyx_empty_unicode);
    length = stop - start;
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* PyObjectFormat */
#if CYTHON_USE_UNICODE_WRITER
static PyObject* __Pyx_PyObject_Format(PyObject* obj, PyObject* format_spec) {
    int ret;
    _PyUnicodeWriter writer;
    if (likely(PyFloat_CheckExact(obj))) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x03040000
        _PyUnicodeWriter_Init(&writer, 0);
#else
        _PyUnicodeWriter_Init(&writer);
#endif
        ret = _PyFloat_FormatAdvancedWriter(
            &writer,
            obj,
            format_spec, 0, PyUnicode_GET_LENGTH(format_spec));
    } else if (likely(PyLong_CheckExact(obj))) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x03040000
        _PyUnicodeWriter_Init(&writer, 0);
#else
        _PyUnicodeWriter_Init(&writer);
#endif
        ret = _PyLong_FormatAdvancedWriter(
            &writer,
            obj,
            format_spec, 0, PyUnicode_GET_LENGTH(format_spec));
    } else {
        return PyObject_Format(obj, format_spec);
    }
    if (unlikely(ret == -1)) {
        _PyUnicodeWriter_Dealloc(&writer);
        return NULL;
    }
    return _PyUnicodeWriter_Finish(&writer);
}
#endif

/* PyObject_GenericGetAttrNoDict */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject *__Pyx_RaiseGenericGetAttributeError(PyTypeObject *tp, PyObject *attr_name) {
    PyErr_Format(PyExc_AttributeError,
#if PY_MAJOR_VERSION >= 3
                 "'%.50s' object has no attribute '%U'",
                 tp->tp_name, attr_name);
#else
                 "'%.50s' object has no attribute '%.400s'",
                 tp->tp_name, PyString_AS_STRING(attr_name));
#endif
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_GenericGetAttrNoDict(PyObject* obj, PyObject* attr_name) {
    PyObject *descr;
    PyTypeObject *tp = Py_TYPE(obj);
    if (unlikely(!PyString_Check(attr_name))) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    assert(!tp->tp_dictoffset);
    descr = _PyType_Lookup(tp, attr_name);
    if (unlikely(!descr)) {
        return __Pyx_RaiseGenericGetAttributeError(tp, attr_name);
    }
    Py_INCREF(descr);
    #if PY_MAJOR_VERSION < 3
    if (likely(PyType_HasFeature(Py_TYPE(descr), Py_TPFLAGS_HAVE_CLASS)))
    #endif
    {
        descrgetfunc f = Py_TYPE(descr)->tp_descr_get;
        if (unlikely(f)) {
            PyObject *res = f(descr, obj, (PyObject *)tp);
            Py_DECREF(descr);
            return res;
        }
    }
    return descr;
}
#endif

/* PyObject_GenericGetAttr */
#if CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP && PY_VERSION_HEX < 0x03070000
static PyObject* __Pyx_PyObject_GenericGetAttr(PyObject* obj, PyObject* attr_name) {
    if (unlikely(Py_TYPE(obj)->tp_dictoffset)) {
        return PyObject_GenericGetAttr(obj, attr_name);
    }
    return __Pyx_PyObject_GenericGetAttrNoDict(obj, attr_name);
}
#endif

/* SetVTable */
static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* TypeImport */
#ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(PyObject *module, const char *module_name, const char *class_name,
    size_t size, enum __Pyx_ImportType_CheckSize check_size)
{
    PyObject *result = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    result = PyObject_GetAttrString(module, class_name);
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if ((size_t)basicsize < size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    if (check_size == __Pyx_ImportType_CheckSize_Error && (size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        goto bad;
    }
    else if (check_size == __Pyx_ImportType_CheckSize_Warn && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(result);
    return NULL;
}
#endif

/* Import */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if ((1) && (strchr(__Pyx_MODULE_NAME, '.'))) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, (PyObject *)NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* ImportFrom */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Format(PyExc_ImportError,
        #if PY_MAJOR_VERSION < 3
            "cannot import name %.230s", PyString_AS_STRING(name));
        #else
            "cannot import name %S", name);
        #endif
    }
    return value;
}

/* FetchCommonType */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* fake_module;
    PyTypeObject* cached_type = NULL;
    fake_module = PyImport_AddModule((char*) "_cython_" CYTHON_ABI);
    if (!fake_module) return NULL;
    Py_INCREF(fake_module);
    cached_type = (PyTypeObject*) PyObject_GetAttrString(fake_module, type->tp_name);
    if (cached_type) {
        if (!PyType_Check((PyObject*)cached_type)) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s is not a type object",
                type->tp_name);
            goto bad;
        }
        if (cached_type->tp_basicsize != type->tp_basicsize) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s has the wrong size, try recompiling",
                type->tp_name);
            goto bad;
        }
    } else {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        if (PyType_Ready(type) < 0) goto bad;
        if (PyObject_SetAttrString(fake_module, type->tp_name, (PyObject*) type) < 0)
            goto bad;
        Py_INCREF(type);
        cached_type = type;
    }
done:
    Py_DECREF(fake_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* CythonFunctionShared */
#include <structmember.h>
static PyObject *
__Pyx_CyFunction_get_doc(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *closure)
{
    if (unlikely(op->func_doc == NULL)) {
        if (op->func.m_ml->ml_doc) {
#if PY_MAJOR_VERSION >= 3
            op->func_doc = PyUnicode_FromString(op->func.m_ml->ml_doc);
#else
            op->func_doc = PyString_FromString(op->func.m_ml->ml_doc);
#endif
            if (unlikely(op->func_doc == NULL))
                return NULL;
        } else {
            Py_INCREF(Py_None);
            return Py_None;
        }
    }
    Py_INCREF(op->func_doc);
    return op->func_doc;
}
static int
__Pyx_CyFunction_set_doc(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp = op->func_doc;
    if (value == NULL) {
        value = Py_None;
    }
    Py_INCREF(value);
    op->func_doc = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_name(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    if (unlikely(op->func_name == NULL)) {
#if PY_MAJOR_VERSION >= 3
        op->func_name = PyUnicode_InternFromString(op->func.m_ml->ml_name);
#else
        op->func_name = PyString_InternFromString(op->func.m_ml->ml_name);
#endif
        if (unlikely(op->func_name == NULL))
            return NULL;
    }
    Py_INCREF(op->func_name);
    return op->func_name;
}
static int
__Pyx_CyFunction_set_name(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = op->func_name;
    Py_INCREF(value);
    op->func_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_qualname(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(op->func_qualname);
    return op->func_qualname;
}
static int
__Pyx_CyFunction_set_qualname(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value)))
#else
    if (unlikely(value == NULL || !PyString_Check(value)))
#endif
    {
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = op->func_qualname;
    Py_INCREF(value);
    op->func_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_self(__pyx_CyFunctionObject *m, CYTHON_UNUSED void *closure)
{
    PyObject *self;
    self = m->func_closure;
    if (self == NULL)
        self = Py_None;
    Py_INCREF(self);
    return self;
}
static PyObject *
__Pyx_CyFunction_get_dict(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    if (unlikely(op->func_dict == NULL)) {
        op->func_dict = PyDict_New();
        if (unlikely(op->func_dict == NULL))
            return NULL;
    }
    Py_INCREF(op->func_dict);
    return op->func_dict;
}
static int
__Pyx_CyFunction_set_dict(__pyx_CyFunctionObject *op, PyObject *value, CYTHON_UNUSED void *context)
{
    PyObject *tmp;
    if (unlikely(value == NULL)) {
        PyErr_SetString(PyExc_TypeError,
               "function's dictionary may not be deleted");
        return -1;
    }
    if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
               "setting function's dictionary to a non-dict");
        return -1;
    }
    tmp = op->func_dict;
    Py_INCREF(value);
    op->func_dict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_globals(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(op->func_globals);
    return op->func_globals;
}
static PyObject *
__Pyx_CyFunction_get_closure(CYTHON_UNUSED __pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    Py_INCREF(Py_None);
    return Py_None;
}
static PyObject *
__Pyx_CyFunction_get_code(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context)
{
    PyObject* result = (op->func_code) ? op->func_code : Py_None;
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_init_defaults(__pyx_CyFunctionObject *op) {
    int result = 0;
    PyObject *res = op->defaults_getter((PyObject *) op);
    if (unlikely(!res))
        return -1;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    op->defaults_tuple = PyTuple_GET_ITEM(res, 0);
    Py_INCREF(op->defaults_tuple);
    op->defaults_kwdict = PyTuple_GET_ITEM(res, 1);
    Py_INCREF(op->defaults_kwdict);
    #else
    op->defaults_tuple = PySequence_ITEM(res, 0);
    if (unlikely(!op->defaults_tuple)) result = -1;
    else {
        op->defaults_kwdict = PySequence_ITEM(res, 1);
        if (unlikely(!op->defaults_kwdict)) result = -1;
    }
    #endif
    Py_DECREF(res);
    return result;
}
static int
__Pyx_CyFunction_set_defaults(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyTuple_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__defaults__ must be set to a tuple object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_tuple;
    op->defaults_tuple = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_defaults(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->defaults_tuple;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_tuple;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_kwdefaults(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value) {
        value = Py_None;
    } else if (value != Py_None && !PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__kwdefaults__ must be set to a dict object");
        return -1;
    }
    Py_INCREF(value);
    tmp = op->defaults_kwdict;
    op->defaults_kwdict = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->defaults_kwdict;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (__Pyx_CyFunction_init_defaults(op) < 0) return NULL;
            result = op->defaults_kwdict;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_set_annotations(__pyx_CyFunctionObject *op, PyObject* value, CYTHON_UNUSED void *context) {
    PyObject* tmp;
    if (!value || value == Py_None) {
        value = NULL;
    } else if (!PyDict_Check(value)) {
        PyErr_SetString(PyExc_TypeError,
                        "__annotations__ must be set to a dict object");
        return -1;
    }
    Py_XINCREF(value);
    tmp = op->func_annotations;
    op->func_annotations = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_annotations(__pyx_CyFunctionObject *op, CYTHON_UNUSED void *context) {
    PyObject* result = op->func_annotations;
    if (unlikely(!result)) {
        result = PyDict_New();
        if (unlikely(!result)) return NULL;
        op->func_annotations = result;
    }
    Py_INCREF(result);
    return result;
}
static PyGetSetDef __pyx_CyFunction_getsets[] = {
    {(char *) "func_doc", (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "__doc__",  (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {(char *) "func_name", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__name__", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {(char *) "__qualname__", (getter)__Pyx_CyFunction_get_qualname, (setter)__Pyx_CyFunction_set_qualname, 0, 0},
    {(char *) "__self__", (getter)__Pyx_CyFunction_get_self, 0, 0, 0},
    {(char *) "func_dict", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "__dict__", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {(char *) "func_globals", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "__globals__", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {(char *) "func_closure", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "__closure__", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {(char *) "func_code", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "__code__", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {(char *) "func_defaults", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__defaults__", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {(char *) "__kwdefaults__", (getter)__Pyx_CyFunction_get_kwdefaults, (setter)__Pyx_CyFunction_set_kwdefaults, 0, 0},
    {(char *) "__annotations__", (getter)__Pyx_CyFunction_get_annotations, (setter)__Pyx_CyFunction_set_annotations, 0, 0},
    {0, 0, 0, 0, 0}
};
static PyMemberDef __pyx_CyFunction_members[] = {
    {(char *) "__module__", T_OBJECT, offsetof(PyCFunctionObject, m_module), PY_WRITE_RESTRICTED, 0},
    {0, 0, 0,  0, 0}
};
static PyObject *
__Pyx_CyFunction_reduce(__pyx_CyFunctionObject *m, CYTHON_UNUSED PyObject *args)
{
#if PY_MAJOR_VERSION >= 3
    Py_INCREF(m->func_qualname);
    return m->func_qualname;
#else
    return PyString_FromString(m->func.m_ml->ml_name);
#endif
}
static PyMethodDef __pyx_CyFunction_methods[] = {
    {"__reduce__", (PyCFunction)__Pyx_CyFunction_reduce, METH_VARARGS, 0},
    {0, 0, 0, 0}
};
#if PY_VERSION_HEX < 0x030500A0
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func_weakreflist)
#else
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func.m_weakreflist)
#endif
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject *op, PyMethodDef *ml, int flags, PyObject* qualname,
                                       PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    if (unlikely(op == NULL))
        return NULL;
    op->flags = flags;
    __Pyx_CyFunction_weakreflist(op) = NULL;
    op->func.m_ml = ml;
    op->func.m_self = (PyObject *) op;
    Py_XINCREF(closure);
    op->func_closure = closure;
    Py_XINCREF(module);
    op->func.m_module = module;
    op->func_dict = NULL;
    op->func_name = NULL;
    Py_INCREF(qualname);
    op->func_qualname = qualname;
    op->func_doc = NULL;
    op->func_classobj = NULL;
    op->func_globals = globals;
    Py_INCREF(op->func_globals);
    Py_XINCREF(code);
    op->func_code = code;
    op->defaults_pyobjects = 0;
    op->defaults_size = 0;
    op->defaults = NULL;
    op->defaults_tuple = NULL;
    op->defaults_kwdict = NULL;
    op->defaults_getter = NULL;
    op->func_annotations = NULL;
    return (PyObject *) op;
}
static int
__Pyx_CyFunction_clear(__pyx_CyFunctionObject *m)
{
    Py_CLEAR(m->func_closure);
    Py_CLEAR(m->func.m_module);
    Py_CLEAR(m->func_dict);
    Py_CLEAR(m->func_name);
    Py_CLEAR(m->func_qualname);
    Py_CLEAR(m->func_doc);
    Py_CLEAR(m->func_globals);
    Py_CLEAR(m->func_code);
    Py_CLEAR(m->func_classobj);
    Py_CLEAR(m->defaults_tuple);
    Py_CLEAR(m->defaults_kwdict);
    Py_CLEAR(m->func_annotations);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_XDECREF(pydefaults[i]);
        PyObject_Free(m->defaults);
        m->defaults = NULL;
    }
    return 0;
}
static void __Pyx__CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    if (__Pyx_CyFunction_weakreflist(m) != NULL)
        PyObject_ClearWeakRefs((PyObject *) m);
    __Pyx_CyFunction_clear(m);
    PyObject_GC_Del(m);
}
static void __Pyx_CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    PyObject_GC_UnTrack(m);
    __Pyx__CyFunction_dealloc(m);
}
static int __Pyx_CyFunction_traverse(__pyx_CyFunctionObject *m, visitproc visit, void *arg)
{
    Py_VISIT(m->func_closure);
    Py_VISIT(m->func.m_module);
    Py_VISIT(m->func_dict);
    Py_VISIT(m->func_name);
    Py_VISIT(m->func_qualname);
    Py_VISIT(m->func_doc);
    Py_VISIT(m->func_globals);
    Py_VISIT(m->func_code);
    Py_VISIT(m->func_classobj);
    Py_VISIT(m->defaults_tuple);
    Py_VISIT(m->defaults_kwdict);
    if (m->defaults) {
        PyObject **pydefaults = __Pyx_CyFunction_Defaults(PyObject *, m);
        int i;
        for (i = 0; i < m->defaults_pyobjects; i++)
            Py_VISIT(pydefaults[i]);
    }
    return 0;
}
static PyObject *__Pyx_CyFunction_descr_get(PyObject *func, PyObject *obj, PyObject *type)
{
#if PY_MAJOR_VERSION < 3
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    if (m->flags & __Pyx_CYFUNCTION_STATICMETHOD) {
        Py_INCREF(func);
        return func;
    }
    if (m->flags & __Pyx_CYFUNCTION_CLASSMETHOD) {
        if (type == NULL)
            type = (PyObject *)(Py_TYPE(obj));
        return __Pyx_PyMethod_New(func, type, (PyObject *)(Py_TYPE(type)));
    }
    if (obj == Py_None)
        obj = NULL;
#endif
    return __Pyx_PyMethod_New(func, obj, type);
}
static PyObject*
__Pyx_CyFunction_repr(__pyx_CyFunctionObject *op)
{
#if PY_MAJOR_VERSION >= 3
    return PyUnicode_FromFormat("<cyfunction %U at %p>",
                                op->func_qualname, (void *)op);
#else
    return PyString_FromFormat("<cyfunction %s at %p>",
                               PyString_AsString(op->func_qualname), (void *)op);
#endif
}
static PyObject * __Pyx_CyFunction_CallMethod(PyObject *func, PyObject *self, PyObject *arg, PyObject *kw) {
    PyCFunctionObject* f = (PyCFunctionObject*)func;
    PyCFunction meth = f->m_ml->ml_meth;
    Py_ssize_t size;
    switch (f->m_ml->ml_flags & (METH_VARARGS | METH_KEYWORDS | METH_NOARGS | METH_O)) {
    case METH_VARARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0))
            return (*meth)(self, arg);
        break;
    case METH_VARARGS | METH_KEYWORDS:
        return (*(PyCFunctionWithKeywords)(void*)meth)(self, arg, kw);
    case METH_NOARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 0))
                return (*meth)(self, NULL);
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes no arguments (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    case METH_O:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
            size = PyTuple_GET_SIZE(arg);
            if (likely(size == 1)) {
                PyObject *result, *arg0;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                arg0 = PyTuple_GET_ITEM(arg, 0);
                #else
                arg0 = PySequence_ITEM(arg, 0); if (unlikely(!arg0)) return NULL;
                #endif
                result = (*meth)(self, arg0);
                #if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
                Py_DECREF(arg0);
                #endif
                return result;
            }
            PyErr_Format(PyExc_TypeError,
                "%.200s() takes exactly one argument (%" CYTHON_FORMAT_SSIZE_T "d given)",
                f->m_ml->ml_name, size);
            return NULL;
        }
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags in "
                        "__Pyx_CyFunction_Call. METH_OLDARGS is no "
                        "longer supported!");
        return NULL;
    }
    PyErr_Format(PyExc_TypeError, "%.200s() takes no keyword arguments",
                 f->m_ml->ml_name);
    return NULL;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    return __Pyx_CyFunction_CallMethod(func, ((PyCFunctionObject*)func)->m_self, arg, kw);
}
static PyObject *__Pyx_CyFunction_CallAsMethod(PyObject *func, PyObject *args, PyObject *kw) {
    PyObject *result;
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *) func;
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        Py_ssize_t argc;
        PyObject *new_args;
        PyObject *self;
        argc = PyTuple_GET_SIZE(args);
        new_args = PyTuple_GetSlice(args, 1, argc);
        if (unlikely(!new_args))
            return NULL;
        self = PyTuple_GetItem(args, 0);
        if (unlikely(!self)) {
            Py_DECREF(new_args);
            return NULL;
        }
        result = __Pyx_CyFunction_CallMethod(func, self, new_args, kw);
        Py_DECREF(new_args);
    } else {
        result = __Pyx_CyFunction_Call(func, args, kw);
    }
    return result;
}
static PyTypeObject __pyx_CyFunctionType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
    (destructor) __Pyx_CyFunction_dealloc,
    0,
    0,
    0,
#if PY_MAJOR_VERSION < 3
    0,
#else
    0,
#endif
    (reprfunc) __Pyx_CyFunction_repr,
    0,
    0,
    0,
    0,
    __Pyx_CyFunction_CallAsMethod,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC,
    0,
    (traverseproc) __Pyx_CyFunction_traverse,
    (inquiry) __Pyx_CyFunction_clear,
    0,
#if PY_VERSION_HEX < 0x030500A0
    offsetof(__pyx_CyFunctionObject, func_weakreflist),
#else
    offsetof(PyCFunctionObject, m_weakreflist),
#endif
    0,
    0,
    __pyx_CyFunction_methods,
    __pyx_CyFunction_members,
    __pyx_CyFunction_getsets,
    0,
    0,
    __Pyx_CyFunction_descr_get,
    0,
    offsetof(__pyx_CyFunctionObject, func_dict),
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if PY_VERSION_HEX >= 0x030400a1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b1
    0,
#endif
#if PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000
    0,
#endif
};
static int __pyx_CyFunction_init(void) {
    __pyx_CyFunctionType = __Pyx_FetchCommonType(&__pyx_CyFunctionType_type);
    if (unlikely(__pyx_CyFunctionType == NULL)) {
        return -1;
    }
    return 0;
}
static CYTHON_INLINE void *__Pyx_CyFunction_InitDefaults(PyObject *func, size_t size, int pyobjects) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults = PyObject_Malloc(size);
    if (unlikely(!m->defaults))
        return PyErr_NoMemory();
    memset(m->defaults, 0, size);
    m->defaults_pyobjects = pyobjects;
    m->defaults_size = size;
    return m->defaults;
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *func, PyObject *tuple) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_tuple = tuple;
    Py_INCREF(tuple);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_kwdict = dict;
    Py_INCREF(dict);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->func_annotations = dict;
    Py_INCREF(dict);
}

/* CythonFunction */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml, int flags, PyObject* qualname,
                                      PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    PyObject *op = __Pyx_CyFunction_Init(
        PyObject_GC_New(__pyx_CyFunctionObject, __pyx_CyFunctionType),
        ml, flags, qualname, closure, module, globals, code
    );
    if (likely(op)) {
        PyObject_GC_Track(op);
    }
    return op;
}

/* PyDictVersioning */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
    PyObject **dictptr = NULL;
    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
    if (offset) {
#if CYTHON_COMPILING_IN_CPYTHON
        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
#else
        dictptr = _PyObject_GetDictPtr(obj);
#endif
    }
    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
}
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
        return 0;
    return obj_dict_version == __Pyx_get_object_dict_version(obj);
}
#endif

/* GetModuleGlobalName */
#if CYTHON_USE_DICT_VERSIONS
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
#else
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
#endif
{
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1
    result = _PyDict_GetItem_KnownHash(__pyx_d, name, ((PyASCIIObject *) name)->hash);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    } else if (unlikely(PyErr_Occurred())) {
        return NULL;
    }
#else
    result = PyDict_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
#endif
#else
    result = PyObject_GetItem(__pyx_d, name);
    __PYX_UPDATE_DICT_CACHE(__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
    PyErr_Clear();
#endif
    return __Pyx_GetBuiltinName(name);
}

/* PyObjectSetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_setattro))
        return tp->tp_setattro(obj, attr_name, value);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_setattr))
        return tp->tp_setattr(obj, PyString_AS_STRING(attr_name), value);
#endif
    return PyObject_SetAttr(obj, attr_name, value);
}
#endif

/* CLineInTraceback */
#ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_NCP_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    if (unlikely(!__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_n_s_cline_in_traceback))
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, ((size_t)new_max) * sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
#include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntFromPyVerify */
#define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntFromPy */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_char(unsigned char value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const unsigned char neg_one = (unsigned char) -1, const_zero = (unsigned char) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(unsigned char) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(unsigned char) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned char) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(unsigned char) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned char) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(unsigned char),
                                     little, !is_unsigned);
    }
}

/* BytesContains */
static CYTHON_INLINE int __Pyx_BytesContains(PyObject* bytes, char character) {
    const Py_ssize_t length = PyBytes_GET_SIZE(bytes);
    char* char_start = PyBytes_AS_STRING(bytes);
    return memchr(char_start, (unsigned char)character, (size_t)length) != NULL;
}

/* CIntFromPy */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* FastTypeChecks */
#if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        #if PY_MAJOR_VERSION < 3
        if (likely(exc_type == t)) return 1;
        #endif
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* CheckBinaryVersion */
static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(b);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
